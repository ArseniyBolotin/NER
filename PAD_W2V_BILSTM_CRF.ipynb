{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "PAD_W2V_BILSTM_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raJ-rDdCJt_",
        "outputId": "7718b7b2-ef3d-48a1-fc4b-10871ebda5e5"
      },
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install tensorflow==1.15.0 keras==2.2.4\n",
        "!pip3 install glove-python-binary\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-2ges4j6r\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-2ges4j6r\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=17cb2bb4e74c1f2e5e2c046069542e1db6d941511b22f76daf608665a1e8efff\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ly9rve76/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hCollecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 36.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=96d6b92dc96cd0014afb389124263c3558a78a1e2a1fad1ba6369a8cb6899c62\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, keras-applications, tensorboard, tensorflow-estimator, tensorflow, keras\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed gast-0.2.2 keras-2.2.4 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting glove-python-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/11/d8510a80110f736822856db566341dd2e1e7c3af536f77e409a6c09e0c22/glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx7wVx0OiYyv",
        "outputId": "ccec5ce9-9254-41f1-c254-a45cbbead72f"
      },
      "source": [
        "!gdown --id 1cCXjHX9FAgouF0DWuWPO5qyBHVZDkXTQ\n",
        "!gdown --id 1RFNBRcly96omdpNtYlEK6O1EuQs3ux7t\n",
        "!gdown --id 1AnLqXtSyJNBK7YmwuW6L6z2OYhE4RPTV"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cCXjHX9FAgouF0DWuWPO5qyBHVZDkXTQ\n",
            "To: /content/NER_PAD_agg_test.csv\n",
            "2.92MB [00:00, 90.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RFNBRcly96omdpNtYlEK6O1EuQs3ux7t\n",
            "To: /content/NER_PAD_agg_train.csv\n",
            "11.7MB [00:00, 54.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AnLqXtSyJNBK7YmwuW6L6z2OYhE4RPTV\n",
            "To: /content/NER_PAD_agg.csv\n",
            "14.6MB [00:00, 68.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEfFyYZVph-B"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "import gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYiqiimi1vV"
      },
      "source": [
        "df = pd.read_csv('NER_PAD_agg.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "train = pd.read_csv('NER_PAD_agg_train.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "test = pd.read_csv('NER_PAD_agg_test.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "\n",
        "all_dfs = [df, train, test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAl784dWnJkR"
      },
      "source": [
        "pretrained_w2v = api.load(\"word2vec-ruscorpora-300\")\n",
        "pretrained_w2v.save_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthif1zkvsok"
      },
      "source": [
        "def add_suffix(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in pretrained_w2v.vocab.keys():\n",
        "                res.append(w + suffix)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(w)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['tokens_with_suffix'] = d.apply(add_suffix, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rp-IeYsnJf"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v = Word2Vec(sentences=df['tokens_with_suffix'], size=300, window=15, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqqSfYYmY-p"
      },
      "source": [
        "w2v.intersect_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz_dGApGKoB"
      },
      "source": [
        "all_tags = set()\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "labels = list(tag_to_idx.keys())\n",
        "labels.remove('O')\n",
        "labels = sorted(labels, key=lambda name: (name[1:], name[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wxpfE8Hx0u"
      },
      "source": [
        "def find_token(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ', '']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in w2v.wv.vocab.keys():\n",
        "                res.append(w2v.wv.vocab[w + suffix].index)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "J7BswpbHlVW2",
        "outputId": "672d4988-7fd4-4103-97a8-8c39d426d070"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>tokens_with_suffix</th>\n",
              "      <th>encoded_ner_tags</th>\n",
              "      <th>int_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SV990125172_ОРГ__INM_18'09'58_1.pdf</td>\n",
              "      <td>[l, *, универсальный, приложение, №, 1, постан...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...</td>\n",
              "      <td>[l, *, универсальный_ADJ, приложение_NOUN, №, ...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 66, 494, 64, 1, 0, 83, 59, 94, 2904, 441, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SS528581_ОРГ__INM_17'05'39_A.pdf</td>\n",
              "      <td>[l, лист, согласования, стр., 1, 1, 2, 9, *, 0...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, лист_NOUN, согласования, стр., 1, 1, 2, 9,...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 47, 35, 193, 0, 0, 4, 41, 66, 11, 17, 113,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SF435712_ОРГ__INM_15'25'41_A.pdf</td>\n",
              "      <td>[l, приложение, №, постановлению, правительств...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-DOCNUM, B-DOCDAT...</td>\n",
              "      <td>[l, приложение_NOUN, №, постановлению, правите...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 7, 6, 13,...</td>\n",
              "      <td>[3, 64, 1, 83, 59, 290, 1752, 74, 1, 0, 133, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SV990124943_ОРГ__INM_19'00'43_A.pdf</td>\n",
              "      <td>[l, акционерное, общество, регистраторское, об...</td>\n",
              "      <td>[O, O, O, O, O, B-DOCCPTY, O, O, O, O, O, O, O...</td>\n",
              "      <td>[l, акционерное, общество_NOUN, регистраторско...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 3, 15, 15, 15, 15, 15, 15...</td>\n",
              "      <td>[3, 112, 43, 6621, 43, 1315, 0, 56, 80, 0, 189...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S29013419_ОРИГИНАЛ__IND_1_22.05.12'21'36.pdf</td>\n",
              "      <td>[l, *, 000стандарт, безопасности, адрес:, 1973...</td>\n",
              "      <td>[O, O, O, B-DOCCPTY, O, O, O, O, O, O, O, O, O...</td>\n",
              "      <td>[l, *, 000стандарт, безопасности, адрес:, 1973...</td>\n",
              "      <td>[15, 15, 15, 3, 15, 15, 15, 15, 15, 15, 15, 15...</td>\n",
              "      <td>[3, 66, 14721, 4486, 28, 2677, 277, 1137, 8911...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>SV990121575_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, стс, отчет, роялти, 2, к...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-DOCAGRNUM,...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, стс_NOUN, отчет_NOU...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 418, 970, 1293, 4, 1828, 1537, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>SV990121572_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, ао, стс, отчет, роялти, 3, квартал, лиценз...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, ао_NOUN, стс_NOUN, отчет_NOUN, роялти_NOUN...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 67, 418, 970, 1293, 14, 1828, 1537, 93, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>SV990121520_ОРГ__INM_16'31'06_3.pdf</td>\n",
              "      <td>[l, экземпляр, ао, стс, ао, стс, отчет, роялти...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...</td>\n",
              "      <td>[l, экземпляр_NOUN, ао_NOUN, стс_NOUN, ао_NOUN...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 67, 418, 67, 418, 970, 1293, 14, 1787...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>SV990121573_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, стс, отчет, п, роялти, 4...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, стс_NOUN, отчет_NOU...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 418, 970, 19, 1293, 17, 0, 16, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>SV990121764_ОРГ__INM_17'56'07_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, ао, стс, отчет, роялти, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, ао_NOUN, стс_NOUN, ...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 67, 418, 970, 1293, 17, 1828, 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                id  ...                                         int_tokens\n",
              "0              SV990125172_ОРГ__INM_18'09'58_1.pdf  ...  [3, 66, 494, 64, 1, 0, 83, 59, 94, 2904, 441, ...\n",
              "1                 SS528581_ОРГ__INM_17'05'39_A.pdf  ...  [3, 47, 35, 193, 0, 0, 4, 41, 66, 11, 17, 113,...\n",
              "2                 SF435712_ОРГ__INM_15'25'41_A.pdf  ...  [3, 64, 1, 83, 59, 290, 1752, 74, 1, 0, 133, 2...\n",
              "3              SV990124943_ОРГ__INM_19'00'43_A.pdf  ...  [3, 112, 43, 6621, 43, 1315, 0, 56, 80, 0, 189...\n",
              "4     S29013419_ОРИГИНАЛ__IND_1_22.05.12'21'36.pdf  ...  [3, 66, 14721, 4486, 28, 2677, 277, 1137, 8911...\n",
              "...                                            ...  ...                                                ...\n",
              "3995           SV990121575_ОРГ__INM_18'45'08_3.pdf  ...  [3, 361, 8542, 418, 970, 1293, 4, 1828, 1537, ...\n",
              "3996           SV990121572_ОРГ__INM_18'45'08_3.pdf  ...  [3, 67, 418, 970, 1293, 14, 1828, 1537, 93, 1,...\n",
              "3997           SV990121520_ОРГ__INM_16'31'06_3.pdf  ...  [3, 361, 67, 418, 67, 418, 970, 1293, 14, 1787...\n",
              "3998           SV990121573_ОРГ__INM_18'45'08_3.pdf  ...  [3, 361, 8542, 418, 970, 19, 1293, 17, 0, 16, ...\n",
              "3999           SV990121764_ОРГ__INM_17'56'07_3.pdf  ...  [3, 361, 8542, 67, 418, 970, 1293, 17, 1828, 2...\n",
              "\n",
              "[4000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QUuM6AhjxyK"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBokW5kspLO"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=1.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JNx5ntzrHuK"
      },
      "source": [
        "## PRETRAINED W2V(not fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1S7oW2BWoX",
        "outputId": "4dda30a0-9d48-4bea-ec6f-3f41e6141f9e"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 7,765,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVZ0buRG02d",
        "outputId": "56b4ab23-0b7d-4b07-db10-5c954a1051bd"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 42s 15ms/step - loss: 0.7843 - crf_marginal_accuracy: 0.2648 - val_loss: 0.6091 - val_crf_marginal_accuracy: 0.8945\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.5570 - crf_marginal_accuracy: 0.4671 - val_loss: 0.4561 - val_crf_marginal_accuracy: 0.1528\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.4077 - crf_marginal_accuracy: 0.7324 - val_loss: 0.3206 - val_crf_marginal_accuracy: 0.9415\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2823 - crf_marginal_accuracy: 0.9513 - val_loss: 0.2279 - val_crf_marginal_accuracy: 0.9590\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2018 - crf_marginal_accuracy: 0.9687 - val_loss: 0.1798 - val_crf_marginal_accuracy: 0.9683\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.1508 - crf_marginal_accuracy: 0.9790 - val_loss: 0.1489 - val_crf_marginal_accuracy: 0.9835\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1154 - crf_marginal_accuracy: 0.9873 - val_loss: 0.1329 - val_crf_marginal_accuracy: 0.9911\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0918 - crf_marginal_accuracy: 0.9924 - val_loss: 0.1295 - val_crf_marginal_accuracy: 0.9934\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0763 - crf_marginal_accuracy: 0.9941 - val_loss: 0.1267 - val_crf_marginal_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0645 - crf_marginal_accuracy: 0.9958 - val_loss: 0.1261 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0561 - crf_marginal_accuracy: 0.9967 - val_loss: 0.1275 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0488 - crf_marginal_accuracy: 0.9971 - val_loss: 0.1371 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0436 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1413 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0393 - crf_marginal_accuracy: 0.9977 - val_loss: 0.1397 - val_crf_marginal_accuracy: 0.9963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNVGThAXHeL",
        "outputId": "d8c06f13-9243-4bb8-8d33-01d4b2c51808"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6794    0.5933    0.6335       150\n",
            " I-DOCAGRDATE     0.6455    0.8068    0.7172        88\n",
            "  B-DOCAGRNUM     0.6899    0.6089    0.6469       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.7548    0.5350    0.6262      1243\n",
            "  I-DOCAMOUNT     0.7153    0.5065    0.5930       620\n",
            "    B-DOCCPTY     0.8613    0.8874    0.8742       595\n",
            "    I-DOCCPTY     0.8724    0.8972    0.8846       564\n",
            " B-DOCCPTYINN     0.8170    0.9184    0.8648       282\n",
            "B-DOCCUSTOMER     0.9111    0.8916    0.9012       609\n",
            "I-DOCCUSTOMER     0.9326    0.9286    0.9306       462\n",
            "    B-DOCDATE     0.8528    0.8264    0.8394       645\n",
            "    I-DOCDATE     0.8561    0.9636    0.9067       605\n",
            "     B-DOCNUM     0.8995    0.6052    0.7236       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8331    0.7497    0.7892      6700\n",
            "    macro avg     0.6992    0.6646    0.6761      6700\n",
            " weighted avg     0.8266    0.7497    0.7795      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8_PPi6mrQe7"
      },
      "source": [
        "## PRETRAINED W2V(fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV6QMPc3cyy",
        "outputId": "aa167467-2cc7-4ece-b0ae-1bd7429b59c9"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 324,576\n",
            "Non-trainable params: 7,440,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19U1yO8c3czD",
        "outputId": "377dd469-e2c0-4f72-8d42-af99f46e74ee"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 40s 14ms/step - loss: 0.7059 - crf_marginal_accuracy: 0.0202 - val_loss: 0.4837 - val_crf_marginal_accuracy: 0.8589\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.4329 - crf_marginal_accuracy: 0.7772 - val_loss: 0.3297 - val_crf_marginal_accuracy: 0.9113\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3150 - crf_marginal_accuracy: 0.9315 - val_loss: 0.2545 - val_crf_marginal_accuracy: 0.9360\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2577 - crf_marginal_accuracy: 0.9472 - val_loss: 0.2153 - val_crf_marginal_accuracy: 0.9522\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2233 - crf_marginal_accuracy: 0.9555 - val_loss: 0.1925 - val_crf_marginal_accuracy: 0.9511\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1989 - crf_marginal_accuracy: 0.9563 - val_loss: 0.1797 - val_crf_marginal_accuracy: 0.9571\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1805 - crf_marginal_accuracy: 0.9590 - val_loss: 0.1680 - val_crf_marginal_accuracy: 0.9595\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1662 - crf_marginal_accuracy: 0.9616 - val_loss: 0.1587 - val_crf_marginal_accuracy: 0.9582\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1539 - crf_marginal_accuracy: 0.9648 - val_loss: 0.1530 - val_crf_marginal_accuracy: 0.9641\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1435 - crf_marginal_accuracy: 0.9674 - val_loss: 0.1448 - val_crf_marginal_accuracy: 0.9694\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1332 - crf_marginal_accuracy: 0.9706 - val_loss: 0.1395 - val_crf_marginal_accuracy: 0.9714\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1249 - crf_marginal_accuracy: 0.9731 - val_loss: 0.1364 - val_crf_marginal_accuracy: 0.9758\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1170 - crf_marginal_accuracy: 0.9756 - val_loss: 0.1336 - val_crf_marginal_accuracy: 0.9771\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1113 - crf_marginal_accuracy: 0.9785 - val_loss: 0.1293 - val_crf_marginal_accuracy: 0.9788\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1071 - crf_marginal_accuracy: 0.9804 - val_loss: 0.1286 - val_crf_marginal_accuracy: 0.9825\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1051 - crf_marginal_accuracy: 0.9813 - val_loss: 0.1270 - val_crf_marginal_accuracy: 0.9823\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1001 - crf_marginal_accuracy: 0.9834 - val_loss: 0.1222 - val_crf_marginal_accuracy: 0.9848\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0947 - crf_marginal_accuracy: 0.9840 - val_loss: 0.1207 - val_crf_marginal_accuracy: 0.9852\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0904 - crf_marginal_accuracy: 0.9859 - val_loss: 0.1225 - val_crf_marginal_accuracy: 0.9882\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0863 - crf_marginal_accuracy: 0.9872 - val_loss: 0.1179 - val_crf_marginal_accuracy: 0.9860\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0825 - crf_marginal_accuracy: 0.9873 - val_loss: 0.1227 - val_crf_marginal_accuracy: 0.9910\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0806 - crf_marginal_accuracy: 0.9885 - val_loss: 0.1185 - val_crf_marginal_accuracy: 0.9887\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0775 - crf_marginal_accuracy: 0.9895 - val_loss: 0.1160 - val_crf_marginal_accuracy: 0.9881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU37zLsF3czD",
        "outputId": "e9247091-2863-448a-ff86-e11901312b16"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.3111    0.5600    0.4000       150\n",
            " I-DOCAGRDATE     0.5426    0.7955    0.6452        88\n",
            "  B-DOCAGRNUM     0.2834    0.6760    0.3993       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.3086    0.7385    0.4353      1243\n",
            "  I-DOCAMOUNT     0.4029    0.8565    0.5480       620\n",
            "    B-DOCCPTY     0.4643    0.8420    0.5986       595\n",
            "    I-DOCCPTY     0.6881    0.8528    0.7617       564\n",
            " B-DOCCPTYINN     0.5408    0.8936    0.6738       282\n",
            "B-DOCCUSTOMER     0.7301    0.8752    0.7961       609\n",
            "I-DOCCUSTOMER     0.7712    0.9264    0.8417       462\n",
            "    B-DOCDATE     0.5693    0.7705    0.6548       645\n",
            "    I-DOCDATE     0.7568    0.9719    0.8509       605\n",
            "     B-DOCNUM     0.6560    0.6298    0.6426       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.4957    0.8081    0.6144      6700\n",
            "    macro avg     0.4683    0.6926    0.5499      6700\n",
            " weighted avg     0.5445    0.8081    0.6379      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0M6U9bFpeSI"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRins3GMDd-"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300000, window=5, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYv7a7bMMEI",
        "outputId": "5cf862b4-b74f-4bda-a268-d87467f8e31b"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_5 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 1,364,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9AHayBOMMEK",
        "outputId": "f2274436-5e80-42b3-f705-f0e9c1c6b91d"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 43s 15ms/step - loss: 0.7996 - crf_marginal_accuracy: 0.5780 - val_loss: 0.6023 - val_crf_marginal_accuracy: 0.9577\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5411 - crf_marginal_accuracy: 0.9492 - val_loss: 0.4425 - val_crf_marginal_accuracy: 0.9568\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.4049 - crf_marginal_accuracy: 0.9545 - val_loss: 0.3401 - val_crf_marginal_accuracy: 0.9477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cofffkTqMMEK",
        "outputId": "d7add6bf-2683-492f-a5dd-a618f1947794"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.0000    0.0000    0.0000       150\n",
            " I-DOCAGRDATE     0.0000    0.0000    0.0000        88\n",
            "  B-DOCAGRNUM     0.0008    0.0056    0.0013       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.0615    0.8294    0.1145      1243\n",
            "  I-DOCAMOUNT     0.0000    0.0000    0.0000       620\n",
            "    B-DOCCPTY     0.0642    0.6286    0.1165       595\n",
            "    I-DOCCPTY     0.0000    0.0000    0.0000       564\n",
            " B-DOCCPTYINN     0.0000    0.0000    0.0000       282\n",
            "B-DOCCUSTOMER     0.0481    0.1839    0.0763       609\n",
            "I-DOCCUSTOMER     0.8505    0.3571    0.5030       462\n",
            "    B-DOCDATE     0.1011    0.4620    0.1659       645\n",
            "    I-DOCDATE     0.3557    0.5686    0.4377       605\n",
            "     B-DOCNUM     0.4756    0.3886    0.4277       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.0834    0.3848    0.1371      6700\n",
            "    macro avg     0.1305    0.2283    0.1229      6700\n",
            " weighted avg     0.1682    0.3848    0.1703      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9pIp5Zpjqo"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKFIa_0IMMEL",
        "outputId": "fdc82936-b2c0-4ab0-9cb9-881f85b19cdb"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_6 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 1,240,150\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSFEq-vMMEL",
        "outputId": "629f89bf-4641-4758-bc2d-b4aba5106a27"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 42s 15ms/step - loss: 0.8119 - crf_marginal_accuracy: 0.1154 - val_loss: 0.6221 - val_crf_marginal_accuracy: 0.8025\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.5348 - crf_marginal_accuracy: 0.2231 - val_loss: 0.3944 - val_crf_marginal_accuracy: 0.8941\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3438 - crf_marginal_accuracy: 0.9376 - val_loss: 0.2690 - val_crf_marginal_accuracy: 0.9606\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2541 - crf_marginal_accuracy: 0.9644 - val_loss: 0.2149 - val_crf_marginal_accuracy: 0.9663\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2091 - crf_marginal_accuracy: 0.9677 - val_loss: 0.1809 - val_crf_marginal_accuracy: 0.9699\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1821 - crf_marginal_accuracy: 0.9694 - val_loss: 0.1622 - val_crf_marginal_accuracy: 0.9708\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1655 - crf_marginal_accuracy: 0.9750 - val_loss: 0.1511 - val_crf_marginal_accuracy: 0.9735\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1521 - crf_marginal_accuracy: 0.9766 - val_loss: 0.1438 - val_crf_marginal_accuracy: 0.9756\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1422 - crf_marginal_accuracy: 0.9779 - val_loss: 0.1350 - val_crf_marginal_accuracy: 0.9813\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1331 - crf_marginal_accuracy: 0.9799 - val_loss: 0.1302 - val_crf_marginal_accuracy: 0.9804\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1258 - crf_marginal_accuracy: 0.9817 - val_loss: 0.1270 - val_crf_marginal_accuracy: 0.9823\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1203 - crf_marginal_accuracy: 0.9824 - val_loss: 0.1251 - val_crf_marginal_accuracy: 0.9801\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1155 - crf_marginal_accuracy: 0.9836 - val_loss: 0.1237 - val_crf_marginal_accuracy: 0.9858\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1125 - crf_marginal_accuracy: 0.9845 - val_loss: 0.1200 - val_crf_marginal_accuracy: 0.9853\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1071 - crf_marginal_accuracy: 0.9863 - val_loss: 0.1166 - val_crf_marginal_accuracy: 0.9847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-v-3tFMMEL",
        "outputId": "16ca3ffc-94e5-4b71-fa29-bd72c4e5eb5e"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.2329    0.5667    0.3301       150\n",
            " I-DOCAGRDATE     0.5431    0.7159    0.6176        88\n",
            "  B-DOCAGRNUM     0.3551    0.6369    0.4560       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.2534    0.7739    0.3818      1243\n",
            "  I-DOCAMOUNT     0.3079    0.8000    0.4446       620\n",
            "    B-DOCCPTY     0.5005    0.8672    0.6347       595\n",
            "    I-DOCCPTY     0.6462    0.8936    0.7500       564\n",
            " B-DOCCPTYINN     0.3796    0.9220    0.5377       282\n",
            "B-DOCCUSTOMER     0.4562    0.8883    0.6028       609\n",
            "I-DOCCUSTOMER     0.5298    0.9632    0.6836       462\n",
            "    B-DOCDATE     0.3298    0.8248    0.4712       645\n",
            "    I-DOCDATE     0.6376    0.9802    0.7726       605\n",
            "     B-DOCNUM     0.2767    0.6805    0.3934       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.3734    0.8290    0.5149      6700\n",
            "    macro avg     0.3632    0.7009    0.4718      6700\n",
            " weighted avg     0.4064    0.8290    0.5371      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Rxo5d1o93d"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGPObsQWal6"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDnQ8VNWal-",
        "outputId": "94fc9941-4e7e-41f7-80f3-8a5810d0630d"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_7 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 3,450,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqCw-lOWamB",
        "outputId": "11bcb9d6-7063-4d84-9f73-e901516a8acc"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 44s 15ms/step - loss: 0.8051 - crf_marginal_accuracy: 0.1195 - val_loss: 0.6141 - val_crf_marginal_accuracy: 0.8147\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5369 - crf_marginal_accuracy: 0.8713 - val_loss: 0.3980 - val_crf_marginal_accuracy: 0.9200\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3585 - crf_marginal_accuracy: 0.9483 - val_loss: 0.2807 - val_crf_marginal_accuracy: 0.9671\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2715 - crf_marginal_accuracy: 0.9674 - val_loss: 0.2284 - val_crf_marginal_accuracy: 0.9650\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2207 - crf_marginal_accuracy: 0.9689 - val_loss: 0.1927 - val_crf_marginal_accuracy: 0.9749\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1837 - crf_marginal_accuracy: 0.9760 - val_loss: 0.1668 - val_crf_marginal_accuracy: 0.9741\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1558 - crf_marginal_accuracy: 0.9791 - val_loss: 0.1491 - val_crf_marginal_accuracy: 0.9791\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1353 - crf_marginal_accuracy: 0.9830 - val_loss: 0.1370 - val_crf_marginal_accuracy: 0.9817\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1179 - crf_marginal_accuracy: 0.9855 - val_loss: 0.1261 - val_crf_marginal_accuracy: 0.9897\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1027 - crf_marginal_accuracy: 0.9879 - val_loss: 0.1183 - val_crf_marginal_accuracy: 0.9917\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0910 - crf_marginal_accuracy: 0.9914 - val_loss: 0.1138 - val_crf_marginal_accuracy: 0.9873\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0811 - crf_marginal_accuracy: 0.9921 - val_loss: 0.1085 - val_crf_marginal_accuracy: 0.9918\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0725 - crf_marginal_accuracy: 0.9935 - val_loss: 0.1088 - val_crf_marginal_accuracy: 0.9944\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0658 - crf_marginal_accuracy: 0.9950 - val_loss: 0.1078 - val_crf_marginal_accuracy: 0.9941\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0602 - crf_marginal_accuracy: 0.9955 - val_loss: 0.1077 - val_crf_marginal_accuracy: 0.9945\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0544 - crf_marginal_accuracy: 0.9962 - val_loss: 0.1052 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0504 - crf_marginal_accuracy: 0.9966 - val_loss: 0.1101 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0459 - crf_marginal_accuracy: 0.9970 - val_loss: 0.1107 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0429 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1161 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0398 - crf_marginal_accuracy: 0.9975 - val_loss: 0.1097 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0377 - crf_marginal_accuracy: 0.9977 - val_loss: 0.1104 - val_crf_marginal_accuracy: 0.9959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCujGbXWamC",
        "outputId": "c38d4dff-a2bf-4676-b80a-60898b87d4b6"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7090    0.6333    0.6690       150\n",
            " I-DOCAGRDATE     0.7416    0.7500    0.7458        88\n",
            "  B-DOCAGRNUM     0.5857    0.6872    0.6324       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.7106    0.6854    0.6978      1243\n",
            "  I-DOCAMOUNT     0.7516    0.5710    0.6489       620\n",
            "    B-DOCCPTY     0.8000    0.9076    0.8504       595\n",
            "    I-DOCCPTY     0.8257    0.8989    0.8608       564\n",
            " B-DOCCPTYINN     0.8810    0.9184    0.8993       282\n",
            "B-DOCCUSTOMER     0.9165    0.9015    0.9089       609\n",
            "I-DOCCUSTOMER     0.8459    0.9502    0.8950       462\n",
            "    B-DOCDATE     0.7926    0.8651    0.8273       645\n",
            "    I-DOCDATE     0.8428    0.9570    0.8963       605\n",
            "     B-DOCNUM     0.6849    0.6544    0.6693       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.7844    0.7981    0.7912      6700\n",
            "    macro avg     0.6725    0.6920    0.6801      6700\n",
            " weighted avg     0.7809    0.7981    0.7869      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1mf60mpD9t"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jRCZwwNWamC",
        "outputId": "6ea57dd7-bb9c-4fd0-f3e3-47bfd3fc96c6"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_8 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 3,325,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy3tg6aWamD",
        "outputId": "1ccb74fd-1d93-470c-ab7b-997c87cc224e"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 43s 15ms/step - loss: 0.7155 - crf_marginal_accuracy: 0.0766 - val_loss: 0.4706 - val_crf_marginal_accuracy: 0.1218\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.4088 - crf_marginal_accuracy: 0.8213 - val_loss: 0.3148 - val_crf_marginal_accuracy: 0.9399\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3034 - crf_marginal_accuracy: 0.9476 - val_loss: 0.2484 - val_crf_marginal_accuracy: 0.9595\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2486 - crf_marginal_accuracy: 0.9584 - val_loss: 0.2087 - val_crf_marginal_accuracy: 0.9615\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2117 - crf_marginal_accuracy: 0.9630 - val_loss: 0.1809 - val_crf_marginal_accuracy: 0.9632\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1870 - crf_marginal_accuracy: 0.9672 - val_loss: 0.1653 - val_crf_marginal_accuracy: 0.9686\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1695 - crf_marginal_accuracy: 0.9703 - val_loss: 0.1540 - val_crf_marginal_accuracy: 0.9721\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1567 - crf_marginal_accuracy: 0.9728 - val_loss: 0.1452 - val_crf_marginal_accuracy: 0.9715\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1451 - crf_marginal_accuracy: 0.9743 - val_loss: 0.1357 - val_crf_marginal_accuracy: 0.9761\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1363 - crf_marginal_accuracy: 0.9771 - val_loss: 0.1348 - val_crf_marginal_accuracy: 0.9804\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1343 - crf_marginal_accuracy: 0.9788 - val_loss: 0.1303 - val_crf_marginal_accuracy: 0.9724\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1269 - crf_marginal_accuracy: 0.9798 - val_loss: 0.1262 - val_crf_marginal_accuracy: 0.9796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuStVCRzWamD",
        "outputId": "bc161a4d-07ef-4dd9-eaa7-76f67a293807"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.2707    0.6333    0.3792       150\n",
            " I-DOCAGRDATE     0.3730    0.5341    0.4393        88\n",
            "  B-DOCAGRNUM     0.2243    0.6592    0.3348       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.1402    0.8142    0.2392      1243\n",
            "  I-DOCAMOUNT     0.3796    0.6919    0.4903       620\n",
            "    B-DOCCPTY     0.4909    0.8605    0.6252       595\n",
            "    I-DOCCPTY     0.4819    0.8493    0.6149       564\n",
            " B-DOCCPTYINN     0.1714    0.9504    0.2904       282\n",
            "B-DOCCUSTOMER     0.3422    0.8686    0.4910       609\n",
            "I-DOCCUSTOMER     0.5100    0.9372    0.6606       462\n",
            "    B-DOCDATE     0.3530    0.7318    0.4763       645\n",
            "    I-DOCDATE     0.6935    0.9686    0.8083       605\n",
            "     B-DOCNUM     0.3574    0.6621    0.4642       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.2888    0.8076    0.4255      6700\n",
            "    macro avg     0.3192    0.6774    0.4209      6700\n",
            " weighted avg     0.3671    0.8076    0.4866      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vELTeX7To1uV"
      },
      "source": [
        "## W2V(not fixed, window=5, max_vocab_size=15000) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBV_xu9jJ7O"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, max_vocab_size=15000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWAPWdOxjJ7P",
        "outputId": "6d089426-d9bd-4638-ddc1-3d60f860c342"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 943, 50)           238250    \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_9 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 362,826\n",
            "Trainable params: 362,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmtqjRfCjJ7c",
        "outputId": "2ff91b08-9c0f-4e0c-d23e-6fdcfebef0f7"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 45s 16ms/step - loss: 0.7793 - crf_marginal_accuracy: 0.2451 - val_loss: 0.5621 - val_crf_marginal_accuracy: 0.0712\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.5019 - crf_marginal_accuracy: 0.7804 - val_loss: 0.3784 - val_crf_marginal_accuracy: 0.9175\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3482 - crf_marginal_accuracy: 0.9454 - val_loss: 0.2692 - val_crf_marginal_accuracy: 0.9551\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2617 - crf_marginal_accuracy: 0.9578 - val_loss: 0.2135 - val_crf_marginal_accuracy: 0.9590\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2113 - crf_marginal_accuracy: 0.9626 - val_loss: 0.1788 - val_crf_marginal_accuracy: 0.9657\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1795 - crf_marginal_accuracy: 0.9657 - val_loss: 0.1594 - val_crf_marginal_accuracy: 0.9701\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1585 - crf_marginal_accuracy: 0.9722 - val_loss: 0.1445 - val_crf_marginal_accuracy: 0.9715\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1432 - crf_marginal_accuracy: 0.9739 - val_loss: 0.1351 - val_crf_marginal_accuracy: 0.9767\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1316 - crf_marginal_accuracy: 0.9760 - val_loss: 0.1276 - val_crf_marginal_accuracy: 0.9782\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1193 - crf_marginal_accuracy: 0.9799 - val_loss: 0.1204 - val_crf_marginal_accuracy: 0.9773\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1103 - crf_marginal_accuracy: 0.9814 - val_loss: 0.1162 - val_crf_marginal_accuracy: 0.9832\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1020 - crf_marginal_accuracy: 0.9853 - val_loss: 0.1094 - val_crf_marginal_accuracy: 0.9812\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0947 - crf_marginal_accuracy: 0.9855 - val_loss: 0.1070 - val_crf_marginal_accuracy: 0.9824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBqJIeRajJ7d",
        "outputId": "57419138-c47f-4656-c42a-f222b93e69d0"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.2073    0.6067    0.3090       150\n",
            " I-DOCAGRDATE     0.5492    0.7614    0.6381        88\n",
            "  B-DOCAGRNUM     0.2872    0.6145    0.3915       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.1751    0.8423    0.2899      1243\n",
            "  I-DOCAMOUNT     0.3390    0.6758    0.4515       620\n",
            "    B-DOCCPTY     0.4278    0.8958    0.5790       595\n",
            "    I-DOCCPTY     0.5349    0.9096    0.6737       564\n",
            " B-DOCCPTYINN     0.3703    0.9113    0.5266       282\n",
            "B-DOCCUSTOMER     0.6198    0.8966    0.7329       609\n",
            "I-DOCCUSTOMER     0.7008    0.9329    0.8004       462\n",
            "    B-DOCDATE     0.3279    0.8744    0.4770       645\n",
            "    I-DOCDATE     0.7016    0.9636    0.8120       605\n",
            "     B-DOCNUM     0.2926    0.6774    0.4087       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.3372    0.8361    0.4806      6700\n",
            "    macro avg     0.3689    0.7042    0.4727      6700\n",
            " weighted avg     0.4100    0.8361    0.5324      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewN4XiuiosKq"
      },
      "source": [
        "## W2V(fixed, window=5, max_vocab_size=15000) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaebcYB-jJ7d",
        "outputId": "1c178096-a5cd-4465-f6ad-60bf1f28cdb5"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 943, 50)           238250    \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_10 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 362,826\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 238,250\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk48dUX-jJ7e",
        "outputId": "11954d4c-2cd2-4d9e-9799-e36040d1963f"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 45s 16ms/step - loss: 0.7324 - crf_marginal_accuracy: 0.2027 - val_loss: 0.4870 - val_crf_marginal_accuracy: 0.1033\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.4326 - crf_marginal_accuracy: 0.6717 - val_loss: 0.3303 - val_crf_marginal_accuracy: 0.9370\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3191 - crf_marginal_accuracy: 0.9390 - val_loss: 0.2592 - val_crf_marginal_accuracy: 0.9487\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2568 - crf_marginal_accuracy: 0.9478 - val_loss: 0.2147 - val_crf_marginal_accuracy: 0.9415\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2175 - crf_marginal_accuracy: 0.9505 - val_loss: 0.1879 - val_crf_marginal_accuracy: 0.9582\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1932 - crf_marginal_accuracy: 0.9561 - val_loss: 0.1720 - val_crf_marginal_accuracy: 0.9620\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1756 - crf_marginal_accuracy: 0.9633 - val_loss: 0.1576 - val_crf_marginal_accuracy: 0.9623\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1627 - crf_marginal_accuracy: 0.9659 - val_loss: 0.1494 - val_crf_marginal_accuracy: 0.9618\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1518 - crf_marginal_accuracy: 0.9679 - val_loss: 0.1419 - val_crf_marginal_accuracy: 0.9715\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1438 - crf_marginal_accuracy: 0.9705 - val_loss: 0.1359 - val_crf_marginal_accuracy: 0.9783\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1360 - crf_marginal_accuracy: 0.9744 - val_loss: 0.1334 - val_crf_marginal_accuracy: 0.9706\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1296 - crf_marginal_accuracy: 0.9741 - val_loss: 0.1285 - val_crf_marginal_accuracy: 0.9691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRxCwd2njJ7e",
        "outputId": "68e7d623-28a2-4b20-a92c-60cceb2d2300"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.1492    0.6533    0.2429       150\n",
            " I-DOCAGRDATE     0.3315    0.6818    0.4461        88\n",
            "  B-DOCAGRNUM     0.1864    0.6872    0.2932       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.1455    0.7828    0.2454      1243\n",
            "  I-DOCAMOUNT     0.1515    0.6145    0.2431       620\n",
            "    B-DOCCPTY     0.3483    0.8353    0.4916       595\n",
            "    I-DOCCPTY     0.5185    0.8954    0.6567       564\n",
            " B-DOCCPTYINN     0.1888    0.9291    0.3138       282\n",
            "B-DOCCUSTOMER     0.5268    0.8883    0.6614       609\n",
            "I-DOCCUSTOMER     0.5321    0.9329    0.6777       462\n",
            "    B-DOCDATE     0.3143    0.7612    0.4449       645\n",
            "    I-DOCDATE     0.6949    0.9488    0.8022       605\n",
            "     B-DOCNUM     0.2883    0.6498    0.3994       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.2655    0.7999    0.3987      6700\n",
            "    macro avg     0.2917    0.6840    0.3946      6700\n",
            " weighted avg     0.3418    0.7999    0.4602      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM_XIWpKsCPI"
      },
      "source": [
        "## W2V(not fixed, window=25) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgm2UrFtuT9p"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=25, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si5Zc-UjuEN3",
        "outputId": "83411ac4-15fc-4e9c-c615-a2308b5624bf"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_11 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 1,364,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EN4RSuMuEN9",
        "outputId": "a2d5ce52-be7e-4325-8c07-1b01d8081a7f"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 47s 16ms/step - loss: 0.8186 - crf_marginal_accuracy: 0.4977 - val_loss: 0.6030 - val_crf_marginal_accuracy: 0.8677\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5151 - crf_marginal_accuracy: 0.9230 - val_loss: 0.3785 - val_crf_marginal_accuracy: 0.9493\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3439 - crf_marginal_accuracy: 0.9535 - val_loss: 0.2713 - val_crf_marginal_accuracy: 0.9643\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2601 - crf_marginal_accuracy: 0.9664 - val_loss: 0.2198 - val_crf_marginal_accuracy: 0.9627\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2130 - crf_marginal_accuracy: 0.9718 - val_loss: 0.1885 - val_crf_marginal_accuracy: 0.9704\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1817 - crf_marginal_accuracy: 0.9755 - val_loss: 0.1658 - val_crf_marginal_accuracy: 0.9685\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1577 - crf_marginal_accuracy: 0.9783 - val_loss: 0.1484 - val_crf_marginal_accuracy: 0.9787\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1379 - crf_marginal_accuracy: 0.9824 - val_loss: 0.1359 - val_crf_marginal_accuracy: 0.9846\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1215 - crf_marginal_accuracy: 0.9859 - val_loss: 0.1267 - val_crf_marginal_accuracy: 0.9828\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1081 - crf_marginal_accuracy: 0.9879 - val_loss: 0.1220 - val_crf_marginal_accuracy: 0.9905\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0954 - crf_marginal_accuracy: 0.9906 - val_loss: 0.1168 - val_crf_marginal_accuracy: 0.9923\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0844 - crf_marginal_accuracy: 0.9927 - val_loss: 0.1097 - val_crf_marginal_accuracy: 0.9926\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0747 - crf_marginal_accuracy: 0.9935 - val_loss: 0.1072 - val_crf_marginal_accuracy: 0.9929\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0671 - crf_marginal_accuracy: 0.9945 - val_loss: 0.1055 - val_crf_marginal_accuracy: 0.9947\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0600 - crf_marginal_accuracy: 0.9956 - val_loss: 0.1032 - val_crf_marginal_accuracy: 0.9948\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0542 - crf_marginal_accuracy: 0.9961 - val_loss: 0.1047 - val_crf_marginal_accuracy: 0.9949\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0493 - crf_marginal_accuracy: 0.9965 - val_loss: 0.1086 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0441 - crf_marginal_accuracy: 0.9970 - val_loss: 0.1080 - val_crf_marginal_accuracy: 0.9957\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0403 - crf_marginal_accuracy: 0.9973 - val_loss: 0.1104 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0372 - crf_marginal_accuracy: 0.9976 - val_loss: 0.1106 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0337 - crf_marginal_accuracy: 0.9978 - val_loss: 0.1103 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0309 - crf_marginal_accuracy: 0.9980 - val_loss: 0.1143 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9981 - val_loss: 0.1228 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 24/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0287 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1185 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 25/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0272 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1235 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 26/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0246 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1384 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 27/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0229 - crf_marginal_accuracy: 0.9986 - val_loss: 0.1312 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 28/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0207 - crf_marginal_accuracy: 0.9987 - val_loss: 0.1379 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 29/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0186 - crf_marginal_accuracy: 0.9988 - val_loss: 0.1455 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 30/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0175 - crf_marginal_accuracy: 0.9989 - val_loss: 0.1466 - val_crf_marginal_accuracy: 0.9968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGjQQcIDuEN9",
        "outputId": "b7d1c6e2-bc2a-496f-a248-a56ea7caded3"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7302    0.6133    0.6667       150\n",
            " I-DOCAGRDATE     0.7407    0.6818    0.7101        88\n",
            "  B-DOCAGRNUM     0.7708    0.6201    0.6873       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.8131    0.6372    0.7145      1243\n",
            "  I-DOCAMOUNT     0.7747    0.5435    0.6389       620\n",
            "    B-DOCCPTY     0.8921    0.8756    0.8838       595\n",
            "    I-DOCCPTY     0.8540    0.8918    0.8725       564\n",
            " B-DOCCPTYINN     0.9577    0.8830    0.9188       282\n",
            "B-DOCCUSTOMER     0.9513    0.8982    0.9240       609\n",
            "I-DOCCUSTOMER     0.9575    0.9264    0.9417       462\n",
            "    B-DOCDATE     0.8740    0.8171    0.8446       645\n",
            "    I-DOCDATE     0.8887    0.9372    0.9123       605\n",
            "     B-DOCNUM     0.8113    0.6406    0.7159       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8628    0.7688    0.8131      6700\n",
            "    macro avg     0.7344    0.6644    0.6954      6700\n",
            " weighted avg     0.8563    0.7688    0.8071      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtkZiRbasEsK"
      },
      "source": [
        "## GLOVE (not fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNrzxYz3ar3x",
        "outputId": "50e169b5-b195-45e2-a129-54b27c6b46ea"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "corpus = Corpus() \n",
        "corpus.fit(df['tokens'], window=15)\n",
        "\n",
        "glove = Glove(no_components=300, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtUIADA6a6h-",
        "outputId": "c484044c-f22b-4140-d80f-a2f270ec2f84"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 943, 300)          19955400  \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_12 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 20,279,976\n",
            "Trainable params: 20,279,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxAndSBa6iK",
        "outputId": "eb750725-ec07-4ef3-be26-5377e8cfdcba"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 48s 17ms/step - loss: 0.9013 - crf_marginal_accuracy: 0.0018 - val_loss: 0.7501 - val_crf_marginal_accuracy: 0.0026\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.6822 - crf_marginal_accuracy: 0.0039 - val_loss: 0.5428 - val_crf_marginal_accuracy: 0.0201\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.4689 - crf_marginal_accuracy: 0.5339 - val_loss: 0.3649 - val_crf_marginal_accuracy: 0.9177\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.3202 - crf_marginal_accuracy: 0.9549 - val_loss: 0.2745 - val_crf_marginal_accuracy: 0.9752\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2322 - crf_marginal_accuracy: 0.9796 - val_loss: 0.2123 - val_crf_marginal_accuracy: 0.9878\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1696 - crf_marginal_accuracy: 0.9886 - val_loss: 0.1767 - val_crf_marginal_accuracy: 0.9932\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1236 - crf_marginal_accuracy: 0.9928 - val_loss: 0.1575 - val_crf_marginal_accuracy: 0.9937\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0953 - crf_marginal_accuracy: 0.9951 - val_loss: 0.1513 - val_crf_marginal_accuracy: 0.9949\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0753 - crf_marginal_accuracy: 0.9964 - val_loss: 0.1454 - val_crf_marginal_accuracy: 0.9950\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0614 - crf_marginal_accuracy: 0.9969 - val_loss: 0.1526 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0504 - crf_marginal_accuracy: 0.9976 - val_loss: 0.1685 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0441 - crf_marginal_accuracy: 0.9979 - val_loss: 0.1742 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0373 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1701 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0336 - crf_marginal_accuracy: 0.9983 - val_loss: 0.1779 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9986 - val_loss: 0.1810 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0254 - crf_marginal_accuracy: 0.9987 - val_loss: 0.1918 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0225 - crf_marginal_accuracy: 0.9989 - val_loss: 0.2116 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0205 - crf_marginal_accuracy: 0.9990 - val_loss: 0.2114 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0174 - crf_marginal_accuracy: 0.9991 - val_loss: 0.2160 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0157 - crf_marginal_accuracy: 0.9992 - val_loss: 0.2401 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0139 - crf_marginal_accuracy: 0.9993 - val_loss: 0.2293 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0121 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2475 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 40s 14ms/step - loss: 0.0112 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2472 - val_crf_marginal_accuracy: 0.9967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fQo3JKAa6iL",
        "outputId": "e4e56f62-11b8-463a-9abf-11301f0b3040"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7252    0.6333    0.6762       150\n",
            " I-DOCAGRDATE     0.6542    0.7955    0.7179        88\n",
            "  B-DOCAGRNUM     0.7925    0.4693    0.5895       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.8304    0.5632    0.6711      1243\n",
            "  I-DOCAMOUNT     0.7613    0.4629    0.5757       620\n",
            "    B-DOCCPTY     0.9048    0.8471    0.8750       595\n",
            "    I-DOCCPTY     0.9241    0.8422    0.8813       564\n",
            " B-DOCCPTYINN     0.9673    0.8404    0.8994       282\n",
            "B-DOCCUSTOMER     0.9572    0.9540    0.9556       609\n",
            "I-DOCCUSTOMER     0.9236    0.9416    0.9325       462\n",
            "    B-DOCDATE     0.8804    0.8217    0.8500       645\n",
            "    I-DOCDATE     0.8640    0.9455    0.9029       605\n",
            "     B-DOCNUM     0.8467    0.6022    0.7038       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8728    0.7406    0.8013      6700\n",
            "    macro avg     0.7354    0.6479    0.6821      6700\n",
            " weighted avg     0.8651    0.7406    0.7908      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0LPCsrMoJYm"
      },
      "source": [
        "## GLOVE (fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7KzsnJxvbDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1372da0c-e578-4588-d8a1-b21ee1a06ba0"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 943, 300)          19955400  \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_13 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 20,279,976\n",
            "Trainable params: 324,576\n",
            "Non-trainable params: 19,955,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE_R3XoqvbDP",
        "outputId": "4e10df2d-b481-4949-d6c9-cb2e94553250"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 48s 17ms/step - loss: 0.8907 - crf_marginal_accuracy: 0.3582 - val_loss: 0.7714 - val_crf_marginal_accuracy: 0.8151\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.7298 - crf_marginal_accuracy: 0.1789 - val_loss: 0.6436 - val_crf_marginal_accuracy: 0.1215\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.6107 - crf_marginal_accuracy: 0.1124 - val_loss: 0.5278 - val_crf_marginal_accuracy: 0.1353\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5076 - crf_marginal_accuracy: 0.1212 - val_loss: 0.4371 - val_crf_marginal_accuracy: 0.2811\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.4291 - crf_marginal_accuracy: 0.8404 - val_loss: 0.3742 - val_crf_marginal_accuracy: 0.9145\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.3698 - crf_marginal_accuracy: 0.9441 - val_loss: 0.3213 - val_crf_marginal_accuracy: 0.9465\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3221 - crf_marginal_accuracy: 0.9503 - val_loss: 0.2816 - val_crf_marginal_accuracy: 0.9271\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2884 - crf_marginal_accuracy: 0.9476 - val_loss: 0.2540 - val_crf_marginal_accuracy: 0.9464\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2611 - crf_marginal_accuracy: 0.9520 - val_loss: 0.2327 - val_crf_marginal_accuracy: 0.9390\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2411 - crf_marginal_accuracy: 0.9496 - val_loss: 0.2188 - val_crf_marginal_accuracy: 0.9317\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2267 - crf_marginal_accuracy: 0.9495 - val_loss: 0.2050 - val_crf_marginal_accuracy: 0.9390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRQU0DDgvbDQ",
        "outputId": "28bd9411-d99d-4e2c-a543-b2269695d024"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.0000    0.0000    0.0000       150\n",
            " I-DOCAGRDATE     0.0000    0.0000    0.0000        88\n",
            "  B-DOCAGRNUM     0.0563    0.0894    0.0691       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.0366    0.7401    0.0697      1243\n",
            "  I-DOCAMOUNT     0.0549    0.0855    0.0669       620\n",
            "    B-DOCCPTY     0.2047    0.7143    0.3182       595\n",
            "    I-DOCCPTY     0.4160    0.4965    0.4527       564\n",
            " B-DOCCPTYINN     0.1605    0.6631    0.2585       282\n",
            "B-DOCCUSTOMER     0.2979    0.6125    0.4009       609\n",
            "I-DOCCUSTOMER     0.3786    0.7056    0.4928       462\n",
            "    B-DOCDATE     0.1041    0.5953    0.1772       645\n",
            "    I-DOCDATE     0.4078    0.7091    0.5178       605\n",
            "     B-DOCNUM     0.1888    0.5975    0.2870       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.0964    0.5645    0.1647      6700\n",
            "    macro avg     0.1538    0.4006    0.2074      6700\n",
            " weighted avg     0.1917    0.5645    0.2603      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWSpAUjhXbVN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}