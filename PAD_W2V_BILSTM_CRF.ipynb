{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "PAD_W2V_BILSTM_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g-czVy0ksd9",
        "outputId": "a9233eda-2125-4083-dba5-de90e8ffcb7f"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raJ-rDdCJt_",
        "outputId": "00349f5d-f393-4ea4-8dc0-9f7096875fe1"
      },
      "source": [
        "!pip install 'h5py<3.0.0'\n",
        "!pip install sklearn_crfsuite\n",
        "# !pip install tensorflow==1.15.2 keras==2.3.1\n",
        "!pip3 install glove-python-binary\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git --upgrade\n",
        "!pip install catboost"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting h5py<3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n",
            "Collecting glove-python-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/11/d8510a80110f736822856db566341dd2e1e7c3af536f77e409a6c09e0c22/glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-8ns25vb3\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-8ns25vb3\n",
            "Requirement already satisfied, skipping upgrade: keras in /tensorflow-1.15.2/python3.7 (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=e77904d72a5c8c04f22650eaf2a69ec5e0fa67c835999bd40567fea10658b81c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9cqxb86g/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/80/8e9c57ec32dfed6ba2922bc5c96462cbf8596ce1a6f5de532ad1e43e53fe/catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3MB)\n",
            "\u001b[K     |████████████████████████████████| 67.3MB 56kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.25.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx7wVx0OiYyv",
        "outputId": "f9319e97-7714-4dae-967f-01f10c16159d"
      },
      "source": [
        "!gdown --id 1cCXjHX9FAgouF0DWuWPO5qyBHVZDkXTQ\n",
        "!gdown --id 1RFNBRcly96omdpNtYlEK6O1EuQs3ux7t\n",
        "!gdown --id 1AnLqXtSyJNBK7YmwuW6L6z2OYhE4RPTV"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cCXjHX9FAgouF0DWuWPO5qyBHVZDkXTQ\n",
            "To: /content/NER_PAD_agg_test.csv\n",
            "2.92MB [00:00, 90.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RFNBRcly96omdpNtYlEK6O1EuQs3ux7t\n",
            "To: /content/NER_PAD_agg_train.csv\n",
            "11.7MB [00:00, 44.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AnLqXtSyJNBK7YmwuW6L6z2OYhE4RPTV\n",
            "To: /content/NER_PAD_agg.csv\n",
            "14.6MB [00:00, 46.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEfFyYZVph-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "944d83f7-3b69-47b6-8ecd-066032463ccc"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "import gensim.downloader as api\n",
        "import matplotlib.pyplot as plt\n",
        "from catboost import CatBoostClassifier\n",
        "from gensim.models import Word2Vec\n",
        "from glove import Corpus, Glove\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYiqiimi1vV"
      },
      "source": [
        "df = pd.read_csv('NER_PAD_agg.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "train = pd.read_csv('NER_PAD_agg_train.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "test = pd.read_csv('NER_PAD_agg_test.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "\n",
        "all_dfs = [df, train, test]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz_dGApGKoB"
      },
      "source": [
        "def find_token(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ', '']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in w2v.wv.vocab.keys():\n",
        "                res.append(w2v.wv.vocab[w + suffix].index)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "all_tags = set()\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "labels = list(tag_to_idx.keys())\n",
        "labels.remove('O')\n",
        "labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
        "int_labels = list(tag_to_idx.values())\n",
        "int_labels.remove(tag_to_idx['O'])\n",
        "int_labels = sorted(int_labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAl784dWnJkR"
      },
      "source": [
        "pretrained_w2v = api.load(\"word2vec-ruscorpora-300\")\n",
        "pretrained_w2v.save_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthif1zkvsok"
      },
      "source": [
        "def add_suffix(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in pretrained_w2v.vocab.keys():\n",
        "                res.append(w + suffix)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(w)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['tokens_with_suffix'] = d.apply(add_suffix, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rp-IeYsnJf"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v = Word2Vec(sentences=df['tokens_with_suffix'], size=300, window=15, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqqSfYYmY-p"
      },
      "source": [
        "w2v.intersect_word2vec_format('tmp')\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wxpfE8Hx0u"
      },
      "source": [
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "J7BswpbHlVW2",
        "outputId": "672d4988-7fd4-4103-97a8-8c39d426d070"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>tokens_with_suffix</th>\n",
              "      <th>encoded_ner_tags</th>\n",
              "      <th>int_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SV990125172_ОРГ__INM_18'09'58_1.pdf</td>\n",
              "      <td>[l, *, универсальный, приложение, №, 1, постан...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...</td>\n",
              "      <td>[l, *, универсальный_ADJ, приложение_NOUN, №, ...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 66, 494, 64, 1, 0, 83, 59, 94, 2904, 441, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SS528581_ОРГ__INM_17'05'39_A.pdf</td>\n",
              "      <td>[l, лист, согласования, стр., 1, 1, 2, 9, *, 0...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, лист_NOUN, согласования, стр., 1, 1, 2, 9,...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 47, 35, 193, 0, 0, 4, 41, 66, 11, 17, 113,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SF435712_ОРГ__INM_15'25'41_A.pdf</td>\n",
              "      <td>[l, приложение, №, постановлению, правительств...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-DOCNUM, B-DOCDAT...</td>\n",
              "      <td>[l, приложение_NOUN, №, постановлению, правите...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 7, 6, 13,...</td>\n",
              "      <td>[3, 64, 1, 83, 59, 290, 1752, 74, 1, 0, 133, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SV990124943_ОРГ__INM_19'00'43_A.pdf</td>\n",
              "      <td>[l, акционерное, общество, регистраторское, об...</td>\n",
              "      <td>[O, O, O, O, O, B-DOCCPTY, O, O, O, O, O, O, O...</td>\n",
              "      <td>[l, акционерное, общество_NOUN, регистраторско...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 3, 15, 15, 15, 15, 15, 15...</td>\n",
              "      <td>[3, 112, 43, 6621, 43, 1315, 0, 56, 80, 0, 189...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S29013419_ОРИГИНАЛ__IND_1_22.05.12'21'36.pdf</td>\n",
              "      <td>[l, *, 000стандарт, безопасности, адрес:, 1973...</td>\n",
              "      <td>[O, O, O, B-DOCCPTY, O, O, O, O, O, O, O, O, O...</td>\n",
              "      <td>[l, *, 000стандарт, безопасности, адрес:, 1973...</td>\n",
              "      <td>[15, 15, 15, 3, 15, 15, 15, 15, 15, 15, 15, 15...</td>\n",
              "      <td>[3, 66, 14721, 4486, 28, 2677, 277, 1137, 8911...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>SV990121575_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, стс, отчет, роялти, 2, к...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-DOCAGRNUM,...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, стс_NOUN, отчет_NOU...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 418, 970, 1293, 4, 1828, 1537, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>SV990121572_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, ао, стс, отчет, роялти, 3, квартал, лиценз...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, ао_NOUN, стс_NOUN, отчет_NOUN, роялти_NOUN...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 67, 418, 970, 1293, 14, 1828, 1537, 93, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>SV990121520_ОРГ__INM_16'31'06_3.pdf</td>\n",
              "      <td>[l, экземпляр, ао, стс, ао, стс, отчет, роялти...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...</td>\n",
              "      <td>[l, экземпляр_NOUN, ао_NOUN, стс_NOUN, ао_NOUN...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 67, 418, 67, 418, 970, 1293, 14, 1787...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>SV990121573_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, стс, отчет, п, роялти, 4...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, стс_NOUN, отчет_NOU...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 418, 970, 19, 1293, 17, 0, 16, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>SV990121764_ОРГ__INM_17'56'07_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, ао, стс, отчет, роялти, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, ао_NOUN, стс_NOUN, ...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 67, 418, 970, 1293, 17, 1828, 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                id  ...                                         int_tokens\n",
              "0              SV990125172_ОРГ__INM_18'09'58_1.pdf  ...  [3, 66, 494, 64, 1, 0, 83, 59, 94, 2904, 441, ...\n",
              "1                 SS528581_ОРГ__INM_17'05'39_A.pdf  ...  [3, 47, 35, 193, 0, 0, 4, 41, 66, 11, 17, 113,...\n",
              "2                 SF435712_ОРГ__INM_15'25'41_A.pdf  ...  [3, 64, 1, 83, 59, 290, 1752, 74, 1, 0, 133, 2...\n",
              "3              SV990124943_ОРГ__INM_19'00'43_A.pdf  ...  [3, 112, 43, 6621, 43, 1315, 0, 56, 80, 0, 189...\n",
              "4     S29013419_ОРИГИНАЛ__IND_1_22.05.12'21'36.pdf  ...  [3, 66, 14721, 4486, 28, 2677, 277, 1137, 8911...\n",
              "...                                            ...  ...                                                ...\n",
              "3995           SV990121575_ОРГ__INM_18'45'08_3.pdf  ...  [3, 361, 8542, 418, 970, 1293, 4, 1828, 1537, ...\n",
              "3996           SV990121572_ОРГ__INM_18'45'08_3.pdf  ...  [3, 67, 418, 970, 1293, 14, 1828, 1537, 93, 1,...\n",
              "3997           SV990121520_ОРГ__INM_16'31'06_3.pdf  ...  [3, 361, 67, 418, 67, 418, 970, 1293, 14, 1787...\n",
              "3998           SV990121573_ОРГ__INM_18'45'08_3.pdf  ...  [3, 361, 8542, 418, 970, 19, 1293, 17, 0, 16, ...\n",
              "3999           SV990121764_ОРГ__INM_17'56'07_3.pdf  ...  [3, 361, 8542, 67, 418, 970, 1293, 17, 1828, 2...\n",
              "\n",
              "[4000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QUuM6AhjxyK"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBokW5kspLO"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=1.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JNx5ntzrHuK"
      },
      "source": [
        "## PRETRAINED W2V(not fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1S7oW2BWoX",
        "outputId": "4dda30a0-9d48-4bea-ec6f-3f41e6141f9e"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 7,765,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVZ0buRG02d",
        "outputId": "56b4ab23-0b7d-4b07-db10-5c954a1051bd"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 42s 15ms/step - loss: 0.7843 - crf_marginal_accuracy: 0.2648 - val_loss: 0.6091 - val_crf_marginal_accuracy: 0.8945\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.5570 - crf_marginal_accuracy: 0.4671 - val_loss: 0.4561 - val_crf_marginal_accuracy: 0.1528\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.4077 - crf_marginal_accuracy: 0.7324 - val_loss: 0.3206 - val_crf_marginal_accuracy: 0.9415\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2823 - crf_marginal_accuracy: 0.9513 - val_loss: 0.2279 - val_crf_marginal_accuracy: 0.9590\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2018 - crf_marginal_accuracy: 0.9687 - val_loss: 0.1798 - val_crf_marginal_accuracy: 0.9683\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.1508 - crf_marginal_accuracy: 0.9790 - val_loss: 0.1489 - val_crf_marginal_accuracy: 0.9835\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1154 - crf_marginal_accuracy: 0.9873 - val_loss: 0.1329 - val_crf_marginal_accuracy: 0.9911\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0918 - crf_marginal_accuracy: 0.9924 - val_loss: 0.1295 - val_crf_marginal_accuracy: 0.9934\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0763 - crf_marginal_accuracy: 0.9941 - val_loss: 0.1267 - val_crf_marginal_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0645 - crf_marginal_accuracy: 0.9958 - val_loss: 0.1261 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0561 - crf_marginal_accuracy: 0.9967 - val_loss: 0.1275 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0488 - crf_marginal_accuracy: 0.9971 - val_loss: 0.1371 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0436 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1413 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0393 - crf_marginal_accuracy: 0.9977 - val_loss: 0.1397 - val_crf_marginal_accuracy: 0.9963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNVGThAXHeL",
        "outputId": "d8c06f13-9243-4bb8-8d33-01d4b2c51808"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6794    0.5933    0.6335       150\n",
            " I-DOCAGRDATE     0.6455    0.8068    0.7172        88\n",
            "  B-DOCAGRNUM     0.6899    0.6089    0.6469       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.7548    0.5350    0.6262      1243\n",
            "  I-DOCAMOUNT     0.7153    0.5065    0.5930       620\n",
            "    B-DOCCPTY     0.8613    0.8874    0.8742       595\n",
            "    I-DOCCPTY     0.8724    0.8972    0.8846       564\n",
            " B-DOCCPTYINN     0.8170    0.9184    0.8648       282\n",
            "B-DOCCUSTOMER     0.9111    0.8916    0.9012       609\n",
            "I-DOCCUSTOMER     0.9326    0.9286    0.9306       462\n",
            "    B-DOCDATE     0.8528    0.8264    0.8394       645\n",
            "    I-DOCDATE     0.8561    0.9636    0.9067       605\n",
            "     B-DOCNUM     0.8995    0.6052    0.7236       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8331    0.7497    0.7892      6700\n",
            "    macro avg     0.6992    0.6646    0.6761      6700\n",
            " weighted avg     0.8266    0.7497    0.7795      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8_PPi6mrQe7"
      },
      "source": [
        "## PRETRAINED W2V(fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV6QMPc3cyy",
        "outputId": "aa167467-2cc7-4ece-b0ae-1bd7429b59c9"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 324,576\n",
            "Non-trainable params: 7,440,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19U1yO8c3czD",
        "outputId": "377dd469-e2c0-4f72-8d42-af99f46e74ee"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 40s 14ms/step - loss: 0.7059 - crf_marginal_accuracy: 0.0202 - val_loss: 0.4837 - val_crf_marginal_accuracy: 0.8589\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.4329 - crf_marginal_accuracy: 0.7772 - val_loss: 0.3297 - val_crf_marginal_accuracy: 0.9113\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3150 - crf_marginal_accuracy: 0.9315 - val_loss: 0.2545 - val_crf_marginal_accuracy: 0.9360\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2577 - crf_marginal_accuracy: 0.9472 - val_loss: 0.2153 - val_crf_marginal_accuracy: 0.9522\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2233 - crf_marginal_accuracy: 0.9555 - val_loss: 0.1925 - val_crf_marginal_accuracy: 0.9511\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1989 - crf_marginal_accuracy: 0.9563 - val_loss: 0.1797 - val_crf_marginal_accuracy: 0.9571\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1805 - crf_marginal_accuracy: 0.9590 - val_loss: 0.1680 - val_crf_marginal_accuracy: 0.9595\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1662 - crf_marginal_accuracy: 0.9616 - val_loss: 0.1587 - val_crf_marginal_accuracy: 0.9582\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1539 - crf_marginal_accuracy: 0.9648 - val_loss: 0.1530 - val_crf_marginal_accuracy: 0.9641\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1435 - crf_marginal_accuracy: 0.9674 - val_loss: 0.1448 - val_crf_marginal_accuracy: 0.9694\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1332 - crf_marginal_accuracy: 0.9706 - val_loss: 0.1395 - val_crf_marginal_accuracy: 0.9714\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1249 - crf_marginal_accuracy: 0.9731 - val_loss: 0.1364 - val_crf_marginal_accuracy: 0.9758\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1170 - crf_marginal_accuracy: 0.9756 - val_loss: 0.1336 - val_crf_marginal_accuracy: 0.9771\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1113 - crf_marginal_accuracy: 0.9785 - val_loss: 0.1293 - val_crf_marginal_accuracy: 0.9788\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1071 - crf_marginal_accuracy: 0.9804 - val_loss: 0.1286 - val_crf_marginal_accuracy: 0.9825\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1051 - crf_marginal_accuracy: 0.9813 - val_loss: 0.1270 - val_crf_marginal_accuracy: 0.9823\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1001 - crf_marginal_accuracy: 0.9834 - val_loss: 0.1222 - val_crf_marginal_accuracy: 0.9848\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0947 - crf_marginal_accuracy: 0.9840 - val_loss: 0.1207 - val_crf_marginal_accuracy: 0.9852\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0904 - crf_marginal_accuracy: 0.9859 - val_loss: 0.1225 - val_crf_marginal_accuracy: 0.9882\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0863 - crf_marginal_accuracy: 0.9872 - val_loss: 0.1179 - val_crf_marginal_accuracy: 0.9860\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0825 - crf_marginal_accuracy: 0.9873 - val_loss: 0.1227 - val_crf_marginal_accuracy: 0.9910\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0806 - crf_marginal_accuracy: 0.9885 - val_loss: 0.1185 - val_crf_marginal_accuracy: 0.9887\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0775 - crf_marginal_accuracy: 0.9895 - val_loss: 0.1160 - val_crf_marginal_accuracy: 0.9881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU37zLsF3czD",
        "outputId": "e9247091-2863-448a-ff86-e11901312b16"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.3111    0.5600    0.4000       150\n",
            " I-DOCAGRDATE     0.5426    0.7955    0.6452        88\n",
            "  B-DOCAGRNUM     0.2834    0.6760    0.3993       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.3086    0.7385    0.4353      1243\n",
            "  I-DOCAMOUNT     0.4029    0.8565    0.5480       620\n",
            "    B-DOCCPTY     0.4643    0.8420    0.5986       595\n",
            "    I-DOCCPTY     0.6881    0.8528    0.7617       564\n",
            " B-DOCCPTYINN     0.5408    0.8936    0.6738       282\n",
            "B-DOCCUSTOMER     0.7301    0.8752    0.7961       609\n",
            "I-DOCCUSTOMER     0.7712    0.9264    0.8417       462\n",
            "    B-DOCDATE     0.5693    0.7705    0.6548       645\n",
            "    I-DOCDATE     0.7568    0.9719    0.8509       605\n",
            "     B-DOCNUM     0.6560    0.6298    0.6426       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.4957    0.8081    0.6144      6700\n",
            "    macro avg     0.4683    0.6926    0.5499      6700\n",
            " weighted avg     0.5445    0.8081    0.6379      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0M6U9bFpeSI"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRins3GMDd-"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYv7a7bMMEI",
        "outputId": "5cf862b4-b74f-4bda-a268-d87467f8e31b"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_5 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 1,364,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9AHayBOMMEK",
        "outputId": "f2274436-5e80-42b3-f705-f0e9c1c6b91d"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 43s 15ms/step - loss: 0.7996 - crf_marginal_accuracy: 0.5780 - val_loss: 0.6023 - val_crf_marginal_accuracy: 0.9577\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5411 - crf_marginal_accuracy: 0.9492 - val_loss: 0.4425 - val_crf_marginal_accuracy: 0.9568\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.4049 - crf_marginal_accuracy: 0.9545 - val_loss: 0.3401 - val_crf_marginal_accuracy: 0.9477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cofffkTqMMEK",
        "outputId": "d7add6bf-2683-492f-a5dd-a618f1947794"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.0000    0.0000    0.0000       150\n",
            " I-DOCAGRDATE     0.0000    0.0000    0.0000        88\n",
            "  B-DOCAGRNUM     0.0008    0.0056    0.0013       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.0615    0.8294    0.1145      1243\n",
            "  I-DOCAMOUNT     0.0000    0.0000    0.0000       620\n",
            "    B-DOCCPTY     0.0642    0.6286    0.1165       595\n",
            "    I-DOCCPTY     0.0000    0.0000    0.0000       564\n",
            " B-DOCCPTYINN     0.0000    0.0000    0.0000       282\n",
            "B-DOCCUSTOMER     0.0481    0.1839    0.0763       609\n",
            "I-DOCCUSTOMER     0.8505    0.3571    0.5030       462\n",
            "    B-DOCDATE     0.1011    0.4620    0.1659       645\n",
            "    I-DOCDATE     0.3557    0.5686    0.4377       605\n",
            "     B-DOCNUM     0.4756    0.3886    0.4277       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.0834    0.3848    0.1371      6700\n",
            "    macro avg     0.1305    0.2283    0.1229      6700\n",
            " weighted avg     0.1682    0.3848    0.1703      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9pIp5Zpjqo"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKFIa_0IMMEL",
        "outputId": "fdc82936-b2c0-4ab0-9cb9-881f85b19cdb"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_6 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 1,240,150\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSFEq-vMMEL",
        "outputId": "629f89bf-4641-4758-bc2d-b4aba5106a27"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 42s 15ms/step - loss: 0.8119 - crf_marginal_accuracy: 0.1154 - val_loss: 0.6221 - val_crf_marginal_accuracy: 0.8025\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.5348 - crf_marginal_accuracy: 0.2231 - val_loss: 0.3944 - val_crf_marginal_accuracy: 0.8941\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3438 - crf_marginal_accuracy: 0.9376 - val_loss: 0.2690 - val_crf_marginal_accuracy: 0.9606\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2541 - crf_marginal_accuracy: 0.9644 - val_loss: 0.2149 - val_crf_marginal_accuracy: 0.9663\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2091 - crf_marginal_accuracy: 0.9677 - val_loss: 0.1809 - val_crf_marginal_accuracy: 0.9699\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1821 - crf_marginal_accuracy: 0.9694 - val_loss: 0.1622 - val_crf_marginal_accuracy: 0.9708\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1655 - crf_marginal_accuracy: 0.9750 - val_loss: 0.1511 - val_crf_marginal_accuracy: 0.9735\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1521 - crf_marginal_accuracy: 0.9766 - val_loss: 0.1438 - val_crf_marginal_accuracy: 0.9756\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1422 - crf_marginal_accuracy: 0.9779 - val_loss: 0.1350 - val_crf_marginal_accuracy: 0.9813\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1331 - crf_marginal_accuracy: 0.9799 - val_loss: 0.1302 - val_crf_marginal_accuracy: 0.9804\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1258 - crf_marginal_accuracy: 0.9817 - val_loss: 0.1270 - val_crf_marginal_accuracy: 0.9823\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1203 - crf_marginal_accuracy: 0.9824 - val_loss: 0.1251 - val_crf_marginal_accuracy: 0.9801\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1155 - crf_marginal_accuracy: 0.9836 - val_loss: 0.1237 - val_crf_marginal_accuracy: 0.9858\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1125 - crf_marginal_accuracy: 0.9845 - val_loss: 0.1200 - val_crf_marginal_accuracy: 0.9853\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1071 - crf_marginal_accuracy: 0.9863 - val_loss: 0.1166 - val_crf_marginal_accuracy: 0.9847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-v-3tFMMEL",
        "outputId": "16ca3ffc-94e5-4b71-fa29-bd72c4e5eb5e"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.2329    0.5667    0.3301       150\n",
            " I-DOCAGRDATE     0.5431    0.7159    0.6176        88\n",
            "  B-DOCAGRNUM     0.3551    0.6369    0.4560       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.2534    0.7739    0.3818      1243\n",
            "  I-DOCAMOUNT     0.3079    0.8000    0.4446       620\n",
            "    B-DOCCPTY     0.5005    0.8672    0.6347       595\n",
            "    I-DOCCPTY     0.6462    0.8936    0.7500       564\n",
            " B-DOCCPTYINN     0.3796    0.9220    0.5377       282\n",
            "B-DOCCUSTOMER     0.4562    0.8883    0.6028       609\n",
            "I-DOCCUSTOMER     0.5298    0.9632    0.6836       462\n",
            "    B-DOCDATE     0.3298    0.8248    0.4712       645\n",
            "    I-DOCDATE     0.6376    0.9802    0.7726       605\n",
            "     B-DOCNUM     0.2767    0.6805    0.3934       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.3734    0.8290    0.5149      6700\n",
            "    macro avg     0.3632    0.7009    0.4718      6700\n",
            " weighted avg     0.4064    0.8290    0.5371      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKJI4oy3hzMT"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=5, min_count=2) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id2BNTd0n0-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87019e3b-cd7d-4c14-d398-d93a2a223715"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZbGJKwZwPNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d07909-d73e-41fd-8771-f4ed428e053d"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFFhboVQs9BR"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OamBx6BudKo",
        "outputId": "990510e4-9449-4e5b-f13e-5a1d1e892adc"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7111    0.4267    0.5333       150\n",
            " I-DOCAGRDATE     0.8028    0.6477    0.7170        88\n",
            "  B-DOCAGRNUM     0.7951    0.5419    0.6445       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8944    0.6340    0.7420      1243\n",
            "  I-DOCAMOUNT     0.8079    0.5903    0.6822       620\n",
            "    B-DOCCPTY     0.8986    0.8336    0.8649       595\n",
            "    I-DOCCPTY     0.8971    0.8191    0.8563       564\n",
            " B-DOCCPTYINN     0.9643    0.8617    0.9101       282\n",
            "B-DOCCUSTOMER     0.9805    0.9080    0.9429       609\n",
            "I-DOCCUSTOMER     0.9387    0.9286    0.9336       462\n",
            "    B-DOCDATE     0.8794    0.7798    0.8266       645\n",
            "    I-DOCDATE     0.8691    0.8777    0.8734       605\n",
            "     B-DOCNUM     0.8860    0.6206    0.7299       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8923    0.7458    0.8125      6700\n",
            "    macro avg     0.8217    0.6694    0.7323      6700\n",
            " weighted avg     0.8884    0.7458    0.8068      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Rxo5d1o93d"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGPObsQWal6"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=1)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDnQ8VNWal-",
        "outputId": "94fc9941-4e7e-41f7-80f3-8a5810d0630d"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_7 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 3,450,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqCw-lOWamB",
        "outputId": "11bcb9d6-7063-4d84-9f73-e901516a8acc"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='window=5,min_count=1,best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('window=5,min_count=1,best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 44s 15ms/step - loss: 0.8051 - crf_marginal_accuracy: 0.1195 - val_loss: 0.6141 - val_crf_marginal_accuracy: 0.8147\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5369 - crf_marginal_accuracy: 0.8713 - val_loss: 0.3980 - val_crf_marginal_accuracy: 0.9200\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3585 - crf_marginal_accuracy: 0.9483 - val_loss: 0.2807 - val_crf_marginal_accuracy: 0.9671\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2715 - crf_marginal_accuracy: 0.9674 - val_loss: 0.2284 - val_crf_marginal_accuracy: 0.9650\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2207 - crf_marginal_accuracy: 0.9689 - val_loss: 0.1927 - val_crf_marginal_accuracy: 0.9749\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1837 - crf_marginal_accuracy: 0.9760 - val_loss: 0.1668 - val_crf_marginal_accuracy: 0.9741\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1558 - crf_marginal_accuracy: 0.9791 - val_loss: 0.1491 - val_crf_marginal_accuracy: 0.9791\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1353 - crf_marginal_accuracy: 0.9830 - val_loss: 0.1370 - val_crf_marginal_accuracy: 0.9817\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1179 - crf_marginal_accuracy: 0.9855 - val_loss: 0.1261 - val_crf_marginal_accuracy: 0.9897\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1027 - crf_marginal_accuracy: 0.9879 - val_loss: 0.1183 - val_crf_marginal_accuracy: 0.9917\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0910 - crf_marginal_accuracy: 0.9914 - val_loss: 0.1138 - val_crf_marginal_accuracy: 0.9873\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0811 - crf_marginal_accuracy: 0.9921 - val_loss: 0.1085 - val_crf_marginal_accuracy: 0.9918\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0725 - crf_marginal_accuracy: 0.9935 - val_loss: 0.1088 - val_crf_marginal_accuracy: 0.9944\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0658 - crf_marginal_accuracy: 0.9950 - val_loss: 0.1078 - val_crf_marginal_accuracy: 0.9941\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0602 - crf_marginal_accuracy: 0.9955 - val_loss: 0.1077 - val_crf_marginal_accuracy: 0.9945\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0544 - crf_marginal_accuracy: 0.9962 - val_loss: 0.1052 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0504 - crf_marginal_accuracy: 0.9966 - val_loss: 0.1101 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0459 - crf_marginal_accuracy: 0.9970 - val_loss: 0.1107 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0429 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1161 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0398 - crf_marginal_accuracy: 0.9975 - val_loss: 0.1097 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0377 - crf_marginal_accuracy: 0.9977 - val_loss: 0.1104 - val_crf_marginal_accuracy: 0.9959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCujGbXWamC",
        "outputId": "c38d4dff-a2bf-4676-b80a-60898b87d4b6"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7090    0.6333    0.6690       150\n",
            " I-DOCAGRDATE     0.7416    0.7500    0.7458        88\n",
            "  B-DOCAGRNUM     0.5857    0.6872    0.6324       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.7106    0.6854    0.6978      1243\n",
            "  I-DOCAMOUNT     0.7516    0.5710    0.6489       620\n",
            "    B-DOCCPTY     0.8000    0.9076    0.8504       595\n",
            "    I-DOCCPTY     0.8257    0.8989    0.8608       564\n",
            " B-DOCCPTYINN     0.8810    0.9184    0.8993       282\n",
            "B-DOCCUSTOMER     0.9165    0.9015    0.9089       609\n",
            "I-DOCCUSTOMER     0.8459    0.9502    0.8950       462\n",
            "    B-DOCDATE     0.7926    0.8651    0.8273       645\n",
            "    I-DOCDATE     0.8428    0.9570    0.8963       605\n",
            "     B-DOCNUM     0.6849    0.6544    0.6693       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.7844    0.7981    0.7912      6700\n",
            "    macro avg     0.6725    0.6920    0.6801      6700\n",
            " weighted avg     0.7809    0.7981    0.7869      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1mf60mpD9t"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jRCZwwNWamC",
        "outputId": "6ea57dd7-bb9c-4fd0-f3e3-47bfd3fc96c6"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_8 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 3,325,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy3tg6aWamD",
        "outputId": "1ccb74fd-1d93-470c-ab7b-997c87cc224e"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='window=5,min_count=1,best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('window=5,min_count=1,best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 43s 15ms/step - loss: 0.7155 - crf_marginal_accuracy: 0.0766 - val_loss: 0.4706 - val_crf_marginal_accuracy: 0.1218\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.4088 - crf_marginal_accuracy: 0.8213 - val_loss: 0.3148 - val_crf_marginal_accuracy: 0.9399\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3034 - crf_marginal_accuracy: 0.9476 - val_loss: 0.2484 - val_crf_marginal_accuracy: 0.9595\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2486 - crf_marginal_accuracy: 0.9584 - val_loss: 0.2087 - val_crf_marginal_accuracy: 0.9615\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2117 - crf_marginal_accuracy: 0.9630 - val_loss: 0.1809 - val_crf_marginal_accuracy: 0.9632\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1870 - crf_marginal_accuracy: 0.9672 - val_loss: 0.1653 - val_crf_marginal_accuracy: 0.9686\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1695 - crf_marginal_accuracy: 0.9703 - val_loss: 0.1540 - val_crf_marginal_accuracy: 0.9721\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1567 - crf_marginal_accuracy: 0.9728 - val_loss: 0.1452 - val_crf_marginal_accuracy: 0.9715\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1451 - crf_marginal_accuracy: 0.9743 - val_loss: 0.1357 - val_crf_marginal_accuracy: 0.9761\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1363 - crf_marginal_accuracy: 0.9771 - val_loss: 0.1348 - val_crf_marginal_accuracy: 0.9804\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1343 - crf_marginal_accuracy: 0.9788 - val_loss: 0.1303 - val_crf_marginal_accuracy: 0.9724\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1269 - crf_marginal_accuracy: 0.9798 - val_loss: 0.1262 - val_crf_marginal_accuracy: 0.9796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuStVCRzWamD",
        "outputId": "bc161a4d-07ef-4dd9-eaa7-76f67a293807"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.2707    0.6333    0.3792       150\n",
            " I-DOCAGRDATE     0.3730    0.5341    0.4393        88\n",
            "  B-DOCAGRNUM     0.2243    0.6592    0.3348       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.1402    0.8142    0.2392      1243\n",
            "  I-DOCAMOUNT     0.3796    0.6919    0.4903       620\n",
            "    B-DOCCPTY     0.4909    0.8605    0.6252       595\n",
            "    I-DOCCPTY     0.4819    0.8493    0.6149       564\n",
            " B-DOCCPTYINN     0.1714    0.9504    0.2904       282\n",
            "B-DOCCUSTOMER     0.3422    0.8686    0.4910       609\n",
            "I-DOCCUSTOMER     0.5100    0.9372    0.6606       462\n",
            "    B-DOCDATE     0.3530    0.7318    0.4763       645\n",
            "    I-DOCDATE     0.6935    0.9686    0.8083       605\n",
            "     B-DOCNUM     0.3574    0.6621    0.4642       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.2888    0.8076    0.4255      6700\n",
            "    macro avg     0.3192    0.6774    0.4209      6700\n",
            " weighted avg     0.3671    0.8076    0.4866      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL_5lS1paJ1a"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=5, min_count=1) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFV0gNT-aJ1a",
        "outputId": "e6ca564b-0294-40c2-edb7-800ab7f56dcf"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7-nO8i6aJ1a",
        "outputId": "a8acfdf7-1420-4165-f7c1-6dab1ee7ff6e"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swuyMDFUaJ1a"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKofLJ1uaJ1b",
        "outputId": "97124c0f-ed48-4e19-f895-0b9c0d6169aa"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6951    0.3800    0.4914       150\n",
            " I-DOCAGRDATE     0.7536    0.5909    0.6624        88\n",
            "  B-DOCAGRNUM     0.7611    0.4804    0.5890       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8804    0.6098    0.7205      1243\n",
            "  I-DOCAMOUNT     0.8186    0.5677    0.6705       620\n",
            "    B-DOCCPTY     0.8909    0.8101    0.8486       595\n",
            "    I-DOCCPTY     0.8745    0.7908    0.8305       564\n",
            " B-DOCCPTYINN     0.9492    0.8617    0.9033       282\n",
            "B-DOCCUSTOMER     0.9773    0.9179    0.9467       609\n",
            "I-DOCCUSTOMER     0.9283    0.9242    0.9262       462\n",
            "    B-DOCDATE     0.8795    0.7581    0.8143       645\n",
            "    I-DOCDATE     0.8645    0.8860    0.8751       605\n",
            "     B-DOCNUM     0.8874    0.5929    0.7109       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8853    0.7279    0.7989      6700\n",
            "    macro avg     0.8107    0.6495    0.7145      6700\n",
            " weighted avg     0.8804    0.7279    0.7916      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM_XIWpKsCPI"
      },
      "source": [
        "## W2V(not fixed, window=25) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgm2UrFtuT9p"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=25, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si5Zc-UjuEN3",
        "outputId": "83411ac4-15fc-4e9c-c615-a2308b5624bf"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_11 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 1,364,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EN4RSuMuEN9",
        "outputId": "a2d5ce52-be7e-4325-8c07-1b01d8081a7f"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 47s 16ms/step - loss: 0.8186 - crf_marginal_accuracy: 0.4977 - val_loss: 0.6030 - val_crf_marginal_accuracy: 0.8677\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5151 - crf_marginal_accuracy: 0.9230 - val_loss: 0.3785 - val_crf_marginal_accuracy: 0.9493\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3439 - crf_marginal_accuracy: 0.9535 - val_loss: 0.2713 - val_crf_marginal_accuracy: 0.9643\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2601 - crf_marginal_accuracy: 0.9664 - val_loss: 0.2198 - val_crf_marginal_accuracy: 0.9627\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2130 - crf_marginal_accuracy: 0.9718 - val_loss: 0.1885 - val_crf_marginal_accuracy: 0.9704\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1817 - crf_marginal_accuracy: 0.9755 - val_loss: 0.1658 - val_crf_marginal_accuracy: 0.9685\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1577 - crf_marginal_accuracy: 0.9783 - val_loss: 0.1484 - val_crf_marginal_accuracy: 0.9787\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1379 - crf_marginal_accuracy: 0.9824 - val_loss: 0.1359 - val_crf_marginal_accuracy: 0.9846\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1215 - crf_marginal_accuracy: 0.9859 - val_loss: 0.1267 - val_crf_marginal_accuracy: 0.9828\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1081 - crf_marginal_accuracy: 0.9879 - val_loss: 0.1220 - val_crf_marginal_accuracy: 0.9905\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0954 - crf_marginal_accuracy: 0.9906 - val_loss: 0.1168 - val_crf_marginal_accuracy: 0.9923\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0844 - crf_marginal_accuracy: 0.9927 - val_loss: 0.1097 - val_crf_marginal_accuracy: 0.9926\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0747 - crf_marginal_accuracy: 0.9935 - val_loss: 0.1072 - val_crf_marginal_accuracy: 0.9929\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0671 - crf_marginal_accuracy: 0.9945 - val_loss: 0.1055 - val_crf_marginal_accuracy: 0.9947\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0600 - crf_marginal_accuracy: 0.9956 - val_loss: 0.1032 - val_crf_marginal_accuracy: 0.9948\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0542 - crf_marginal_accuracy: 0.9961 - val_loss: 0.1047 - val_crf_marginal_accuracy: 0.9949\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0493 - crf_marginal_accuracy: 0.9965 - val_loss: 0.1086 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0441 - crf_marginal_accuracy: 0.9970 - val_loss: 0.1080 - val_crf_marginal_accuracy: 0.9957\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0403 - crf_marginal_accuracy: 0.9973 - val_loss: 0.1104 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0372 - crf_marginal_accuracy: 0.9976 - val_loss: 0.1106 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0337 - crf_marginal_accuracy: 0.9978 - val_loss: 0.1103 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0309 - crf_marginal_accuracy: 0.9980 - val_loss: 0.1143 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9981 - val_loss: 0.1228 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 24/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0287 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1185 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 25/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0272 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1235 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 26/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0246 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1384 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 27/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0229 - crf_marginal_accuracy: 0.9986 - val_loss: 0.1312 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 28/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0207 - crf_marginal_accuracy: 0.9987 - val_loss: 0.1379 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 29/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0186 - crf_marginal_accuracy: 0.9988 - val_loss: 0.1455 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 30/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0175 - crf_marginal_accuracy: 0.9989 - val_loss: 0.1466 - val_crf_marginal_accuracy: 0.9968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGjQQcIDuEN9",
        "outputId": "b7d1c6e2-bc2a-496f-a248-a56ea7caded3"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7302    0.6133    0.6667       150\n",
            " I-DOCAGRDATE     0.7407    0.6818    0.7101        88\n",
            "  B-DOCAGRNUM     0.7708    0.6201    0.6873       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.8131    0.6372    0.7145      1243\n",
            "  I-DOCAMOUNT     0.7747    0.5435    0.6389       620\n",
            "    B-DOCCPTY     0.8921    0.8756    0.8838       595\n",
            "    I-DOCCPTY     0.8540    0.8918    0.8725       564\n",
            " B-DOCCPTYINN     0.9577    0.8830    0.9188       282\n",
            "B-DOCCUSTOMER     0.9513    0.8982    0.9240       609\n",
            "I-DOCCUSTOMER     0.9575    0.9264    0.9417       462\n",
            "    B-DOCDATE     0.8740    0.8171    0.8446       645\n",
            "    I-DOCDATE     0.8887    0.9372    0.9123       605\n",
            "     B-DOCNUM     0.8113    0.6406    0.7159       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8628    0.7688    0.8131      6700\n",
            "    macro avg     0.7344    0.6644    0.6954      6700\n",
            " weighted avg     0.8563    0.7688    0.8071      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpLPjaElaOZH"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=20) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wywjpjwaeB_Z"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=15, window=20, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iksvgnyyaOZH",
        "outputId": "87b343fd-f477-4b5c-fde3-fedcfed12252"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgY_iTw6aOZI",
        "outputId": "9533d0d0-a13b-4258-e9b0-4390c64c5afb"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jsvElhRaOZI"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsP5GT8daOZI",
        "outputId": "33955d8f-e2af-45f7-b4d7-c709f05be77b"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7303    0.4333    0.5439       150\n",
            " I-DOCAGRDATE     0.8194    0.6705    0.7375        88\n",
            "  B-DOCAGRNUM     0.7521    0.4916    0.5946       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.9232    0.6187    0.7408      1243\n",
            "  I-DOCAMOUNT     0.8409    0.5968    0.6981       620\n",
            "    B-DOCCPTY     0.8799    0.8000    0.8380       595\n",
            "    I-DOCCPTY     0.9214    0.8316    0.8742       564\n",
            " B-DOCCPTYINN     0.9567    0.8617    0.9067       282\n",
            "B-DOCCUSTOMER     0.9755    0.8489    0.9078       609\n",
            "I-DOCCUSTOMER     0.9677    0.9091    0.9375       462\n",
            "    B-DOCDATE     0.9004    0.7426    0.8139       645\n",
            "    I-DOCDATE     0.9276    0.9322    0.9299       605\n",
            "     B-DOCNUM     0.9493    0.6037    0.7380       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.9143    0.7337    0.8141      6700\n",
            "    macro avg     0.8363    0.6608    0.7326      6700\n",
            " weighted avg     0.9114    0.7337    0.8079      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtkZiRbasEsK"
      },
      "source": [
        "## GLOVE (not fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNrzxYz3ar3x",
        "outputId": "77c10a8a-f7d7-4f86-a9a0-3148881e3422"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=5)\n",
        "\n",
        "glove = Glove(no_components=50, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtUIADA6a6h-",
        "outputId": "c484044c-f22b-4140-d80f-a2f270ec2f84"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 943, 300)          19955400  \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_12 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 20,279,976\n",
            "Trainable params: 20,279,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxAndSBa6iK",
        "outputId": "eb750725-ec07-4ef3-be26-5377e8cfdcba"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 48s 17ms/step - loss: 0.9013 - crf_marginal_accuracy: 0.0018 - val_loss: 0.7501 - val_crf_marginal_accuracy: 0.0026\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.6822 - crf_marginal_accuracy: 0.0039 - val_loss: 0.5428 - val_crf_marginal_accuracy: 0.0201\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.4689 - crf_marginal_accuracy: 0.5339 - val_loss: 0.3649 - val_crf_marginal_accuracy: 0.9177\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.3202 - crf_marginal_accuracy: 0.9549 - val_loss: 0.2745 - val_crf_marginal_accuracy: 0.9752\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2322 - crf_marginal_accuracy: 0.9796 - val_loss: 0.2123 - val_crf_marginal_accuracy: 0.9878\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1696 - crf_marginal_accuracy: 0.9886 - val_loss: 0.1767 - val_crf_marginal_accuracy: 0.9932\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1236 - crf_marginal_accuracy: 0.9928 - val_loss: 0.1575 - val_crf_marginal_accuracy: 0.9937\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0953 - crf_marginal_accuracy: 0.9951 - val_loss: 0.1513 - val_crf_marginal_accuracy: 0.9949\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0753 - crf_marginal_accuracy: 0.9964 - val_loss: 0.1454 - val_crf_marginal_accuracy: 0.9950\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0614 - crf_marginal_accuracy: 0.9969 - val_loss: 0.1526 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0504 - crf_marginal_accuracy: 0.9976 - val_loss: 0.1685 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0441 - crf_marginal_accuracy: 0.9979 - val_loss: 0.1742 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0373 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1701 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0336 - crf_marginal_accuracy: 0.9983 - val_loss: 0.1779 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9986 - val_loss: 0.1810 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0254 - crf_marginal_accuracy: 0.9987 - val_loss: 0.1918 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0225 - crf_marginal_accuracy: 0.9989 - val_loss: 0.2116 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0205 - crf_marginal_accuracy: 0.9990 - val_loss: 0.2114 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0174 - crf_marginal_accuracy: 0.9991 - val_loss: 0.2160 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0157 - crf_marginal_accuracy: 0.9992 - val_loss: 0.2401 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0139 - crf_marginal_accuracy: 0.9993 - val_loss: 0.2293 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0121 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2475 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 40s 14ms/step - loss: 0.0112 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2472 - val_crf_marginal_accuracy: 0.9967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fQo3JKAa6iL",
        "outputId": "e4e56f62-11b8-463a-9abf-11301f0b3040"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7252    0.6333    0.6762       150\n",
            " I-DOCAGRDATE     0.6542    0.7955    0.7179        88\n",
            "  B-DOCAGRNUM     0.7925    0.4693    0.5895       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.8304    0.5632    0.6711      1243\n",
            "  I-DOCAMOUNT     0.7613    0.4629    0.5757       620\n",
            "    B-DOCCPTY     0.9048    0.8471    0.8750       595\n",
            "    I-DOCCPTY     0.9241    0.8422    0.8813       564\n",
            " B-DOCCPTYINN     0.9673    0.8404    0.8994       282\n",
            "B-DOCCUSTOMER     0.9572    0.9540    0.9556       609\n",
            "I-DOCCUSTOMER     0.9236    0.9416    0.9325       462\n",
            "    B-DOCDATE     0.8804    0.8217    0.8500       645\n",
            "    I-DOCDATE     0.8640    0.9455    0.9029       605\n",
            "     B-DOCNUM     0.8467    0.6022    0.7038       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8728    0.7406    0.8013      6700\n",
            "    macro avg     0.7354    0.6479    0.6821      6700\n",
            " weighted avg     0.8651    0.7406    0.7908      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0LPCsrMoJYm"
      },
      "source": [
        "## GLOVE (fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7KzsnJxvbDN"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE_R3XoqvbDP"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQU0DDgvbDQ"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvYtfwsNzuZd"
      },
      "source": [
        "## GLOVE (fixed, window=5) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pCZ2NJ_zfvQ",
        "outputId": "d6e5df6e-2f51-4b05-b26c-ce1a0ff5b5cc"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJlUl4tnzfvb",
        "outputId": "7634715c-7844-441e-c406-f018e55c71e1"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_-CTKgczfvb"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBN8OPD0zfvb",
        "outputId": "9c4864a2-a804-48dd-be3f-853182916fde"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6897    0.4000    0.5063       150\n",
            " I-DOCAGRDATE     0.7121    0.5341    0.6104        88\n",
            "  B-DOCAGRNUM     0.7656    0.5475    0.6384       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8766    0.6002    0.7125      1243\n",
            "  I-DOCAMOUNT     0.8028    0.5645    0.6629       620\n",
            "    B-DOCCPTY     0.8942    0.8235    0.8574       595\n",
            "    I-DOCCPTY     0.8946    0.7979    0.8435       564\n",
            " B-DOCCPTYINN     0.9361    0.8830    0.9088       282\n",
            "B-DOCCUSTOMER     0.9777    0.9360    0.9564       609\n",
            "I-DOCCUSTOMER     0.9386    0.9264    0.9325       462\n",
            "    B-DOCDATE     0.8696    0.7550    0.8083       645\n",
            "    I-DOCDATE     0.8640    0.8926    0.8780       605\n",
            "     B-DOCNUM     0.8991    0.6022    0.7213       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8850    0.7330    0.8019      6700\n",
            "    macro avg     0.8080    0.6556    0.7176      6700\n",
            " weighted avg     0.8800    0.7330    0.7945      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mj6XiDy65yt"
      },
      "source": [
        "## GLOVE (fixed, window=10) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r-ARNPS61Ib",
        "outputId": "92a2e686-0786-445a-8ad8-bf9af909da07"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=10)\n",
        "\n",
        "glove = Glove(no_components=30, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjcyEbXN7GM0",
        "outputId": "66f979fa-76f1-43c0-8ac5-873ccef50f5c"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 10\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPYrbq2m7GM1",
        "outputId": "1863edf3-1e3f-4dad-9fbf-f0e370c175ce"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 10\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_V0-ls47GM1"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqI-aOY37GM1",
        "outputId": "2d2df68b-b448-44d9-bb3d-65b64489a46a"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6837    0.4467    0.5403       150\n",
            " I-DOCAGRDATE     0.7123    0.5909    0.6460        88\n",
            "  B-DOCAGRNUM     0.7339    0.5084    0.6007       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8851    0.6195    0.7288      1243\n",
            "  I-DOCAMOUNT     0.8423    0.6032    0.7030       620\n",
            "    B-DOCCPTY     0.8830    0.8118    0.8459       595\n",
            "    I-DOCCPTY     0.9036    0.8475    0.8747       564\n",
            " B-DOCCPTYINN     0.9643    0.8617    0.9101       282\n",
            "B-DOCCUSTOMER     0.9693    0.8801    0.9225       609\n",
            "I-DOCCUSTOMER     0.9591    0.9134    0.9357       462\n",
            "    B-DOCDATE     0.8966    0.7798    0.8342       645\n",
            "    I-DOCDATE     0.9066    0.9140    0.9103       605\n",
            "     B-DOCNUM     0.8968    0.6006    0.7194       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8964    0.7413    0.8115      6700\n",
            "    macro avg     0.8158    0.6633    0.7266      6700\n",
            " weighted avg     0.8921    0.7413    0.8055      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYzIBS7IjLwK"
      },
      "source": [
        "## GLOVE (fixed, window=25) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VICcoqOVjLwL",
        "outputId": "6e332dee-5857-43eb-fa1b-bf4eeb74454e"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=25)\n",
        "\n",
        "glove = Glove(no_components=10, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQncFeCOjLwL",
        "outputId": "074759ed-da24-4911-8478-6fedc0e1ee05"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMFCFVQWjLwL",
        "outputId": "12b0eac3-bb57-47c5-8a1e-2c53a8a6ec45"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0uYfrCUjLwL"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k600p1NVjLwM",
        "outputId": "35d2ae57-09e8-4ab3-a989-c7b2f6019cfc"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6264    0.3800    0.4730       150\n",
            " I-DOCAGRDATE     0.7703    0.6477    0.7037        88\n",
            "  B-DOCAGRNUM     0.7315    0.4413    0.5505       179\n",
            "  I-DOCAGRNUM     1.0000    0.4286    0.6000         7\n",
            "  B-DOCAMOUNT     0.9018    0.6058    0.7247      1243\n",
            "  I-DOCAMOUNT     0.8178    0.5935    0.6879       620\n",
            "    B-DOCCPTY     0.8587    0.7765    0.8155       595\n",
            "    I-DOCCPTY     0.8926    0.8103    0.8494       564\n",
            " B-DOCCPTYINN     0.9563    0.8546    0.9026       282\n",
            "B-DOCCUSTOMER     0.9677    0.8358    0.8969       609\n",
            "I-DOCCUSTOMER     0.9589    0.9091    0.9333       462\n",
            "    B-DOCDATE     0.8993    0.7612    0.8245       645\n",
            "    I-DOCDATE     0.9211    0.9256    0.9233       605\n",
            "     B-DOCNUM     0.9175    0.5975    0.7237       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8966    0.7233    0.8007      6700\n",
            "    macro avg     0.8146    0.6378    0.7073      6700\n",
            " weighted avg     0.8923    0.7233    0.7941      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBIZP9Wqn4Xe"
      },
      "source": [
        "## GLOVE (fixed, window=20) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtnxKj_ln4Xe",
        "outputId": "c2071c84-d3d4-4811-ad90-f1473830bc61"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=20)\n",
        "\n",
        "glove = Glove(no_components=10, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9QiUfNKn4Xe",
        "outputId": "7d7dc265-001a-4b71-fe86-fb44d1fc07be"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6OkahAUn4Xf",
        "outputId": "335bce4a-f64e-4f7a-eefd-a85e6506b3fe"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Picoj7eUn4Xf"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7utYKHkHn4Xf",
        "outputId": "000bd8ff-c17b-4227-c292-3e99fd321d8f"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6250    0.3333    0.4348       150\n",
            " I-DOCAGRDATE     0.8154    0.6023    0.6928        88\n",
            "  B-DOCAGRNUM     0.7596    0.4413    0.5583       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8927    0.6026    0.7195      1243\n",
            "  I-DOCAMOUNT     0.8060    0.6032    0.6900       620\n",
            "    B-DOCCPTY     0.8835    0.7899    0.8341       595\n",
            "    I-DOCCPTY     0.8980    0.8121    0.8529       564\n",
            " B-DOCCPTYINN     0.9753    0.8404    0.9029       282\n",
            "B-DOCCUSTOMER     0.9610    0.8506    0.9024       609\n",
            "I-DOCCUSTOMER     0.9653    0.9026    0.9329       462\n",
            "    B-DOCDATE     0.8839    0.7318    0.8007       645\n",
            "    I-DOCDATE     0.9058    0.9058    0.9058       605\n",
            "     B-DOCNUM     0.9236    0.5945    0.7234       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8968    0.7188    0.7980      6700\n",
            "    macro avg     0.8197    0.6388    0.7118      6700\n",
            " weighted avg     0.8919    0.7188    0.7912      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl-kdToFKHn0"
      },
      "source": [
        "## Подбор гиперпараметров для CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxr9cm5gKNIx",
        "outputId": "9fec40d7-81c5-4120-ae51-c02dc577eeda"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "window_sizes = range(2, 25)\n",
        "EMBEDDING_LENGTH = 10\n",
        "\n",
        "for window_size in tqdm(window_sizes):\n",
        "    corpus = Corpus() \n",
        "\n",
        "    corpus.fit(df['tokens'], window=window_size)\n",
        "\n",
        "    glove = Glove(no_components=EMBEDDING_LENGTH, learning_rate=0.05) \n",
        "    glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=False)\n",
        "    glove.add_dictionary(corpus.dictionary)\n",
        "    for d in all_dfs:\n",
        "        d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "        d['int_tokens'] = d.apply(find_glove_token, axis=1)\n",
        "    \n",
        "    catboost_x_train = []\n",
        "    catboost_y_train = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_train.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    train.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    catboost_x_test = []\n",
        "    catboost_y_test = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_test.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    test.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "    cb.fit(catboost_x_train, catboost_y_train)\n",
        "    pred = cb.predict(catboost_x_test)\n",
        "    f1_scores.append(f1_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    precision_scores.append(precision_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    recall_scores.append(recall_score(catboost_y_test, pred, average='weighted', labels=int_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 23/23 [1:09:53<00:00, 182.33s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3kXaDebHr0FR",
        "outputId": "50627931-97c9-4963-c5ca-da5bfc76bc33"
      },
      "source": [
        "plt.plot(window_sizes, f1_scores, label='f1')\n",
        "plt.plot(window_sizes, precision_scores, label='precision')\n",
        "plt.plot(window_sizes, recall_scores, label='recall')\n",
        "plt.title('Metrics dependency on window size')\n",
        "plt.xlabel('Window size')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU5dn48e+dPWTfQzb2fREwoFRUEBTFWuvSuvbVqrXVaq1d7aq19vfWvmq1LdatbnWvrS0qVUQgCIoSEGQLENYskH1PJsvM8/vjnCRDSMgQZjIJ3J/rOtec/dxnMjn3eZ6zPGKMQSmllPJEgL8DUEopNXho0lBKKeUxTRpKKaU8pklDKaWUxzRpKKWU8pgmDaWUUh7TpKF6JSI/F5FnfLj+4SJiRCTIV9voCxG5T0Re8ncc/iQi9SIyso/LrhKRW7wdk4fb7nPc6tg0aQxSIrJfRFpEJLHL+M/tA/BwD9YxV0QKe5vPGPP/jDF++edX/mWMiTTG7PV3HMdrsMY9GGjSGNz2Ade0D4jIFGCINzcw0M7+lVL+pUljcPs78D9uwzcAL7rPICKhIvKQiBwUkRIReUJEwkUkAvgvkGYX5etFJM2uknlTRF4SkVrgxq7VNCIyR0Q+FpFqESkQkRvt8YtEZLuI1IlIkYj8qLugRSTQjqlcRPYCF3eZHiMifxORQ/Z6HhCRQHvajSKyVkT+IiI1IpInIvOPY9k19rarRGSfiFzktuwIEcmx4/8A6FqKO9NtvzeLyFy3aatE5Ld2bHUissy9FNjddyYiM+2/SaDbfJeLyOYevrcYEXlRRMpE5ICI/FJEAjzZty7r+aaIvO02vFtE/uE2XCAi0+x+IyKj7f7nRWSxiLxr7+OnIjLKbbnz7b9HjYj8BRC3aQF2vAdEpNTejxh72gsi8kO7P93e5nft4VEiUtm+n132Y7T996qxf0uvu00z9nT333e9iDSKiHGb7yYR2WF/Z++LyLDuvjPlxhij3SDsgP3AAmAnMAEIBAqBYYABhtvz/RFYAsQDUcDbwP/a0+YChV3Wex/QCnwV66Qi3B73kj19GFCHVcIJBhKAafa0Q8DZdn8cMKOH2L8D5AGZdlwr7ZiD7OlvAU8CEUAy8BnwbXvajUAbcLe9/auAGiDew2VbgW/Z39dtQDEg9vRPgEeAUOAcez/b9zsdqAAW2d/L+fZwkj19FbAHGGt/Z6uA33vwnW0HLnL7bt4CftjD9/Yi8B/77zgc2AXc7Mm+dVnPSKDa3o804ED778CeVgUE2MMGGG33P2/v8ywgCHgZeM2elmjv45X2Pt5t/51usaffBOTb648E/gX83W3a23b/tfb3+LrbtP/08H28CvzC3o8wYI7btI64uyzzMvCq3X+pHdMEe39+CXzs7//tgd75PQDt+viH60wavwT+F7gQ+MD+8Rv7oCJAAzDKbbnZwD67fy7dJ43V3YxrP3j+DHirh5gOAt8GonuJfQXwHbfhC+yYg4AUoBkId5t+DbDS7r+x68EQKzF8w8Nl892mDbG3mwpk2Qe5CLfpr7jt90/bD3Ju098HbrD7VwG/dJt2O/CeB9/ZT4GX7f54oBEY2s18gUALMNFt3LeBVb3tWw/bLQBmAFcDT9nf4Xjgm8ASt/m6Jo1n3KYtAvLs/v8B1rlNE6yTmPak8SFwu9v0cVhJLggYhZ2ogCfs/WpPYi8AP+hhH160Y8/oZtpRScP+rje0/z6wSto3u00PsL//Yf7+/x7InVZPDX5/xzo7u5EuVVNAEtbBY4NdLVINvGePP5aCY0zLxDoT7M4VWAeSA3a1wewe5kvrso0Dbv3DsM5UD7nF/CRWqaFdkbH/y92WT/Nw2cPtPcaYRrs30l6+yhjTcIy4vta+Xnvdc4Ch3a0b6+ATafcf6zt7CbhErOrCrwMfGWMOdTNfor1v7jEdwCoB9bZv3cnBOmk4x+5fBZxrdzk9LHPENjhyH4/4m9p/H/e/cXuJxj32ICDFGLMH6+RmGnA28A5QLCLjeonnJ1jJ6TMR2SYiN/UUtF1VdxfwVWNMkz16GPCY29+z0l5feg+rUVh/NDWIGWMOiMg+rIP1zV0mlwNNwCRjTFF3i/e02mNssgCreqK7WNYDl4pIMHAH8AbWAbOrQ13GZ3VZfzOQaIxp6yGGdBERt8SRhVUF58myPTkExIlIhFviyKLzuyjAKml86zjX275sT99ZkYh8AlyOVVr6aw/rKMc6Mx+GVaXVHl93f1dP5ACXACOA/4dVXXUdVkn0L31Y3xF/UxERjvwbF2PF3q69ZFfiFs+VQIj9neRgXaOLAzZ1t0FjzGGs6jhEZA6wXERWG2Py3eezk88LwOXGGPdEVgD8zhjz8nHu6ylNSxonh5uB87qcJWOMcQFPA38UkWTouNC40J6lBEhovyDpoZeBBSLydREJEpEEEZkmIiEicp2IxBhjWoFawNXDOt4AviciGSISB9zjFvMhYBnwsIhE2xdQR4nIuW7LJ9vLB4vI17DqpJd6uGy3jDEHgFzgN/a+zME6qLZrLxEsFOtCfphYtyxn9PU7c5v+ItZZ8xSsuv7u4nNifW+/E5Eo+4LtD+y4+iIHmIdVVVMIfIRVxZkAfN6H9b0LTBLrQn4Q8D2sar92rwJ3i3WzQSRWonrdLbnnYJ1orLaHV9nDa+x9P4qIfM3t+6/CSvCuLvNEY10H+oUxZk2XVTwB/ExEJtnzxti/J3UMmjROAsaYPcaY3B4m/xTrYt86se6GWo5Vn4wxJg/rn3mvXURP82BbB7FKNT/EKs5vAk6zJ38D2G9v5ztYZ67deRrresBmYCNHHyj/BwjBOqOuAt7kyGqgT4ExWGffvwOuNMZUeLjssVwLnGHv1724VffZZ6iXAj8HyrDOUn+MB/9DvXxnYF38HoZ13aPx6DV0uBOrGmcvsAbrmsuznu3aUTHtAuqxkgXGmFp7vWt7Okj3sr5y4GvA77Eulo8B1rrN8ixWVepqrFvFHfb+tMvBusDfnjTWYFWtrqZnM4FPRaQeq6R5lzn62YwZWL/3P7rfRWXH/BbwIPCa/ZvdCnR7x5nq1H7XiFKDgli3995ijJnj71i8SUT2YN3ltdzfsSh1LFrSUMrPROQKrKqVFf6ORane6IVwpfxIRFYBE4Fv2NeglBrQtHpKKaWUx7R6SimllMdOmuqpxMREM3z4cH+HoZRSg8qGDRvKjTG9PfDb4aRJGsOHDyc3t6e7TpVSSnVHRA70PlcnrZ5SSinlMU0aSimlPKZJQymllMd8mjRE5EIR2Ski+SJyTzfTh4nIhyLyhViN2GS4TbtBrMZhdovIDb6MUymllGd8ljTEao1sMda7XCYC14jIxC6zPQS8aIyZCtyP1S4EIhKP9e6fM7DeDnqv/WI7pZRSfuTLksYsrEZh9hpjWoDXsF745m4ina9OWOk2fSHwgTGm0hhThdW40IU+jFUppZQHfJk00jmyEZZCjm7cZDNWOwIAlwFRIpLg4bJKKaX6mb+f0/gR8Bf7zaWrsRqU8fi1zCJyK3ArQFZWVi9zqwHH5YKqfVC6HSryweUECQAR+zMAcOvvGC+d48OiYfT51ufJxOWCukMQlQoBgb7fXsUe2P5vCI6A8FgIj+vswmKtcYHBvo9DDXi+TBpFHNlyVwZdWhkzxhRjlzTshlmuMMZUi0gRVlOU7suu6roBY8xTWG0Ek52drS/RGsgaKqBkq5UgSrZZn6U7oPVYzUd4KCgMxn8Zpl0DI+f1z0HWm1xOK2kWb4JDm+HQJjj0BbTUQdp0uOQxGHpa7+vpC2cbrHscVv4O2hzHnjckyk4osUcmlPgRMPlKiO2ukUY/cdRC0QYoXG91xZsgMAQiEiEiyeoikzr7IxIhIrmzfyAnyFYHlOVZ/0+Ht1qfkSlw5d/6ZfM+e2Gh3XrXLmA+VrJYD1xrjNnmNk8iUGmMcYnI7wCnMebX9oXwDVgNqIDVUM/pxpjKnraXnZ1t9InwAaC1Ccp2diaH9gRRX9I5z5AESJkEyZMgZaL1mTQWAkPBuKwO09lvTOdn1/HVB2HLG7DlTXBUQ2QqTP06nHaNtW5vqj0EjhoIjbK6kEgIOM4aXpcTyndbiaF4U2eCaLUbXQwKg9QpMHQaRKfBur9CYzmccRvM+zmE9tTkdx8c3gL/ucOKYdzFsOgPEDwEmqqgqdr6dNifHV2XYUe1/bcVGHkuTLseJnwZgsO9F2dvjLGSbsFnUPgZFKy3fnPtLfUmjYe0GVYJtb4UGsqgoRwaSsHZ0v06w2I7E0pHqaubhOk+LTTm+H8Pve1XfUlnYmhPEuW7oL2drKBw63c+4hxYcF+fNiMiG4wx2R7P78u33IrIIuBRIBB41hjzOxG5H8g1xiwRkSux7pgyWNVT3zXGNNvL3oTVShpY7fg+d6xtadLwsZZGqD8MdSWdn3WHrB913WH785B1IGkXFAZJ4+zk4JYgIpPtKiYvamuGXe/D5ldh9zJwtUHqVJh2rXUWHOnxq3Usjhoo/tw6Wy3aaH3WHTp6vpAoq2qsPZF0dNF2F2Ud6KsLrIPz4S2dpavgIXaCOM1KEmnTIHEcBLpVADRVwfLfwIbnIDrDOrCPv7jv3xNY39Xq/4M1f7QOeIv+DyZ+te9/k6r9sOlV2PQK1By0Dp6TL4dp10FGtvf/1u6liILPrE9HtTUtNMbaZsZMyJwJ6dnWAb07xkBzrZ1Ayjq7erf+hvIjE+SxSsYSAGExVjIJi7H+vsHhVhcU1qV/CASHWQd99/GtjdZvpD1BNJZ3rj86w/o/Sp0MKZOt3078yBMuWQ+opNGfNGl4QavDKhkUb7QOcNUHrYRQVwLNNUfPHxBsFYujUiBqqN2fColjrOQQP/LIA2B/aSiHrf+0DmKHNoEEwpjzrdLH2Autf1Z3rQ7rn7Q9ORRtgIrdndPjR0H66VYXmQTN9dBcZx1w3D8d7cN1neNb6q11BA+xkljaNLcEMdbzf/iDn8I737fOoMd/GS56EGI8aZ68m/UsuRPKd1rfx8L/B0Pij3893XG54MAa+Pxl2P4faGuykuC0a+G0q63fxvGqL3U7iG6xDqRleVjnmWKVIjKyIXMWZMyyv1Mf3t/T6rBLX9VHJpOuJTFHtTVvW5P12dpoVf+1Nlmds7nnbQSGQvJ4SJnSmSBSJnnv79SFJg3lmbYW6wBU/HlnV7rdOkMHCI+HhNFHJ4SoVKsKKCrVmseX/6DeULrDKn188YZVUgiLgclXWAfuw19YCeLwVnC1WvNHptgJYob1mTbdOhvvK5fTShwhkSd+rcXZCp/8BVY9aK1r3i9g1q2eJebmevjwfvjsKSvZfPlRGLPgxOI5FkctbHsLNr0MBZ9aZ+GjF1ilj3EXQVDokfM726wqpo7kYCcK92rN6AzrIJo23SpJpJ/ecylioHO5OpOIe2IJCrVOUvrxZEuThjqas806O3NPECVbO+tzw2Ktf8S06dYZcNp0iMn0frWCP7mcsC/HqkbZ8bb1jxoSBenTrfru9pJEdNrA3++q/fDuDyF/uVW19eVHrSTXk/zl8PbdUFNgJZn5v7KqzfpLeb6VPDa/BnXFVhKe8nXrpKTEThClOzovxAcEH3mmnTrFOtv20Zn2qU6TxsnqizesfzpXm3UR2OW0LwY73YadVj2t+zSX0zrDbv+HDI12qyKxE0Xc8IF/oPSm5jqr2iNuxMAvKfXEGOtM/r17rLr3WbdaJQ/3W48bK+H9X8DmV6xqm6/8GbLO9F/MLifsWWklkLx3rSqa8Hg7MUztrKdPHAtBIf6L8xSjSeNkYwys+j3k/N4qtkYkWVUT7c8udPQHHjm+Y1qgdeG5I0EM4gOlOpqjxqp2Wv83qxrxogdhwiXWMxdLf2zVr5/1fTjnx0dfy/EnRw20NFgxn0onLAPQ8SYNfz/cp47F2Qpvfx82vWTVBV/y2MC+f1z1v7AYuPhh66L223fBG9+wqn0q8q3S5Dfess7eB5qwGKtTg46ecg5UzXXwylVWwjj3p3DpYk0YqmcZ2XDrKjj/t9YtteffD7d8ODAThhrUtKQxENUdhpe/Zt3+esmf4HR9M7zyQGAwnPU9q1PKRzRpDDRlO+GlK6GxAq593Xq+QCmlBghNGgPJgY/h1Wusd+R8813rwrVSSg0gek1joNj2Frz4VevuqFs+0IShlBqQNGkMBJ8shn9803p+4uZl1nMTSik1AGn1lD+5nNbDV5/+1bq3/vKn+/ftoEopdZw0afhLaxP861bYscR67fXC3w2+diCUUqccTRr+0FhpXfAuWGe9ZXT2d/0dkVJKeUSTRn+rKYIXL4XqA3Dlc1a7A0opNUho0uhPxsA7d0NtMXzj3zD8LH9HpJRSx0XvnupPO5fC7vdh7j2aMJRSg5Imjf7S0gj/vQeSJsCZt/k7GqWU6hOtnuovHz1stZ9847v64kGl1KClJY3+UJ4PH/8Jpl4Fw+f4OxqllOozTRq+Zgws/REEhVmvrVZKqUHMp0lDRC4UkZ0iki8i93QzPUtEVorI5yLyhYgssscPF5EmEdlkd0/4Mk6f2v5v2LsSzvslRKX4OxqllDohPrumISKBwGLgfKAQWC8iS4wx291m+yXwhjHmryIyEVgKDLen7THGTPNVfP2iuR7e+7nVEE72zf6ORimlTpgvSxqzgHxjzF5jTAvwGnBpl3kMEG33xwDFPoyn/+U8CHXFcPEjEKj3HCilBj9fJo10oMBtuNAe5+4+4HoRKcQqZdzpNm2EXW2VIyJnd7cBEblVRHJFJLesrMyLoXtB6Q5Y9zhMvx4yZ/k7GqWU8gp/Xwi/BnjeGJMBLAL+LiIBwCEgyxgzHfgB8IqIRHdd2BjzlDEm2xiTnZSU1K+BH5Mx8O6PICQSFvzG39EopZTX+DJpFAGZbsMZ9jh3NwNvABhjPgHCgERjTLMxpsIevwHYA4z1YazeteUfcGANLLgXIhL9HY1SSnmNL5PGemCMiIwQkRDgamBJl3kOAvMBRGQCVtIoE5Ek+0I6IjISGAPs9WGs3uOogWW/hLQZMOMGf0ejlFJe5bOrs8aYNhG5A3gfCASeNcZsE5H7gVxjzBLgh8DTInI31kXxG40xRkTOAe4XkVbABXzHGFPpq1i9auX/Qn0pXPOato+hlDrpiDHG3zF4RXZ2tsnNzfVvEIe3wJPnwOk3wpf/6N9YlFLKAyKywRiT7en8/r4QfvJwueDdH0J4HJz3K39Ho5RSPqEPD3jL5leg4FO4dDEMifd3NEop5RNa0vCGpir44NeQeQacdq2/o1FKKZ/RpOENH/7WShwXPwwB+pUqpU5eeoQ7UUUbIfdZmPVt6x1TSil1EtOkcSJcTuvid2QyzPuZv6NRSimf0wvhJ2LjC1C8ES5/GsJi/B2NUkr5nJY0+qqhApb/BoafDVO+5u9olFKqX2jS6KvV/wfNtbDo/0DE39EopVS/0KTRF1X7Yf0z1mvPkyf4OxqllOo3mjT6YsXvICAI5urFb6XUqUWTxvE6tBm2vAFn3gbRaf6ORiml+pUmjeO1/D7r/VJn3eXvSJRSqt9p0jgee1bCnhVwzo8hPNbf0SilVL/TpOEplwuW3wsxWTDzFn9Ho5RSfqEP93lq27+s6xmXPQVBof6ORiml/EJLGp5oa4EVv4WUKfogn1LqlKYlDU9seM56NuO6f+pbbJVSpzQ9AvbGUQs5D8KIc2D0fH9Ho5RSfqVJozcf/xkaK2DBffq6EKXUKU+TxrHUlcAnf4FJl0H66f6ORiml/M6nSUNELhSRnSKSLyL3dDM9S0RWisjnIvKFiCxym/Yze7mdIrLQl3H2KOf34GyB837ll80rpdRA47ML4SISCCwGzgcKgfUissQYs91ttl8Cbxhj/ioiE4GlwHC7/2pgEpAGLBeRscYYp6/iPUp5Pmx4AbJvgoRR/bZZpZQayHx599QsIN8YsxdARF4DLgXck4YBou3+GKDY7r8UeM0Y0wzsE5F8e32f+DDeI624H4LD4dyf9NsmT0XGGBytLlraXESEBhIUOHBrTGsdrZTVNRMUIAQGCMGBAQQGSMdwUEDncEBA99e/XC5Dq8tFq9PQ2uaixWnte6vTHue0xrW2uXAaw7TMWIaE6E2OauDw5a8xHShwGy4Ezugyz33AMhG5E4gAFrgtu67LsuldNyAitwK3AmRlZXklaGtrubD9P9ZbbCOTvbfek4QxhqZWJ5UNLVQ1tFLZ2EJ1Y4s13NhKQ3MbTa1OHC1OGlucNLXaXUv3n+6iw4KIHRJC3JDgLp8hxEUEExMebPUPCSF2SDCJkaGEhwT6bD+3FdeSs6uMVTtL2XiwGqfLeLSsCEckE6fLSghtHi7fLjEylNvmjuK6M7IIC/bNfip1PPx9CnMN8Lwx5mERmQ38XUQme7qwMeYp4CmA7Ozs4/tv7Hml8MGvISIJZn/XK6scbMrqmsnZVcbBykaqGlqoarS6yobWjuHmNle3y4rAkOBAwkOCCA8JILy9PziAxMgQhoQEERYc2GVaIMGBQp2jjerGFqqbWqlqbKWqsYW95fVUN7RS19zW4/ZGJkYwNSOWqRkxTM2IYeLQmD4nkprGVlbvLmPVzjJW7y6jrK4ZgMnp0Xzn3JGMTYnC6TK0uQxtToPTZSWC9nHtyaHrcKAIIUEBBAcG2J9CSGAAwe3jAo+e1tji5G9r9vHbd7bz9Oq9fPe80VyVnUlIkP9LY8YYappaKa1rxhgYnRxJYA+lK39rbGljT2kDcRHBpMeGIz66C7KqoYVtxbVsK66hqLqJlOgwMuLC7W4ISZGhPZZABxNfJo0iINNtOMMe5+5m4EIAY8wnIhIGJHq4rG/sXgYH1sKihyA0ql826W8ul3VG/WFeCSvzStlcWNMxLXZIMPH2WX16bBiT06KJjwghLiKE+CH2Z4RVGogfEkJ0eLBPDh6tThfVja3UNFmlmaqGFqobWymuaWJrUQ1r8st563PrJxIYIIxJjuS0jFim2IlkfGp0twdbl8uwtbiGnJ1lrNpVxucHq3AZiAkP5uwxicwdl8w5YxNJjgrz+j55YsHEFD7eU84jy3bxq39v5YlVe/je/NFcPiODYB9U5RljqG5spaTOQWltMyW1Dkrrmilt/6zrHNfiduIQERLItKxYTs+KY/qwOGZkxhEzJNjr8fWmor6ZbcW1bD9Ua30W17CvvIH2Al5ESCCjU6IYmxzJmJRIxqREMTYlirSYMI+TiTGG0rpmthbVsK24tuOzqLqpY56o0KCjTnRCAgNIiw0jI24I6bF2MokPJz12CBlx4aREhw3YxOtOjPHOCfpRKxYJAnYB87EO+OuBa40x29zm+S/wujHmeRGZAHyIVQ01EXgF6zpGmj1+zLEuhGdnZ5vc3NwTC9rlhCfmQJsDvvsZBPb/j76/1De3sWZ3OSvzSlmxs5SyumZEYFpmLPPHJzNvfDLjUqIG9DWGrg7XOPiisJovCmv4oqiGLwqrqW5sBax/2PFDo6zSSHosocEB5NilifL6FgCmZsQwd2wS545L4rSM2AG178YYcnaV8cgHu/iisIZhCUO4a/4YLp2WfkIHmoLKRtbkl7Mmv5zNBdWU1jbT4jy6FBkVFkRKdBjJUaEdn8n2Z6vTxecHq9lwoIq8w7UdB+gxyZHMyIrj9GFxzBgWx8jECK+dabtchoKqRrYX17oliRpKaps75kmPDWdiWjQTh0YzLjWKyoYWdpfUsauknt2l9ZTXd84bGRrE6ORIxiRHMjYlijEp1mdqdBiFVU1sLa7pSA7bims6fjNglXQnpccwKS2ayWnWZ1xECI0tbRRVNVFY3URhVROFVY3WsN25bx+s6syMuHDGpkQxPjWKsanW5/CECJ/+FkVkgzEm2+P5fZU07GAWAY8CgcCzxpjficj9QK4xZol9l9TTQCTWRfGfGGOW2cv+ArgJaAO+b4z577G25ZWksekV+PdtcOVzMPnyE1vXAHSgooEVeaWsyCvl072VtDhdRIUFcc7YJOaPT+bcsUkkRJ48L2M0xlBY1WQlETuZbC2q6TgDjB0SzDljkpg7LolzxiaROAj23RjD8h2lPPLBLnYcqmV0ciTfXzCGRZOHenRArmpo4eM9FazJL2dtfjkHKxsBSIkOZdaIBNJjwzsTQ3QoKVFhJEV5ft2oobmNzQXVbDxYxYYDVWw8WE1Nk5W4Y8KDmZEVayWRrDjSYsNxtDlxtLpw2Ne9mlut4aZWJ47WzmntXVOrk/3ljew4VNvxdwwMEEYnRTIxLZpJdpKYmBZN7JCQXr+LXSV17CqtJ78jmdQdkRACA6TjOlZQgDA6OZLJ7QkiPYYJQ6OJDO1bhY2j1UmRnVCK7KSyr7yBnSV17HcrHYUEBjAqOdJKJG4J5XhKR8cyoJJGfzrhpNHqgD+fbl34/taKQf30d3sVQ1F1E0XVTWw4UMWHO0rYU9YAwKikCOZPSGHeuGSyh8f5pJpjoHK5DPsqGmhsdjIxLXpQVAd0x+UyvLftMI98sIv80nrGp0Zx9/ljuWBiyhEHEkerk/X7KzuSxLbiWoyxzqzPHJnAnNEJzBmTyKikSJ/U9btchr3lDWw8UNWRSHaX1h/3ekKDAggLDiQsOICMuCFMHGoniLRoxqZEefUmgUo7mewuraewspFhCRFMTvf+do7F0eokv7SeXSV17Dxcx07781CNo2OeqNAgxqZGMS41iumZsXwtO/MYa+yZJo2+Wvsn+OBXcMPb1numBrA2p4uSumaKq60zlPbkUFTVZI2rbqKxpbMmLyQwgDNGxjN/fDLnjU8hK2GIH6NX3uR0Gd7eXMyjy3exv6KRKekx3HL2CIqqm1ibX876/VW0tLkIDhSmZ8UxZ3QiZ41O5LSMGL9Vv9U0tvJ5QRWVDS2EBwcSFhxIaLCVFNqHw4IDCAsKJDwkkJDAgJPiArI31DS1diYSu8s7XMuEodG8/u3ZfVqnJo2+aKqCx6ZBRjZc/0/vBuYl7209zLNr91FU1cThWsdRt37GR4SQHhtOWmwY6bFDSI8LJ93uH5kUQUQfi9BqcGhzuvjX50U8tnx3xwXZ8alRVpIYk8is4fH6GzhJGWNoaHH2uZrseJOG/ooA1vwRHDXWSwkHoA93lPDdVzYyLD1E7foAACAASURBVGEIs0bEd0kMVqLQB8BObUGBAXw9O5OvTktnw4EqRidHkhQ18K/RqBMnIn1OGH2hR5qaQlj3BEy9ClKn+Duao3y6t4LbX97IpLRoXvnWmf3641CDT0hQALNHJfg7DHUS0yNQeDzMvQemXOnvSI6yrbiGW17IJT0unOdunKkJQynld3oUChkCZ//A31EcZV95Azc8+xlRYUG8dPMZJ9WtsEqpwevUuddyEDlc4+D6Zz7FZeDFm88gLTbc3yEppRSgSWPAqW5s4X+e/ZTqxhae/+ZMRidH+jskpZTqoNVTA0hDcxs3Pree/eWNPH/TTKZmxPo7JKWUOoKWNAaI5jYn33lpA18UVvPna6fzpVGJ/g5JKaWOoiWNAcDpMvzgjc18tLucP1w5lYWTUv0dklJKdUtLGn5mjOFX/9nKu18c4ueLxvP1Pr4/Riml+oMmDT97aNlOXvn0ILfNHcWt52hb5EqpgU2Thh8989FeFq/cwzWzMvnJwnH+DkcppXqlScNP3txQyAPv7mDRlFQe+OoUnzVBqZRS3qRJww+WbTvMT//5BXNGJ/LHq6YN2jYdlFKnHk0a/WxzQTV3vPo5k9NjePIbpxMa1D+NuiillDdo0uhnDy3bSXRYEM/fOFPbN1BKDTqaNPrR1qIaPtpdzk1zRhAXcez2i5VSaiDSpNGPnsjZQ1RoENefOczfoSilVJ9o0ugnByoaWLrlENeemUV0WLC/w1FKqT7xadIQkQtFZKeI5IvIPd1M/6OIbLK7XSJS7TbN6TZtiS/j7A9Prd5LUEAAN581wt+hKKVUn/nsSqyIBAKLgfOBQmC9iCwxxmxvn8cYc7fb/HcC091W0WSMmear+PpTaZ2Df2wo5IrT00mODvN3OEop1We+LGnMAvKNMXuNMS3Aa8Clx5j/GuBVH8bjN8+t3U+r06WvCVFKDXoeJw0RCReR43nXRTpQ4DZcaI/rbt3DgBHACrfRYSKSKyLrROSrPSx3qz1PbllZ2XGE1n9qHa289MkBFk0eyojECH+Ho5RSJ8SjpCEilwCbgPfs4Wlevs5wNfCmMcbpNm6YMSYbuBZ4VESOOk03xjxljMk2xmQnJSV5MRzveeXTg9Q1t/Gdc7WUoZQa/DwtadyHVd1UDWCM2YRVMjiWIsD9Pd8Z9rjuXE2XqiljTJH9uRdYxZHXOwYFR6uTv63Zx5zRiUzJiPF3OEopdcI8TRqtxpiaLuNML8usB8aIyAgRCcFKDEeVTkRkPBAHfOI2Lk5EQu3+ROAsYHvXZQe6tz4voqyumdvmailDKXVy8PTuqW0ici0QKCJjgO8BHx9rAWNMm4jcAbwPBALPGmO2icj9QK4xpj2BXA28ZoxxT0ITgCdFxIWV2H7vftfVYOB0GZ7M2cOU9Bi+NCrB3+EopZRXeJo07gR+ATQDr2Alggd6W8gYsxRY2mXcr7sM39fNch8DUzyMbUB6f9th9lc08vh1M/S150qpk0avScN+3uJdY8w8rMShemGM4a+r9jAiMULb+1ZKnVR6vaZh39HkEhG9kuuhj/dUsKWohlvPGaltZSilTiqeVk/VA1tE5AOgoX2kMeZ7PolqkPvrqj0kR4Vy+YxuH0tRSqlBy9Ok8S+7U73YUljDmvxy7rlovDawpJQ66XiUNIwxL9i3zY61R+00xrT6LqzB64mcPUSFBXHdGVn+DqVfOV1OalpqqHZUg0BwQDAhASEEB1qfIYEhBAcED9qbApwuJ1+Uf0FhXSEGg8u4MMZ09mMwprO/6/TI4EiShiSRGJ5IUngS8WHxBAboSYUafDxKGiIyF3gB2A8IkCkiNxhjVvsutMFnX3kDS7ce4rZzRxE1yF9/7jIuaptrqXRUdnRVjqojh5urOsZVN1fjMq5e1xsUENRtMgkNDCU1IpX0yHSri0onIzKD9Mh0IkMi+2GPj+Zoc7Du0DpWHFxBTmEOlY5Kr607QAKID4snKdxKJO1d0pCkjnHJQ5IZGjF00CZadXLytHrqYeACY8xOABEZi/UE9+m+Cmwwemr1XoIDA/jmIH39eV1LHWuL1rKqcBUfFX5EbUttt/NFh0QTHxZPfFg8w6OHMz15OvFh8cSFxREXGoeI0OJsodXV2vHp3t/ibDlqfFNbE4caDpFbkktDa8MR24sJjelIJhmRGWREZXQMp0WmERLovVYQqx3V5BTmsOLgCj459AlNbU1EBkdydsbZnJd5HhMSJhAgAQhCgAQQINa9JEf1E4CIWB1CXUsdZU1llDeWU95UbvXbn2WNZeRV5lHhqDgq8Y6IGcHloy/nklGXkBCuz/sMBjXNNeys3MnI2JEkhif6Oxyv8zRpBLcnDABjzC4RGdyn0l5WWuvgnxsK+Vp2BklRof4Ox2NF9UWsKljFqoJV5B7Opc20ERcax9zMuUyIn9CRDNqTRGxYLMEBvvvTG2Ooaa6hqL6IwvpCiuqLKKqz+ndV7WJVwSpaXZ01o4IwNGIomdGZDIsaRlZ0FplRmQyLHkZGVAahgb3/LQrqClh5cCUrC1aysXQjLuMieUgyl466lHlZ85iZMpPgwBPb56iQKNIi0445j9PlpKq5ykomjWUU1hfy333/5eEND/PYxsc4N/NcLh9zOV9K+xJBAdq+/EDS2NrIqoJVLN23lLXFa2lztQGQPCSZSQmTmJgwsaMb7IlEjnwQu4eZRJ4FXMBL9qjrgEBjzE0+jO24ZGdnm9zcXL9t/3//u4OnV+9l5Y/mMixh4L7N1mVcbCvfxsqClawqXMXuqt0AjIwZydzMuczNnMvUxKkDtr7dZVyUNpZayaS+iIK6AgrqCjhYe5CDdQepae58240gpEakkhWVRVZ0FllRWR3JpdnZzMqClawoWNHxHYyJG8O8zHmcl3UeE+MnDphqob3Ve3kr/y2W7FlCpaOyI6FdNuYyMqMye1+BD9Q011BYV0hBfQENLQ0kD0kmJSKFlCEpRIdED5jvrqmticK6Qorri0mNSGVU7CivJdxWZytri9eydN9SVhWsoqmtieQhySwasYiZqTPZV7OP7RXb2V6xnQO1BzD2m5dShqQwMWHiEcnEn6VIEdlgvxzWs/k9TBqhwHeBOfaoj4DHjTHNfYrSB/yZNGodrZz1vys4d1wSf7l2hl9iOJamtiY+PfQpqwpWkVOYQ3lTOYESyPTk6R2JYlj0ydFueU1zTUcC6fi0+6ubq4+YN0ACmJE8g3mZ85iXNc9vB2BPtTpbySnM4V+7/8Xa4rW4jItZqbO4fMzlzM+aT1iQ9xr4chkXJQ0lFNYXdiTmgroCK1HUFfRYdQkQHhROypCUjiSSMiSF1IhUUiNSO4ZjQmO8llia2pqOOHFw/yxpLDli3rDAMMbHj2dy4mQmJU5icsJksqKzOqoWe+N0OdlQsoGl+5bywYEPqG2pJTY0lguGXcBFIy5iRsqMbtdV31LPjsodHUlke8V29tfu75ieGpHKxPiJTEuexoKsBWRG999v0VdJIwJwtL+63H5KPNQY09jnSL3Mn0nj8VX5/OG9nbxz5xwmp/ffM5DGGBrbGqloqqDCUWF9uvc7KihvKmdn5U4cTgcRwRHMSZ/D3My5nJ1+NjGhp9bzmu1nxwdqD+DCxVlpZxEXFufvsPrkcMNhluxZwlu736KwvpCokCguHnExl4+5nAkJE46av9nZTF1LHfUt9dS31lv9rfUdw/Ut9VQ1V3UkhaL6oiOqAYMkiKGRQ8mMyuzo2q8vRYZEUtZYxuHGw5Q0lFDSWMLhhsOUNJZQ0lBCWVPZUddqQgNDiQuLIywwjLCgsM7PoDDCA8M7+tuHQ4NCO+apclR1Jofag5Q2lR6x7viw+I7SZXtV5dCIoRTVF7G1fCvbKraxo2IHDqcDgKjgKCYmTmRywmQrmSRMIjUitSOpGWPYVrGNpfuW8t6+9yhrKiM8KJzzss5j0YhFzE6b3acqW/dE0h5TeyKZmDCRhcMXcsGwC8iIyjjudR8PXyWNdcACY0y9PRwJLDPGfKnPkXqZv5KGo9XJnAdXMmFoFH+/+QyfbWdbxTb+ueuflDeVH5Eg2n/47gQhNjSWhPAEEsITGBUzirmZc8lOyT7hunk1sLiMi/WH1/Ov3f9i+YHltLhaGBUzipDAkCOSgnsC6ElUcBTpUelWQojK6EgMmVGZpEak9rlap83VRkVThZVE7ERyuOEwNS01ONocONocNDmbOvodTgdNbU00O5txtDlodh5doREfFs+w6GEdSaG96jErKouokCiPYtpTvYdtFdvYWr6VreVb2V21mzZjXYtICEtgUuIkMiIzWFO0hoN1BwkOCGZO+hwWjVzEuRnnEh4U3qfv41iK64v54MAHvL//fbaUbwFgcsJkK4EMv6DX62J94auksalre93djfMnfyWNlz89wC/e2sor3zqDL43yzQWufTX7uH7p9bS52kiLTCMxPNFKCGEJHZ/u4+LC4vRC6SmoprmGd/e+y6qCVQQFBBEZEklUcJT1GRJFZHBkx7iI4AhrXEikNT44csBex3K6nFYCsZNJTEiMT27DbnY2s7NyZ0dpZGv5Vg7WHuT01NO5eMTFzB82n+iQaK9vtyeFdYUdCWRbxTYApiZO5YLhF7Bw+EJSI7zzXjtfJY21wJ3GmI32cDbwZ2PM7D5H6mX+SBpOl+G8h1cROySEf9/+JZ9c/KtyVHHd0utoaG3g5UUv+7yoqpTqZIwZEBf1C+oKWLZ/Ge/vf58dlTsAOC3pNBYOX8j5w84/oQTiq6QxE3gNKLZHDQWuMsZs6FOUPuCPpPHOF8Xc8crnPHH9DC6cPNTr6292NvOtZd9ie8V2/rbwb5yWdJrXt6GUGlwO1h5k2QErgeRV5gEwN2Muf57/5z6t73iTxjHrMOxkUWCMWW+3sPdt4HKstsL39SnCk0T7689HJkVwwUTvv/7cGMOv1/6az0s/56FzH9KEoZQCICs6i1um3MItU25hf81+lh1Yhicn/97SW8X3k8ACu3828HOsBpmmAU8BV/outIEt90AV24prefCKKQT44PXnj29+nKX7lnLXjLtYOHyh19evlBr8hscM59apt/brNntLGoHGmPYX7lwFPGWM+SfwTxHZ5NvQBrbl20sIDhQunur9uxne3vM2T2x+gktHXcrNk2/2+vqVUqqvenuiJVBE2hPLfGCF27RT+vacD/NKOWNEApGh3v0acg/n8uuPf82s1FncO/veAXERTiml2vV2xHsVyBGRcqAJ60lwRGQ0UHOsBU9mBZWN5JfWc80s777+/EDtAb6/6vtkRGbwyNxH9JkKpdSAc8ykYYz5nYh8iHW31DLTebUlAOvaxilpRZ71BOr88cleW2e1o5rbl99OAAE8Pv/xU+5pbaXU4OBJG+HrjDFvGWPcm3nd1f7MxrGIyIUislNE8kXknm6m/1FENtndLhGpdpt2g4jstrsbjmenfO3DvFJGJkYwPNE7LyZscbZw18q7ONRwiMfOe6xf3zujlFLHw2fXJez3Uy0GzgcKgfUissQYs719HmPM3W7z3wlMt/vjgXuBbMAAG+xlq3wVr6caW9pYt7eCb5zpnRf8GWO49+N72Vi6kQfPfpDpydO9sl6llPIFz17t2DezgHxjzF5jTAvWw4GXHmP+a7CuoQAsBD4wxlTaieID4EIfxuqxtfkVtLS5vFY19eQXT/LO3nf47rTvsmjkIq+sUymlfMWXSSMdKHAbLrTHHUVEhgEj6Lw7y6NlReRWEckVkdyysjKvBN2bFXklRIYGkT08/oTXtXTvUhZvWswlIy/h21O/7YXolFLKt3yZNI7H1cCb7a9e95Qx5iljTLYxJjspKclHoR2xPVbmlXH2mERCgk7sq/u89HN+ufaXnJ5yOvd96T69tVYpNSj4MmkUAe5XdDPscd25ms6qqeNdtt9sP1TL4VoH551g1VRBbQF3rbiLtMg0Hp37qFfbuFZKKV/yZdJYD4wRkREiEoKVGJZ0ncl+p1Uc8Inb6PeBC0QkTkTigAvscX610r7Vdu64vieNmuYabv/wdly4WDx/MbFhsd4KTymlfM5nd08ZY9pE5A6sg30g8KwxZpuI3A/kGmPaE8jVwGtuz4BgjKkUkd9iJR6A+91eZ+I3H+aVclpGDElRoX1exxObn6CgroBnLnjmpGliVSl16vDpq0CMMUuBpV3G/brL8H09LPss8KzPgjtOFfXNbCqo5vvzx/Z5HZWOSt7c9SYXj7yY7FSP30SslFIDxkC5ED7g5ewqwxhO6HrGS9tfotnZrC8hVEoNWpo0PPRhXilJUaFMSutbc491LXW8mvcqC4YtYGTsSC9Hp5RS/UOThgdanS5W7yrjvHHJfW4747W816hvredbU77l5eiUUqr/aNLwwIYDVdQ52pjXx6qpprYm/r7978xJn8OEhAlejk4ppfqPJg0PrMgrJThQmDMmsU/L/3PXP6lqrtJShlJq0NOk4YEVJ9DgUouzhee2PcfpKaczI2WGD6JTSqn+o0mjFwcrrAaX+nrX1Nt73qa0sZRbp/RvO75KKeULmjR6sSKvBOjbrbZtrjb+tvVvTEyYyOy02d4OTSml+p0mjV6s2FnW5waX3t//PgV1Bdw65VZ9IaFS6qSgSeMYGprbWLenok+lDJdx8cyWZxgVM4p5WfN8EJ1SSvU/TRrHsDa/nBanq09JY1XBKvKr87l5ys0EiH7NSqmTgx7NjmHlztI+NbhkjOGZLc+QEZnBRSMu8lF0SinV/zRp9MAYw4q8Us4Ze/wNLq07tI4t5Vu4acpNBAX49J2QSinVrzRp9GBbcS0ltc3M60PbGU9veZrk8GQuHXWsJtGVUmrw0aTRg742uLSpdBPrD6/nhkk3aIt8SqmTjiaNHqzYWcppmbHH3eDS01ueJjY0livHXumjyJRSyn80aXSjvcGl846zlJFXmcfqwtVcP+F6hgQP8VF0SinlP5o0urFqZ98aXHpmyzNEBkdyzYRrfBSZUkr5lyaNbqzYWUrycTa4tK9mH8v2L+Pq8VcTHdK3hpqUUmqg06TRRavTxeqdZcw7zgaXnt36LKGBoVw/4XofRqeUUv6lSaOL3P1V1DUfX4NLxfXFvLPnHa4YewUJ4Qk+jE4ppfzLp0lDRC4UkZ0iki8i9/Qwz9dFZLuIbBORV9zGO0Vkk90t8WWc7lbuLCUkMOC4Glx6butzIHDjpBt9F5hSSg0APntcWUQCgcXA+UAhsF5ElhhjtrvNMwb4GXCWMaZKRNxP75uMMdN8FV9PPtxRwhkj4z1ucKm8qZx/7f4XXxn1FVIjUn0cnVJK+ZcvSxqzgHxjzF5jTAvwGtD1EelvAYuNMVUAxphSH8bTq4MVjewpaziup8Bf3P4ibaaNmyff7MPIlFJqYPBl0kgHCtyGC+1x7sYCY0VkrYisE5EL3aaFiUiuPf6r3W1ARG6158ktKys74YDbG1yaP8GzpFHTXMPrea+zcPhCsqKzTnj7Sik10Pn7bXpBwBhgLpABrBaRKcaYamCYMaZIREYCK0RkizFmj/vCxpingKcAsrOzzYkG82FeKSOTIhiW4FmDS6/kvUJjWyO3TLnlRDetlFKDgi9LGkVApttwhj3OXSGwxBjTaozZB+zCSiIYY4rsz73AKmC6D2OlobmNT/dWevwUeGNrIy/veJm5mXMZGzfWl6EppdSA4cuksR4YIyIjRCQEuBroehfUv7FKGYhIIlZ11V4RiRORULfxZwHb8aGOBpc8rJpaUbCCmuYavjnpm74MSymlBhSfVU8ZY9pE5A7gfSAQeNYYs01E7gdyjTFL7GkXiMh2wAn82BhTISJfAp4UERdWYvu9+11XvrAir5So0CBmetjg0uqC1SSEJTAtud9v8FJKKb/x6TUNY8xSYGmXcb926zfAD+zOfZ6PgSm+jK3L9li5s5SzxyYSHNh74avV1cqa4jUsyFqgTbkqpU4pesSjs8Gl88aneDT/ptJN1LXUcW7GuT6OTCmlBhZ/3z01IKzIK0UE5o5L8mj+jwo/IiggiDPTzvRxZEqpdq2trRQWFuJwOPwdyqAUFhZGRkYGwcHBJ7QeTRpYSWNqRiyJkZ41uJRTmMPMlJlEBHt2a65S6sQVFhYSFRXF8OHDEfH8ZaLKqoKvqKigsLCQESNGnNC6TvnqqfL6ZjYXVjPfwxcUFtQWsLdmL+dmatWUUv3J4XCQkJCgCaMPRISEhASvlNJO+ZJGeHAgD115GjOGxXk0/+qi1QCck36OL8NSSnVDE0bfeeu7O+WTRkRoEFecnuHx/DkFOYyMGUlmdGbvMyul1EnmlK+eOh4NrQ2sL1mvd00pdYr605/+xIQJE7jiiiuYPXs2oaGhPPTQQ/4Oq1+d8iWN4/FJ8Se0udo4J0OrppQ6FT3++OMsX76ckJAQDhw4wL///W9/h9TvNGkch5zCHKJCovQpcKX87Ddvb2N7ca1X1zkxLZp7L5nU4/TvfOc77N27l4suuoibbrqJu+++m3fffderMQwGmjQ85DIuVheuZk7aHIIC9GtT6lTzxBNP8N5777Fy5UoSEz1v2fNko0c/D20r30alo5JzMrVqSil/O1aJQPmWXgj3UE5hDgESwJy0Of4ORSml/EaThodWF65mWtI0YsNi/R2KUkr5jVZPeaCkoYQdlTv4/ozv+zsUpdQAcPjwYbKzs6mtrSUgIIBHH32U7du3Ex0d7e/QfE6Thgc+KvoIQJ/PUOoUt3///o7+wsJC/wXiR1o95YGcwhzSI9MZFTvK36EopZRfadLohaPNwaeHPuWcjHP0vTdKqVOeJo1erD+8nqa2Jn0KXCml0KTRq5zCHMKDwpmZOtPfoSillN9p0jgGYwyrC1dz5tAzCQ30rIEmpZQ6mWnSOIbd1bs51HBI75pSSimbT5OGiFwoIjtFJF9E7ulhnq+LyHYR2SYir7iNv0FEdtvdDb6MsyerC60Gl87OONsfm1dKnQJyc3P53ve+1+P04uJirrzyyn6M6Nh89pyGiAQCi4HzgUJgvYgsMcZsd5tnDPAz4CxjTJWIJNvj44F7gWzAABvsZat8FW93cgpymJgwkeQhnjUFq5RSTqeTwMBAj+fPzs4mOzu7x+lpaWm8+eab3gjNK3z5cN8sIN8YsxdARF4DLgW2u83zLWBxezIwxpTa4xcCHxhjKu1lPwAuBF71YbxHqHJU8UX5F3x76rf7a5NKKU/99x44vMW760ydAhf9/piz7N+/nwsvvJDTTz+djRs3MmnSJF588UUmTpzIVVddxQcffMBPfvIT4uPjuffee2lubmbUqFE899xzREZGsn79eu666y4aGhoIDQ3lww8/ZMOGDTz00EO888475OTkcNdddwFW86yrV6+moqKCL3/5y2zduhWHw8Ftt91Gbm4uQUFBPPLII8ybN4/nn3+eJUuW0NjYyJ49e7jsssv4wx/+4N3vx+bL6ql0oMBtuNAe524sMFZE1orIOhG58DiWRURuFZFcEcktKyvzYuiwpmgNLuPS6xlKqSPs3LmT22+/nR07dhAdHc3jjz8OQEJCAhs3bmTBggU88MADLF++nI0bN5Kdnc0jjzxCS0sLV111FY899hibN29m+fLlhIeHH7Huhx56iMWLF7Np0yY++uijo6YvXrwYEWHLli28+uqr3HDDDTgcDgA2bdrE66+/zpYtW3j99dcpKCjAF/z9GpEgYAwwF8gAVovIFE8XNsY8BTwFkJ2dbbwZ2OrC1SSEJTAhYYI3V6uU8oZeSgS+lJmZyVlnnQXA9ddfz5/+9CcArrrqKgDWrVvH9u3bO+ZpaWlh9uzZ7Ny5k6FDhzJzpnX7fnfvqTrrrLP4wQ9+wHXXXcfll19ORkbGEdPXrFnDnXfeCcD48eMZNmwYu3btAmD+/PnExMQAMHHiRA4cOEBmZqa3d9+nSaMIcI84wx7nrhD41BjTCuwTkV1YSaQIK5G4L7vKZ5F20epqZW3RWhYMW0CA6A1mSqlOXd8M0T4cEREBWLfqn3/++bz66pG16Vu29F6dds8993DxxRezdOlSzjrrLN5//33CwsI8iis0tPOxgMDAQNra2jxa7nj58oi4HhgjIiNEJAS4GljSZZ5/YycHEUnEqq7aC7wPXCAicSISB1xgj+sXm0o3Uddap1VTSqmjHDx4kE8++QSAV155hTlzjmxj58wzz2Tt2rXk5+cD0NDQwK5duxg3bhyHDh1i/fr1ANTV1R11YN+zZw9Tpkzhpz/9KTNnziQvL++I6WeffTYvv/wyALt27eLgwYOMGzfOJ/vZE58lDWNMG3AH1sF+B/CGMWabiNwvIl+xZ3sfqBCR7cBK4MfGmAr7AvhvsRLPeuD+9ovi/SGnIIfggGDOTDuzvzaplBokxo0bx+LFi5kwYQJVVVXcdtttR0xPSkri+eef55prrmHq1KnMnj2bvLw8QkJCeP3117nzzjs57bTTOP/88zuuR7R79NFHmTx5MlOnTiU4OJiLLrroiOm33347LpeLKVOmcNVVV/H8888fUcLoD2KMVy8F+E12drbJzc31yroueesS0iLTePL8J72yPqXUiduxYwcTJvj3GuP+/fs77mQajLr7DkVkgzGm53t+u9AK+y4O1B5gf+1+fUGhUkp1Q5NGF+1PgWvSUEp1NXz48EFbyvAWTRpd5BTmMCpmFJlR3r9VTSmlBjtNGm7qW+rZULJBSxlKKdUDTRpuPjn0CW2uNk0aSinVA00abnIKcogKiWJa8jR/h6KUUgOSJg2by7j4qOgj5qTPISjA329XUUqdKp5//nnuuOMOAO677z4eeughP0d0bJo0bFvLt1LpqNSnwJVSHjHG4HK5/B1Gv9NTaltOYQ4BEsCc9Dm9z6yU8qsHP3uQvMq83mc8DuPjx/PTWT895jz79+9n4cKFnHHGGWzYsIGvf/3rvPPOOzQ3N3PZZZfxm9/8BoAXX3yRhx56CBFh6tSp/P3vti/h2QAACEZJREFUf+ftt9/mgQceoKWlhYSEBF5++WVSUlK8ug/9QZOGbXXhaqYlTSMmNMbfoSilBrDdu3fzwgsvUFtby5tvvslnn32GMYavfOUrrF69moSEBB544AE+/vhjEhMTqay03oA0Z84c1q1bh4jwzDPP8Ic//IGHH37Yz3tz/DRpAIcbDpNXmcfdp9/t71CUUh7orUTgS8OGDePMM8/kRz/6EcuWLWP69OkA1NfXs3v3bjZv3szXvvY1EhMTAYiPjwegsLCQq666ikOHDtHS0sKIESP8tg8nQq9p4PYUeLreaquUOjb3V6D/7Gc/Y9OmTWzatIn8/HxuvvnmHpe78847ueOOO9iyZQtPPvnkUS8rHCw0aWAljfTIdEbFjvJ3KEqpQWLhwoU8++yz1NfXA1BUVERpaSnnnXce//jHP6ioqADoqJ6qqakhPd1qgPSFF17wT9BecMpXTznaHHx66FMuG3PZUY2rKKVUTy644AJ27NjB7NmzAYiMjOSll15i0qRJ/OL/t3f/sXXVZRzH3x/L5MZhQnUTGwtZxDkRTJyyGcjY5kg0IhFMNowmOohRIP5a/BEJJNiYmCybYEKWaBRnhxGIyg+JMRmixpJ1Wdjm2MYIEOnUjbnVkgyIIsIe//h+K9fe23Ju1/X09Hxe//Scc3vvffrk2/v0+z09z7npJlasWEFXVxeLFy+mv7+fvr4+1qxZQ3d3N6tWrWJoaKjkn2Byat8affifw2zcuZHVC1eztGfpKYjMzKbCTGiNXnVT0Rq99jON+W+Yz4blG8oOw8ysEnxOw8zMCnPRMLPKmC3L6WWYqty5aJhZJTQaDUZGRlw4JiEiGBkZodFonPRr1f6chplVQ29vL4cOHWJ4eLjsUCqp0WjQ29t70q/jomFmlTBnzpzKXkU9m3h5yszMCnPRMDOzwlw0zMyssFlzRbikYeAvZcdxis0D/lF2EDOMc9Ke89LKOWk1D5gbEfOLPmHWFI06kLSzk8v968A5ac95aeWctJpMTrw8ZWZmhblomJlZYS4a1fLDsgOYgZyT9pyXVs5Jq45z4nMaZmZWmGcaZmZWmIuGmZkV5qJREZIOStonaY+kzm9ROAtI2izpmKT9TcfeJOm3kp7KX7vLjHG6jZOTPkmH81jZI+myMmOcbpLOlvQHSQckPSbpK/l4bcfKBDnpeKz4nEZFSDoIXBgRtb04SdJy4AXgjoi4IB/bADwbEesl3QB0R8Q3y4xzOo2Tkz7ghYj4bpmxlUVSD9ATEbslvRHYBVwJXE1Nx8oEObmKDseKZxpWGRExADw75vAVwJa8vYX0i1Ab4+Sk1iLiSETsztvPA48Db6PGY2WCnHTMRaM6AnhQ0i5Jny87mBnkrIg4krf/DpxVZjAzyBcl7c3LV7VZhhlL0gJgMbADjxWgJSfQ4Vhx0aiOZRHxPuAjwBfysoQ1ibTW6vVW+D5wLvBe4AhwS7nhlEPSGcA9wLqIeK75sbqOlTY56XisuGhUREQczl+PAfcBS8uNaMY4mtdrR9dtj5UcT+ki4mhEvBIRJ4AfUcOxImkO6cPxZxFxbz5c67HSLieTGSsuGhUgaW4+eYWkucCHgP0TP6s2HgDW5u21wK9KjGVGGP1gzD5OzcaKJAE/Bh6PiFubHqrtWBkvJ5MZK/7vqQqQ9HbS7ALSLXrvjIjvlBhSKSTdBawktXM+CnwLuB/4OXAOqTX+VRFRmxPD4+RkJWm5IYCDwLVNa/mznqRlwMPAPuBEPnwjaQ2/lmNlgpx8kg7HiouGmZkV5uUpMzMrzEXDzMwKc9EwM7PCXDTMzKwwFw0zMyvMRcNqQ9L3JK1r2t8q6fam/VskfVXSx3JDu05eu1/S6qmMt817XCjptlP5HmavxUXD6mQbcDGApNeRrm04v+nxi4HBiHggItaXEN+EImJnRHy57Dis3lw0rE4GgYvy9vmkq1+fl9Qt6XTgPGC3pKslbYL/zSBukzQo6enR2YSSTZKekPQQ8JbRN5F0qaQ/5fufbJZ0uqQlku7Nj18h6V+SXi+pIenpsYFKWiNpv6RHJQ3kYysl/Tpv/6bpHgjHJa2V1CVpo6RHcgO6a09ZJq22Tis7ALPpEhHPSHpZ0jmkWcV2Unvoi4DjwL6IeCl1XPg/PcAy4F2kVhS/JLVcWAS8m9Qt9QCwWVID6AcujYgnJd0BXA9sIl15C3AJqWAtIf0O7qDVzcCHI+KwpDPb/CyXAUh6P/AT0pXxnwWOR8SSXAS3SXowIoY6y5TZ+DzTsLoZJBWM0aKxvWl/2zjPuT8iTkTEAV5tp70cuCs3e3sG+H0+vggYiogn8/4WYHlEvAz8WdJ5pKZwt+bXuITU3mGsbUC/pM8BXe2CkjQP+CnwqYg4TupJ9hlJe0iF6M3AwtdKiFknPNOwuhk9r/Ee0l/7fwO+BjxH+ou9nX83bbdMQzowQGpt/x/gIdKMpAv4xthvjIjrJH0A+CiwK88oXg1C6gLuBr4dEaNN5gR8KSK2nkSMZhPyTMPqZhC4nHTbz1dyw7ozSUtUgx28zgDwiXweoQf4YD7+BLBA0jvy/qeBP+bth4F1wPaIGCbNBBbRprOopHMjYkdE3AwMA2eP+Zb1wN6IuLvp2Fbg+twCG0nvzF2RzaaMZxpWN/tI/zV155hjZ3R4//X7gFWkcxl/JS1zEREvSroG+IWk04BHgB/k5+wgLW8N5P29wFujfdfQjZIWkmYPvwMeBVY0Pf514LG8FAXpHMjtwALSyXyRik1tbmlq08Ndbs3MrDAvT5mZWWEuGmZmVpiLhpmZFeaiYWZmhblomJlZYS4aZmZWmIuGmZkV9l+czWe8T6Rf8wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "vbgOyEPrAXL0",
        "outputId": "ea738903-9330-4aa0-f61d-e0c6476b49ba"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "window_size = 7\n",
        "EMBEDDING_LENGTH = 30\n",
        "\n",
        "for o_weight in tqdm(np.arange(0.05, 1.0000001, 0.05)):\n",
        "    corpus = Corpus() \n",
        "\n",
        "    corpus.fit(df['tokens'], window=window_size)\n",
        "\n",
        "    glove = Glove(no_components=EMBEDDING_LENGTH, learning_rate=0.05) \n",
        "    glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=False)\n",
        "    glove.add_dictionary(corpus.dictionary)\n",
        "    for d in all_dfs:\n",
        "        d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "        d['int_tokens'] = d.apply(find_glove_token, axis=1)\n",
        "    \n",
        "    catboost_x_train = []\n",
        "    catboost_y_train = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_train.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    train.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    catboost_x_test = []\n",
        "    catboost_y_test = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_test.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    test.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    cb = CatBoostClassifier(verbose=False, class_weights=[1] * 15 + [o_weight], iterations=1000)\n",
        "    cb.fit(catboost_x_train, catboost_y_train)\n",
        "    pred = cb.predict(catboost_x_test)\n",
        "    f1_scores.append(f1_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    precision_scores.append(precision_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    recall_scores.append(recall_score(catboost_y_test, pred, average='weighted', labels=int_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-37f87f8030ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo_weight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatboost_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatboost_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatboost_x_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mf1_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatboost_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4539\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   4540\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4541\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   4542\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m             )\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7aD5-aKAXL-"
      },
      "source": [
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), f1_scores, label='f1')\n",
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), precision_scores, label='precision')\n",
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), recall_scores, label='recall')\n",
        "plt.title('Metrics dependency on O weight')\n",
        "plt.xlabel('O weight')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2QR8DRAXm2t"
      },
      "source": [
        "## GLOVE (fixed, window=7, O_weight=0.5) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgjHucwQXm23",
        "outputId": "3ed31d34-b212-4ae2-e997-661c05f17848"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=7)\n",
        "\n",
        "glove = Glove(no_components=20, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0SQSRAZXm23",
        "outputId": "94c3f3c0-d846-467f-acbd-d1c28e63c338"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 12\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByE22v1wXm24",
        "outputId": "10e5bbb3-f811-4caf-e96d-37e87e5b8b56"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 12\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WflxHpukXm24"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1] * 15 + [0.5], iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrjV1cLjXm24",
        "outputId": "4899ff90-913d-4bc4-e6ac-65c4c33a2820"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6207    0.4800    0.5414       150\n",
            " I-DOCAGRDATE     0.7241    0.7159    0.7200        88\n",
            "  B-DOCAGRNUM     0.7183    0.5698    0.6355       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8635    0.6870    0.7652      1243\n",
            "  I-DOCAMOUNT     0.7763    0.6774    0.7235       620\n",
            "    B-DOCCPTY     0.8364    0.8420    0.8392       595\n",
            "    I-DOCCPTY     0.8642    0.8688    0.8665       564\n",
            " B-DOCCPTYINN     0.9538    0.8794    0.9151       282\n",
            "B-DOCCUSTOMER     0.9642    0.8834    0.9220       609\n",
            "I-DOCCUSTOMER     0.9568    0.9113    0.9335       462\n",
            "    B-DOCDATE     0.8501    0.8000    0.8243       645\n",
            "    I-DOCDATE     0.8894    0.9438    0.9158       605\n",
            "     B-DOCNUM     0.8568    0.6252    0.7229       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8639    0.7772    0.8183      6700\n",
            "    macro avg     0.7916    0.6970    0.7368      6700\n",
            " weighted avg     0.8619    0.7772    0.8147      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9bT06PkUHFB"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}