{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "PAD_W2V_BILSTM_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g-czVy0ksd9",
        "outputId": "8f893adc-4449-4319-eb7d-a2fd9ccdee83"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raJ-rDdCJt_",
        "outputId": "40d1acf9-b8c6-4f39-8086-cc543804c793"
      },
      "source": [
        "!pip install 'h5py<3.0.0'\n",
        "!pip install sklearn_crfsuite\n",
        "# !pip install tensorflow==1.15.2 keras==2.3.1\n",
        "!pip3 install glove-python-binary\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git --upgrade\n",
        "!pip install catboost"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py<3.0.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.15.0)\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-8htbvmwy\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-8htbvmwy\n",
            "Requirement already satisfied, skipping upgrade: keras in /tensorflow-1.15.2/python3.7 (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=dfedae816658150521228942c652782d6dcf745af46a703948d8f80fda9d7020\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-67s8ndxf/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "  Found existing installation: keras-contrib 2.0.8\n",
            "    Uninstalling keras-contrib-2.0.8:\n",
            "      Successfully uninstalled keras-contrib-2.0.8\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx7wVx0OiYyv",
        "outputId": "ca8c28d9-44ad-4586-b57d-3c93424a627c"
      },
      "source": [
        "!gdown --id 1cCXjHX9FAgouF0DWuWPO5qyBHVZDkXTQ\n",
        "!gdown --id 1RFNBRcly96omdpNtYlEK6O1EuQs3ux7t\n",
        "!gdown --id 1AnLqXtSyJNBK7YmwuW6L6z2OYhE4RPTV"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cCXjHX9FAgouF0DWuWPO5qyBHVZDkXTQ\n",
            "To: /content/NER_PAD_agg_test.csv\n",
            "2.92MB [00:00, 13.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RFNBRcly96omdpNtYlEK6O1EuQs3ux7t\n",
            "To: /content/NER_PAD_agg_train.csv\n",
            "11.7MB [00:00, 25.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AnLqXtSyJNBK7YmwuW6L6z2OYhE4RPTV\n",
            "To: /content/NER_PAD_agg.csv\n",
            "14.6MB [00:00, 31.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEfFyYZVph-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15b5265-4073-4d60-ffad-cbbcf364de97"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "import gensim.downloader as api\n",
        "import matplotlib.pyplot as plt\n",
        "from catboost import CatBoostClassifier\n",
        "from gensim.models import Word2Vec\n",
        "from glove import Corpus, Glove\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYiqiimi1vV"
      },
      "source": [
        "df = pd.read_csv('NER_PAD_agg.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "train = pd.read_csv('NER_PAD_agg_train.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "test = pd.read_csv('NER_PAD_agg_test.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "\n",
        "all_dfs = [df, train, test]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz_dGApGKoB"
      },
      "source": [
        "def find_token(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ', '']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in w2v.wv.vocab.keys():\n",
        "                res.append(w2v.wv.vocab[w + suffix].index)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "all_tags = set()\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "labels = list(tag_to_idx.keys())\n",
        "labels.remove('O')\n",
        "labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
        "int_labels = list(tag_to_idx.values())\n",
        "int_labels.remove(tag_to_idx['O'])\n",
        "int_labels = sorted(int_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAl784dWnJkR"
      },
      "source": [
        "pretrained_w2v = api.load(\"word2vec-ruscorpora-300\")\n",
        "pretrained_w2v.save_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthif1zkvsok"
      },
      "source": [
        "def add_suffix(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in pretrained_w2v.vocab.keys():\n",
        "                res.append(w + suffix)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(w)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['tokens_with_suffix'] = d.apply(add_suffix, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rp-IeYsnJf"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v = Word2Vec(sentences=df['tokens_with_suffix'], size=300, window=15, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqqSfYYmY-p"
      },
      "source": [
        "w2v.intersect_word2vec_format('tmp')\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wxpfE8Hx0u"
      },
      "source": [
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "J7BswpbHlVW2",
        "outputId": "672d4988-7fd4-4103-97a8-8c39d426d070"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>tokens_with_suffix</th>\n",
              "      <th>encoded_ner_tags</th>\n",
              "      <th>int_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SV990125172_ОРГ__INM_18'09'58_1.pdf</td>\n",
              "      <td>[l, *, универсальный, приложение, №, 1, постан...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...</td>\n",
              "      <td>[l, *, универсальный_ADJ, приложение_NOUN, №, ...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 66, 494, 64, 1, 0, 83, 59, 94, 2904, 441, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SS528581_ОРГ__INM_17'05'39_A.pdf</td>\n",
              "      <td>[l, лист, согласования, стр., 1, 1, 2, 9, *, 0...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, лист_NOUN, согласования, стр., 1, 1, 2, 9,...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 47, 35, 193, 0, 0, 4, 41, 66, 11, 17, 113,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SF435712_ОРГ__INM_15'25'41_A.pdf</td>\n",
              "      <td>[l, приложение, №, постановлению, правительств...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-DOCNUM, B-DOCDAT...</td>\n",
              "      <td>[l, приложение_NOUN, №, постановлению, правите...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 7, 6, 13,...</td>\n",
              "      <td>[3, 64, 1, 83, 59, 290, 1752, 74, 1, 0, 133, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SV990124943_ОРГ__INM_19'00'43_A.pdf</td>\n",
              "      <td>[l, акционерное, общество, регистраторское, об...</td>\n",
              "      <td>[O, O, O, O, O, B-DOCCPTY, O, O, O, O, O, O, O...</td>\n",
              "      <td>[l, акционерное, общество_NOUN, регистраторско...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 3, 15, 15, 15, 15, 15, 15...</td>\n",
              "      <td>[3, 112, 43, 6621, 43, 1315, 0, 56, 80, 0, 189...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S29013419_ОРИГИНАЛ__IND_1_22.05.12'21'36.pdf</td>\n",
              "      <td>[l, *, 000стандарт, безопасности, адрес:, 1973...</td>\n",
              "      <td>[O, O, O, B-DOCCPTY, O, O, O, O, O, O, O, O, O...</td>\n",
              "      <td>[l, *, 000стандарт, безопасности, адрес:, 1973...</td>\n",
              "      <td>[15, 15, 15, 3, 15, 15, 15, 15, 15, 15, 15, 15...</td>\n",
              "      <td>[3, 66, 14721, 4486, 28, 2677, 277, 1137, 8911...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>SV990121575_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, стс, отчет, роялти, 2, к...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-DOCAGRNUM,...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, стс_NOUN, отчет_NOU...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 418, 970, 1293, 4, 1828, 1537, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>SV990121572_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, ао, стс, отчет, роялти, 3, квартал, лиценз...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, ао_NOUN, стс_NOUN, отчет_NOUN, роялти_NOUN...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 67, 418, 970, 1293, 14, 1828, 1537, 93, 1,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>SV990121520_ОРГ__INM_16'31'06_3.pdf</td>\n",
              "      <td>[l, экземпляр, ао, стс, ао, стс, отчет, роялти...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-D...</td>\n",
              "      <td>[l, экземпляр_NOUN, ао_NOUN, стс_NOUN, ао_NOUN...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 67, 418, 67, 418, 970, 1293, 14, 1787...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>SV990121573_ОРГ__INM_18'45'08_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, стс, отчет, п, роялти, 4...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, стс_NOUN, отчет_NOU...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 418, 970, 19, 1293, 17, 0, 16, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>SV990121764_ОРГ__INM_17'56'07_3.pdf</td>\n",
              "      <td>[l, экземпляр, аостс, ао, стс, отчет, роялти, ...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[l, экземпляр_NOUN, аостс, ао_NOUN, стс_NOUN, ...</td>\n",
              "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
              "      <td>[3, 361, 8542, 67, 418, 970, 1293, 17, 1828, 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                id  ...                                         int_tokens\n",
              "0              SV990125172_ОРГ__INM_18'09'58_1.pdf  ...  [3, 66, 494, 64, 1, 0, 83, 59, 94, 2904, 441, ...\n",
              "1                 SS528581_ОРГ__INM_17'05'39_A.pdf  ...  [3, 47, 35, 193, 0, 0, 4, 41, 66, 11, 17, 113,...\n",
              "2                 SF435712_ОРГ__INM_15'25'41_A.pdf  ...  [3, 64, 1, 83, 59, 290, 1752, 74, 1, 0, 133, 2...\n",
              "3              SV990124943_ОРГ__INM_19'00'43_A.pdf  ...  [3, 112, 43, 6621, 43, 1315, 0, 56, 80, 0, 189...\n",
              "4     S29013419_ОРИГИНАЛ__IND_1_22.05.12'21'36.pdf  ...  [3, 66, 14721, 4486, 28, 2677, 277, 1137, 8911...\n",
              "...                                            ...  ...                                                ...\n",
              "3995           SV990121575_ОРГ__INM_18'45'08_3.pdf  ...  [3, 361, 8542, 418, 970, 1293, 4, 1828, 1537, ...\n",
              "3996           SV990121572_ОРГ__INM_18'45'08_3.pdf  ...  [3, 67, 418, 970, 1293, 14, 1828, 1537, 93, 1,...\n",
              "3997           SV990121520_ОРГ__INM_16'31'06_3.pdf  ...  [3, 361, 67, 418, 67, 418, 970, 1293, 14, 1787...\n",
              "3998           SV990121573_ОРГ__INM_18'45'08_3.pdf  ...  [3, 361, 8542, 418, 970, 19, 1293, 17, 0, 16, ...\n",
              "3999           SV990121764_ОРГ__INM_17'56'07_3.pdf  ...  [3, 361, 8542, 67, 418, 970, 1293, 17, 1828, 2...\n",
              "\n",
              "[4000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QUuM6AhjxyK"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBokW5kspLO"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=1.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JNx5ntzrHuK"
      },
      "source": [
        "## PRETRAINED W2V(not fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1S7oW2BWoX",
        "outputId": "4dda30a0-9d48-4bea-ec6f-3f41e6141f9e"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 7,765,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVZ0buRG02d",
        "outputId": "56b4ab23-0b7d-4b07-db10-5c954a1051bd"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 42s 15ms/step - loss: 0.7843 - crf_marginal_accuracy: 0.2648 - val_loss: 0.6091 - val_crf_marginal_accuracy: 0.8945\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.5570 - crf_marginal_accuracy: 0.4671 - val_loss: 0.4561 - val_crf_marginal_accuracy: 0.1528\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.4077 - crf_marginal_accuracy: 0.7324 - val_loss: 0.3206 - val_crf_marginal_accuracy: 0.9415\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2823 - crf_marginal_accuracy: 0.9513 - val_loss: 0.2279 - val_crf_marginal_accuracy: 0.9590\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2018 - crf_marginal_accuracy: 0.9687 - val_loss: 0.1798 - val_crf_marginal_accuracy: 0.9683\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.1508 - crf_marginal_accuracy: 0.9790 - val_loss: 0.1489 - val_crf_marginal_accuracy: 0.9835\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1154 - crf_marginal_accuracy: 0.9873 - val_loss: 0.1329 - val_crf_marginal_accuracy: 0.9911\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0918 - crf_marginal_accuracy: 0.9924 - val_loss: 0.1295 - val_crf_marginal_accuracy: 0.9934\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0763 - crf_marginal_accuracy: 0.9941 - val_loss: 0.1267 - val_crf_marginal_accuracy: 0.9946\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0645 - crf_marginal_accuracy: 0.9958 - val_loss: 0.1261 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0561 - crf_marginal_accuracy: 0.9967 - val_loss: 0.1275 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0488 - crf_marginal_accuracy: 0.9971 - val_loss: 0.1371 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0436 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1413 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0393 - crf_marginal_accuracy: 0.9977 - val_loss: 0.1397 - val_crf_marginal_accuracy: 0.9963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNVGThAXHeL",
        "outputId": "d8c06f13-9243-4bb8-8d33-01d4b2c51808"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6794    0.5933    0.6335       150\n",
            " I-DOCAGRDATE     0.6455    0.8068    0.7172        88\n",
            "  B-DOCAGRNUM     0.6899    0.6089    0.6469       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.7548    0.5350    0.6262      1243\n",
            "  I-DOCAMOUNT     0.7153    0.5065    0.5930       620\n",
            "    B-DOCCPTY     0.8613    0.8874    0.8742       595\n",
            "    I-DOCCPTY     0.8724    0.8972    0.8846       564\n",
            " B-DOCCPTYINN     0.8170    0.9184    0.8648       282\n",
            "B-DOCCUSTOMER     0.9111    0.8916    0.9012       609\n",
            "I-DOCCUSTOMER     0.9326    0.9286    0.9306       462\n",
            "    B-DOCDATE     0.8528    0.8264    0.8394       645\n",
            "    I-DOCDATE     0.8561    0.9636    0.9067       605\n",
            "     B-DOCNUM     0.8995    0.6052    0.7236       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8331    0.7497    0.7892      6700\n",
            "    macro avg     0.6992    0.6646    0.6761      6700\n",
            " weighted avg     0.8266    0.7497    0.7795      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8_PPi6mrQe7"
      },
      "source": [
        "## PRETRAINED W2V(fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV6QMPc3cyy",
        "outputId": "aa167467-2cc7-4ece-b0ae-1bd7429b59c9"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 324,576\n",
            "Non-trainable params: 7,440,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19U1yO8c3czD",
        "outputId": "377dd469-e2c0-4f72-8d42-af99f46e74ee"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 40s 14ms/step - loss: 0.7059 - crf_marginal_accuracy: 0.0202 - val_loss: 0.4837 - val_crf_marginal_accuracy: 0.8589\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.4329 - crf_marginal_accuracy: 0.7772 - val_loss: 0.3297 - val_crf_marginal_accuracy: 0.9113\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3150 - crf_marginal_accuracy: 0.9315 - val_loss: 0.2545 - val_crf_marginal_accuracy: 0.9360\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2577 - crf_marginal_accuracy: 0.9472 - val_loss: 0.2153 - val_crf_marginal_accuracy: 0.9522\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2233 - crf_marginal_accuracy: 0.9555 - val_loss: 0.1925 - val_crf_marginal_accuracy: 0.9511\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1989 - crf_marginal_accuracy: 0.9563 - val_loss: 0.1797 - val_crf_marginal_accuracy: 0.9571\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1805 - crf_marginal_accuracy: 0.9590 - val_loss: 0.1680 - val_crf_marginal_accuracy: 0.9595\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1662 - crf_marginal_accuracy: 0.9616 - val_loss: 0.1587 - val_crf_marginal_accuracy: 0.9582\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1539 - crf_marginal_accuracy: 0.9648 - val_loss: 0.1530 - val_crf_marginal_accuracy: 0.9641\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1435 - crf_marginal_accuracy: 0.9674 - val_loss: 0.1448 - val_crf_marginal_accuracy: 0.9694\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1332 - crf_marginal_accuracy: 0.9706 - val_loss: 0.1395 - val_crf_marginal_accuracy: 0.9714\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1249 - crf_marginal_accuracy: 0.9731 - val_loss: 0.1364 - val_crf_marginal_accuracy: 0.9758\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1170 - crf_marginal_accuracy: 0.9756 - val_loss: 0.1336 - val_crf_marginal_accuracy: 0.9771\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1113 - crf_marginal_accuracy: 0.9785 - val_loss: 0.1293 - val_crf_marginal_accuracy: 0.9788\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1071 - crf_marginal_accuracy: 0.9804 - val_loss: 0.1286 - val_crf_marginal_accuracy: 0.9825\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1051 - crf_marginal_accuracy: 0.9813 - val_loss: 0.1270 - val_crf_marginal_accuracy: 0.9823\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1001 - crf_marginal_accuracy: 0.9834 - val_loss: 0.1222 - val_crf_marginal_accuracy: 0.9848\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0947 - crf_marginal_accuracy: 0.9840 - val_loss: 0.1207 - val_crf_marginal_accuracy: 0.9852\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0904 - crf_marginal_accuracy: 0.9859 - val_loss: 0.1225 - val_crf_marginal_accuracy: 0.9882\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0863 - crf_marginal_accuracy: 0.9872 - val_loss: 0.1179 - val_crf_marginal_accuracy: 0.9860\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0825 - crf_marginal_accuracy: 0.9873 - val_loss: 0.1227 - val_crf_marginal_accuracy: 0.9910\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0806 - crf_marginal_accuracy: 0.9885 - val_loss: 0.1185 - val_crf_marginal_accuracy: 0.9887\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.0775 - crf_marginal_accuracy: 0.9895 - val_loss: 0.1160 - val_crf_marginal_accuracy: 0.9881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU37zLsF3czD",
        "outputId": "e9247091-2863-448a-ff86-e11901312b16"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.3111    0.5600    0.4000       150\n",
            " I-DOCAGRDATE     0.5426    0.7955    0.6452        88\n",
            "  B-DOCAGRNUM     0.2834    0.6760    0.3993       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.3086    0.7385    0.4353      1243\n",
            "  I-DOCAMOUNT     0.4029    0.8565    0.5480       620\n",
            "    B-DOCCPTY     0.4643    0.8420    0.5986       595\n",
            "    I-DOCCPTY     0.6881    0.8528    0.7617       564\n",
            " B-DOCCPTYINN     0.5408    0.8936    0.6738       282\n",
            "B-DOCCUSTOMER     0.7301    0.8752    0.7961       609\n",
            "I-DOCCUSTOMER     0.7712    0.9264    0.8417       462\n",
            "    B-DOCDATE     0.5693    0.7705    0.6548       645\n",
            "    I-DOCDATE     0.7568    0.9719    0.8509       605\n",
            "     B-DOCNUM     0.6560    0.6298    0.6426       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.4957    0.8081    0.6144      6700\n",
            "    macro avg     0.4683    0.6926    0.5499      6700\n",
            " weighted avg     0.5445    0.8081    0.6379      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0M6U9bFpeSI"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRins3GMDd-"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYv7a7bMMEI",
        "outputId": "5cf862b4-b74f-4bda-a268-d87467f8e31b"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_5 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 1,364,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9AHayBOMMEK",
        "outputId": "f2274436-5e80-42b3-f705-f0e9c1c6b91d"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 43s 15ms/step - loss: 0.7996 - crf_marginal_accuracy: 0.5780 - val_loss: 0.6023 - val_crf_marginal_accuracy: 0.9577\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5411 - crf_marginal_accuracy: 0.9492 - val_loss: 0.4425 - val_crf_marginal_accuracy: 0.9568\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.4049 - crf_marginal_accuracy: 0.9545 - val_loss: 0.3401 - val_crf_marginal_accuracy: 0.9477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cofffkTqMMEK",
        "outputId": "d7add6bf-2683-492f-a5dd-a618f1947794"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.0000    0.0000    0.0000       150\n",
            " I-DOCAGRDATE     0.0000    0.0000    0.0000        88\n",
            "  B-DOCAGRNUM     0.0008    0.0056    0.0013       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.0615    0.8294    0.1145      1243\n",
            "  I-DOCAMOUNT     0.0000    0.0000    0.0000       620\n",
            "    B-DOCCPTY     0.0642    0.6286    0.1165       595\n",
            "    I-DOCCPTY     0.0000    0.0000    0.0000       564\n",
            " B-DOCCPTYINN     0.0000    0.0000    0.0000       282\n",
            "B-DOCCUSTOMER     0.0481    0.1839    0.0763       609\n",
            "I-DOCCUSTOMER     0.8505    0.3571    0.5030       462\n",
            "    B-DOCDATE     0.1011    0.4620    0.1659       645\n",
            "    I-DOCDATE     0.3557    0.5686    0.4377       605\n",
            "     B-DOCNUM     0.4756    0.3886    0.4277       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.0834    0.3848    0.1371      6700\n",
            "    macro avg     0.1305    0.2283    0.1229      6700\n",
            " weighted avg     0.1682    0.3848    0.1703      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9pIp5Zpjqo"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKFIa_0IMMEL",
        "outputId": "fdc82936-b2c0-4ab0-9cb9-881f85b19cdb"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_6 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 1,240,150\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSFEq-vMMEL",
        "outputId": "629f89bf-4641-4758-bc2d-b4aba5106a27"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 42s 15ms/step - loss: 0.8119 - crf_marginal_accuracy: 0.1154 - val_loss: 0.6221 - val_crf_marginal_accuracy: 0.8025\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.5348 - crf_marginal_accuracy: 0.2231 - val_loss: 0.3944 - val_crf_marginal_accuracy: 0.8941\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3438 - crf_marginal_accuracy: 0.9376 - val_loss: 0.2690 - val_crf_marginal_accuracy: 0.9606\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2541 - crf_marginal_accuracy: 0.9644 - val_loss: 0.2149 - val_crf_marginal_accuracy: 0.9663\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.2091 - crf_marginal_accuracy: 0.9677 - val_loss: 0.1809 - val_crf_marginal_accuracy: 0.9699\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1821 - crf_marginal_accuracy: 0.9694 - val_loss: 0.1622 - val_crf_marginal_accuracy: 0.9708\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1655 - crf_marginal_accuracy: 0.9750 - val_loss: 0.1511 - val_crf_marginal_accuracy: 0.9735\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1521 - crf_marginal_accuracy: 0.9766 - val_loss: 0.1438 - val_crf_marginal_accuracy: 0.9756\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1422 - crf_marginal_accuracy: 0.9779 - val_loss: 0.1350 - val_crf_marginal_accuracy: 0.9813\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1331 - crf_marginal_accuracy: 0.9799 - val_loss: 0.1302 - val_crf_marginal_accuracy: 0.9804\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1258 - crf_marginal_accuracy: 0.9817 - val_loss: 0.1270 - val_crf_marginal_accuracy: 0.9823\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1203 - crf_marginal_accuracy: 0.9824 - val_loss: 0.1251 - val_crf_marginal_accuracy: 0.9801\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1155 - crf_marginal_accuracy: 0.9836 - val_loss: 0.1237 - val_crf_marginal_accuracy: 0.9858\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1125 - crf_marginal_accuracy: 0.9845 - val_loss: 0.1200 - val_crf_marginal_accuracy: 0.9853\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.1071 - crf_marginal_accuracy: 0.9863 - val_loss: 0.1166 - val_crf_marginal_accuracy: 0.9847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-v-3tFMMEL",
        "outputId": "16ca3ffc-94e5-4b71-fa29-bd72c4e5eb5e"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.2329    0.5667    0.3301       150\n",
            " I-DOCAGRDATE     0.5431    0.7159    0.6176        88\n",
            "  B-DOCAGRNUM     0.3551    0.6369    0.4560       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.2534    0.7739    0.3818      1243\n",
            "  I-DOCAMOUNT     0.3079    0.8000    0.4446       620\n",
            "    B-DOCCPTY     0.5005    0.8672    0.6347       595\n",
            "    I-DOCCPTY     0.6462    0.8936    0.7500       564\n",
            " B-DOCCPTYINN     0.3796    0.9220    0.5377       282\n",
            "B-DOCCUSTOMER     0.4562    0.8883    0.6028       609\n",
            "I-DOCCUSTOMER     0.5298    0.9632    0.6836       462\n",
            "    B-DOCDATE     0.3298    0.8248    0.4712       645\n",
            "    I-DOCDATE     0.6376    0.9802    0.7726       605\n",
            "     B-DOCNUM     0.2767    0.6805    0.3934       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.3734    0.8290    0.5149      6700\n",
            "    macro avg     0.3632    0.7009    0.4718      6700\n",
            " weighted avg     0.4064    0.8290    0.5371      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKJI4oy3hzMT"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=5, min_count=2) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id2BNTd0n0-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87019e3b-cd7d-4c14-d398-d93a2a223715"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZbGJKwZwPNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d07909-d73e-41fd-8771-f4ed428e053d"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFFhboVQs9BR"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OamBx6BudKo",
        "outputId": "990510e4-9449-4e5b-f13e-5a1d1e892adc"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7111    0.4267    0.5333       150\n",
            " I-DOCAGRDATE     0.8028    0.6477    0.7170        88\n",
            "  B-DOCAGRNUM     0.7951    0.5419    0.6445       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8944    0.6340    0.7420      1243\n",
            "  I-DOCAMOUNT     0.8079    0.5903    0.6822       620\n",
            "    B-DOCCPTY     0.8986    0.8336    0.8649       595\n",
            "    I-DOCCPTY     0.8971    0.8191    0.8563       564\n",
            " B-DOCCPTYINN     0.9643    0.8617    0.9101       282\n",
            "B-DOCCUSTOMER     0.9805    0.9080    0.9429       609\n",
            "I-DOCCUSTOMER     0.9387    0.9286    0.9336       462\n",
            "    B-DOCDATE     0.8794    0.7798    0.8266       645\n",
            "    I-DOCDATE     0.8691    0.8777    0.8734       605\n",
            "     B-DOCNUM     0.8860    0.6206    0.7299       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8923    0.7458    0.8125      6700\n",
            "    macro avg     0.8217    0.6694    0.7323      6700\n",
            " weighted avg     0.8884    0.7458    0.8068      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Rxo5d1o93d"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGPObsQWal6"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=1)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDnQ8VNWal-",
        "outputId": "94fc9941-4e7e-41f7-80f3-8a5810d0630d"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_7 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 3,450,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqCw-lOWamB",
        "outputId": "11bcb9d6-7063-4d84-9f73-e901516a8acc"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='window=5,min_count=1,best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('window=5,min_count=1,best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 44s 15ms/step - loss: 0.8051 - crf_marginal_accuracy: 0.1195 - val_loss: 0.6141 - val_crf_marginal_accuracy: 0.8147\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5369 - crf_marginal_accuracy: 0.8713 - val_loss: 0.3980 - val_crf_marginal_accuracy: 0.9200\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3585 - crf_marginal_accuracy: 0.9483 - val_loss: 0.2807 - val_crf_marginal_accuracy: 0.9671\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2715 - crf_marginal_accuracy: 0.9674 - val_loss: 0.2284 - val_crf_marginal_accuracy: 0.9650\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2207 - crf_marginal_accuracy: 0.9689 - val_loss: 0.1927 - val_crf_marginal_accuracy: 0.9749\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1837 - crf_marginal_accuracy: 0.9760 - val_loss: 0.1668 - val_crf_marginal_accuracy: 0.9741\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1558 - crf_marginal_accuracy: 0.9791 - val_loss: 0.1491 - val_crf_marginal_accuracy: 0.9791\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1353 - crf_marginal_accuracy: 0.9830 - val_loss: 0.1370 - val_crf_marginal_accuracy: 0.9817\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1179 - crf_marginal_accuracy: 0.9855 - val_loss: 0.1261 - val_crf_marginal_accuracy: 0.9897\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1027 - crf_marginal_accuracy: 0.9879 - val_loss: 0.1183 - val_crf_marginal_accuracy: 0.9917\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0910 - crf_marginal_accuracy: 0.9914 - val_loss: 0.1138 - val_crf_marginal_accuracy: 0.9873\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0811 - crf_marginal_accuracy: 0.9921 - val_loss: 0.1085 - val_crf_marginal_accuracy: 0.9918\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0725 - crf_marginal_accuracy: 0.9935 - val_loss: 0.1088 - val_crf_marginal_accuracy: 0.9944\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0658 - crf_marginal_accuracy: 0.9950 - val_loss: 0.1078 - val_crf_marginal_accuracy: 0.9941\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0602 - crf_marginal_accuracy: 0.9955 - val_loss: 0.1077 - val_crf_marginal_accuracy: 0.9945\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0544 - crf_marginal_accuracy: 0.9962 - val_loss: 0.1052 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0504 - crf_marginal_accuracy: 0.9966 - val_loss: 0.1101 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0459 - crf_marginal_accuracy: 0.9970 - val_loss: 0.1107 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0429 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1161 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0398 - crf_marginal_accuracy: 0.9975 - val_loss: 0.1097 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0377 - crf_marginal_accuracy: 0.9977 - val_loss: 0.1104 - val_crf_marginal_accuracy: 0.9959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCujGbXWamC",
        "outputId": "c38d4dff-a2bf-4676-b80a-60898b87d4b6"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7090    0.6333    0.6690       150\n",
            " I-DOCAGRDATE     0.7416    0.7500    0.7458        88\n",
            "  B-DOCAGRNUM     0.5857    0.6872    0.6324       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.7106    0.6854    0.6978      1243\n",
            "  I-DOCAMOUNT     0.7516    0.5710    0.6489       620\n",
            "    B-DOCCPTY     0.8000    0.9076    0.8504       595\n",
            "    I-DOCCPTY     0.8257    0.8989    0.8608       564\n",
            " B-DOCCPTYINN     0.8810    0.9184    0.8993       282\n",
            "B-DOCCUSTOMER     0.9165    0.9015    0.9089       609\n",
            "I-DOCCUSTOMER     0.8459    0.9502    0.8950       462\n",
            "    B-DOCDATE     0.7926    0.8651    0.8273       645\n",
            "    I-DOCDATE     0.8428    0.9570    0.8963       605\n",
            "     B-DOCNUM     0.6849    0.6544    0.6693       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.7844    0.7981    0.7912      6700\n",
            "    macro avg     0.6725    0.6920    0.6801      6700\n",
            " weighted avg     0.7809    0.7981    0.7869      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1mf60mpD9t"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jRCZwwNWamC",
        "outputId": "6ea57dd7-bb9c-4fd0-f3e3-47bfd3fc96c6"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_8 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 3,325,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy3tg6aWamD",
        "outputId": "1ccb74fd-1d93-470c-ab7b-997c87cc224e"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='window=5,min_count=1,best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('window=5,min_count=1,best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 43s 15ms/step - loss: 0.7155 - crf_marginal_accuracy: 0.0766 - val_loss: 0.4706 - val_crf_marginal_accuracy: 0.1218\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.4088 - crf_marginal_accuracy: 0.8213 - val_loss: 0.3148 - val_crf_marginal_accuracy: 0.9399\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 36s 13ms/step - loss: 0.3034 - crf_marginal_accuracy: 0.9476 - val_loss: 0.2484 - val_crf_marginal_accuracy: 0.9595\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2486 - crf_marginal_accuracy: 0.9584 - val_loss: 0.2087 - val_crf_marginal_accuracy: 0.9615\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.2117 - crf_marginal_accuracy: 0.9630 - val_loss: 0.1809 - val_crf_marginal_accuracy: 0.9632\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1870 - crf_marginal_accuracy: 0.9672 - val_loss: 0.1653 - val_crf_marginal_accuracy: 0.9686\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1695 - crf_marginal_accuracy: 0.9703 - val_loss: 0.1540 - val_crf_marginal_accuracy: 0.9721\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1567 - crf_marginal_accuracy: 0.9728 - val_loss: 0.1452 - val_crf_marginal_accuracy: 0.9715\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1451 - crf_marginal_accuracy: 0.9743 - val_loss: 0.1357 - val_crf_marginal_accuracy: 0.9761\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1363 - crf_marginal_accuracy: 0.9771 - val_loss: 0.1348 - val_crf_marginal_accuracy: 0.9804\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1343 - crf_marginal_accuracy: 0.9788 - val_loss: 0.1303 - val_crf_marginal_accuracy: 0.9724\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.1269 - crf_marginal_accuracy: 0.9798 - val_loss: 0.1262 - val_crf_marginal_accuracy: 0.9796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuStVCRzWamD",
        "outputId": "bc161a4d-07ef-4dd9-eaa7-76f67a293807"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.2707    0.6333    0.3792       150\n",
            " I-DOCAGRDATE     0.3730    0.5341    0.4393        88\n",
            "  B-DOCAGRNUM     0.2243    0.6592    0.3348       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.1402    0.8142    0.2392      1243\n",
            "  I-DOCAMOUNT     0.3796    0.6919    0.4903       620\n",
            "    B-DOCCPTY     0.4909    0.8605    0.6252       595\n",
            "    I-DOCCPTY     0.4819    0.8493    0.6149       564\n",
            " B-DOCCPTYINN     0.1714    0.9504    0.2904       282\n",
            "B-DOCCUSTOMER     0.3422    0.8686    0.4910       609\n",
            "I-DOCCUSTOMER     0.5100    0.9372    0.6606       462\n",
            "    B-DOCDATE     0.3530    0.7318    0.4763       645\n",
            "    I-DOCDATE     0.6935    0.9686    0.8083       605\n",
            "     B-DOCNUM     0.3574    0.6621    0.4642       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.2888    0.8076    0.4255      6700\n",
            "    macro avg     0.3192    0.6774    0.4209      6700\n",
            " weighted avg     0.3671    0.8076    0.4866      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL_5lS1paJ1a"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=5, min_count=1) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFV0gNT-aJ1a",
        "outputId": "e6ca564b-0294-40c2-edb7-800ab7f56dcf"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7-nO8i6aJ1a",
        "outputId": "a8acfdf7-1420-4165-f7c1-6dab1ee7ff6e"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swuyMDFUaJ1a"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKofLJ1uaJ1b",
        "outputId": "97124c0f-ed48-4e19-f895-0b9c0d6169aa"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6951    0.3800    0.4914       150\n",
            " I-DOCAGRDATE     0.7536    0.5909    0.6624        88\n",
            "  B-DOCAGRNUM     0.7611    0.4804    0.5890       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8804    0.6098    0.7205      1243\n",
            "  I-DOCAMOUNT     0.8186    0.5677    0.6705       620\n",
            "    B-DOCCPTY     0.8909    0.8101    0.8486       595\n",
            "    I-DOCCPTY     0.8745    0.7908    0.8305       564\n",
            " B-DOCCPTYINN     0.9492    0.8617    0.9033       282\n",
            "B-DOCCUSTOMER     0.9773    0.9179    0.9467       609\n",
            "I-DOCCUSTOMER     0.9283    0.9242    0.9262       462\n",
            "    B-DOCDATE     0.8795    0.7581    0.8143       645\n",
            "    I-DOCDATE     0.8645    0.8860    0.8751       605\n",
            "     B-DOCNUM     0.8874    0.5929    0.7109       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8853    0.7279    0.7989      6700\n",
            "    macro avg     0.8107    0.6495    0.7145      6700\n",
            " weighted avg     0.8804    0.7279    0.7916      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM_XIWpKsCPI"
      },
      "source": [
        "## W2V(not fixed, window=25) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgm2UrFtuT9p"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=25, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si5Zc-UjuEN3",
        "outputId": "83411ac4-15fc-4e9c-c615-a2308b5624bf"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_11 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 1,364,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EN4RSuMuEN9",
        "outputId": "a2d5ce52-be7e-4325-8c07-1b01d8081a7f"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 47s 16ms/step - loss: 0.8186 - crf_marginal_accuracy: 0.4977 - val_loss: 0.6030 - val_crf_marginal_accuracy: 0.8677\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.5151 - crf_marginal_accuracy: 0.9230 - val_loss: 0.3785 - val_crf_marginal_accuracy: 0.9493\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.3439 - crf_marginal_accuracy: 0.9535 - val_loss: 0.2713 - val_crf_marginal_accuracy: 0.9643\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2601 - crf_marginal_accuracy: 0.9664 - val_loss: 0.2198 - val_crf_marginal_accuracy: 0.9627\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.2130 - crf_marginal_accuracy: 0.9718 - val_loss: 0.1885 - val_crf_marginal_accuracy: 0.9704\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1817 - crf_marginal_accuracy: 0.9755 - val_loss: 0.1658 - val_crf_marginal_accuracy: 0.9685\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1577 - crf_marginal_accuracy: 0.9783 - val_loss: 0.1484 - val_crf_marginal_accuracy: 0.9787\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1379 - crf_marginal_accuracy: 0.9824 - val_loss: 0.1359 - val_crf_marginal_accuracy: 0.9846\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1215 - crf_marginal_accuracy: 0.9859 - val_loss: 0.1267 - val_crf_marginal_accuracy: 0.9828\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1081 - crf_marginal_accuracy: 0.9879 - val_loss: 0.1220 - val_crf_marginal_accuracy: 0.9905\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0954 - crf_marginal_accuracy: 0.9906 - val_loss: 0.1168 - val_crf_marginal_accuracy: 0.9923\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0844 - crf_marginal_accuracy: 0.9927 - val_loss: 0.1097 - val_crf_marginal_accuracy: 0.9926\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0747 - crf_marginal_accuracy: 0.9935 - val_loss: 0.1072 - val_crf_marginal_accuracy: 0.9929\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0671 - crf_marginal_accuracy: 0.9945 - val_loss: 0.1055 - val_crf_marginal_accuracy: 0.9947\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0600 - crf_marginal_accuracy: 0.9956 - val_loss: 0.1032 - val_crf_marginal_accuracy: 0.9948\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0542 - crf_marginal_accuracy: 0.9961 - val_loss: 0.1047 - val_crf_marginal_accuracy: 0.9949\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0493 - crf_marginal_accuracy: 0.9965 - val_loss: 0.1086 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0441 - crf_marginal_accuracy: 0.9970 - val_loss: 0.1080 - val_crf_marginal_accuracy: 0.9957\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0403 - crf_marginal_accuracy: 0.9973 - val_loss: 0.1104 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0372 - crf_marginal_accuracy: 0.9976 - val_loss: 0.1106 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0337 - crf_marginal_accuracy: 0.9978 - val_loss: 0.1103 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.0309 - crf_marginal_accuracy: 0.9980 - val_loss: 0.1143 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9981 - val_loss: 0.1228 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 24/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0287 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1185 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 25/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0272 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1235 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 26/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0246 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1384 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 27/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0229 - crf_marginal_accuracy: 0.9986 - val_loss: 0.1312 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 28/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0207 - crf_marginal_accuracy: 0.9987 - val_loss: 0.1379 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 29/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0186 - crf_marginal_accuracy: 0.9988 - val_loss: 0.1455 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 30/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0175 - crf_marginal_accuracy: 0.9989 - val_loss: 0.1466 - val_crf_marginal_accuracy: 0.9968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGjQQcIDuEN9",
        "outputId": "b7d1c6e2-bc2a-496f-a248-a56ea7caded3"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7302    0.6133    0.6667       150\n",
            " I-DOCAGRDATE     0.7407    0.6818    0.7101        88\n",
            "  B-DOCAGRNUM     0.7708    0.6201    0.6873       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.8131    0.6372    0.7145      1243\n",
            "  I-DOCAMOUNT     0.7747    0.5435    0.6389       620\n",
            "    B-DOCCPTY     0.8921    0.8756    0.8838       595\n",
            "    I-DOCCPTY     0.8540    0.8918    0.8725       564\n",
            " B-DOCCPTYINN     0.9577    0.8830    0.9188       282\n",
            "B-DOCCUSTOMER     0.9513    0.8982    0.9240       609\n",
            "I-DOCCUSTOMER     0.9575    0.9264    0.9417       462\n",
            "    B-DOCDATE     0.8740    0.8171    0.8446       645\n",
            "    I-DOCDATE     0.8887    0.9372    0.9123       605\n",
            "     B-DOCNUM     0.8113    0.6406    0.7159       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8628    0.7688    0.8131      6700\n",
            "    macro avg     0.7344    0.6644    0.6954      6700\n",
            " weighted avg     0.8563    0.7688    0.8071      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpLPjaElaOZH"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=20) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wywjpjwaeB_Z"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=15, window=20, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iksvgnyyaOZH",
        "outputId": "87b343fd-f477-4b5c-fde3-fedcfed12252"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgY_iTw6aOZI",
        "outputId": "9533d0d0-a13b-4258-e9b0-4390c64c5afb"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jsvElhRaOZI"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsP5GT8daOZI",
        "outputId": "33955d8f-e2af-45f7-b4d7-c709f05be77b"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7303    0.4333    0.5439       150\n",
            " I-DOCAGRDATE     0.8194    0.6705    0.7375        88\n",
            "  B-DOCAGRNUM     0.7521    0.4916    0.5946       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.9232    0.6187    0.7408      1243\n",
            "  I-DOCAMOUNT     0.8409    0.5968    0.6981       620\n",
            "    B-DOCCPTY     0.8799    0.8000    0.8380       595\n",
            "    I-DOCCPTY     0.9214    0.8316    0.8742       564\n",
            " B-DOCCPTYINN     0.9567    0.8617    0.9067       282\n",
            "B-DOCCUSTOMER     0.9755    0.8489    0.9078       609\n",
            "I-DOCCUSTOMER     0.9677    0.9091    0.9375       462\n",
            "    B-DOCDATE     0.9004    0.7426    0.8139       645\n",
            "    I-DOCDATE     0.9276    0.9322    0.9299       605\n",
            "     B-DOCNUM     0.9493    0.6037    0.7380       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.9143    0.7337    0.8141      6700\n",
            "    macro avg     0.8363    0.6608    0.7326      6700\n",
            " weighted avg     0.9114    0.7337    0.8079      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtkZiRbasEsK"
      },
      "source": [
        "## GLOVE (not fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNrzxYz3ar3x",
        "outputId": "77c10a8a-f7d7-4f86-a9a0-3148881e3422"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=5)\n",
        "\n",
        "glove = Glove(no_components=50, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtUIADA6a6h-",
        "outputId": "c484044c-f22b-4140-d80f-a2f270ec2f84"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 943, 300)          19955400  \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_12 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_12 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 20,279,976\n",
            "Trainable params: 20,279,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxAndSBa6iK",
        "outputId": "eb750725-ec07-4ef3-be26-5377e8cfdcba"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 48s 17ms/step - loss: 0.9013 - crf_marginal_accuracy: 0.0018 - val_loss: 0.7501 - val_crf_marginal_accuracy: 0.0026\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.6822 - crf_marginal_accuracy: 0.0039 - val_loss: 0.5428 - val_crf_marginal_accuracy: 0.0201\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.4689 - crf_marginal_accuracy: 0.5339 - val_loss: 0.3649 - val_crf_marginal_accuracy: 0.9177\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.3202 - crf_marginal_accuracy: 0.9549 - val_loss: 0.2745 - val_crf_marginal_accuracy: 0.9752\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.2322 - crf_marginal_accuracy: 0.9796 - val_loss: 0.2123 - val_crf_marginal_accuracy: 0.9878\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1696 - crf_marginal_accuracy: 0.9886 - val_loss: 0.1767 - val_crf_marginal_accuracy: 0.9932\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.1236 - crf_marginal_accuracy: 0.9928 - val_loss: 0.1575 - val_crf_marginal_accuracy: 0.9937\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0953 - crf_marginal_accuracy: 0.9951 - val_loss: 0.1513 - val_crf_marginal_accuracy: 0.9949\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0753 - crf_marginal_accuracy: 0.9964 - val_loss: 0.1454 - val_crf_marginal_accuracy: 0.9950\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0614 - crf_marginal_accuracy: 0.9969 - val_loss: 0.1526 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0504 - crf_marginal_accuracy: 0.9976 - val_loss: 0.1685 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0441 - crf_marginal_accuracy: 0.9979 - val_loss: 0.1742 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0373 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1701 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0336 - crf_marginal_accuracy: 0.9983 - val_loss: 0.1779 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 38s 13ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9986 - val_loss: 0.1810 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0254 - crf_marginal_accuracy: 0.9987 - val_loss: 0.1918 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0225 - crf_marginal_accuracy: 0.9989 - val_loss: 0.2116 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 39s 13ms/step - loss: 0.0205 - crf_marginal_accuracy: 0.9990 - val_loss: 0.2114 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0174 - crf_marginal_accuracy: 0.9991 - val_loss: 0.2160 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0157 - crf_marginal_accuracy: 0.9992 - val_loss: 0.2401 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0139 - crf_marginal_accuracy: 0.9993 - val_loss: 0.2293 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 39s 14ms/step - loss: 0.0121 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2475 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 40s 14ms/step - loss: 0.0112 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2472 - val_crf_marginal_accuracy: 0.9967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fQo3JKAa6iL",
        "outputId": "e4e56f62-11b8-463a-9abf-11301f0b3040"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.7252    0.6333    0.6762       150\n",
            " I-DOCAGRDATE     0.6542    0.7955    0.7179        88\n",
            "  B-DOCAGRNUM     0.7925    0.4693    0.5895       179\n",
            "  I-DOCAGRNUM     0.0000    0.0000    0.0000         7\n",
            "  B-DOCAMOUNT     0.8304    0.5632    0.6711      1243\n",
            "  I-DOCAMOUNT     0.7613    0.4629    0.5757       620\n",
            "    B-DOCCPTY     0.9048    0.8471    0.8750       595\n",
            "    I-DOCCPTY     0.9241    0.8422    0.8813       564\n",
            " B-DOCCPTYINN     0.9673    0.8404    0.8994       282\n",
            "B-DOCCUSTOMER     0.9572    0.9540    0.9556       609\n",
            "I-DOCCUSTOMER     0.9236    0.9416    0.9325       462\n",
            "    B-DOCDATE     0.8804    0.8217    0.8500       645\n",
            "    I-DOCDATE     0.8640    0.9455    0.9029       605\n",
            "     B-DOCNUM     0.8467    0.6022    0.7038       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8728    0.7406    0.8013      6700\n",
            "    macro avg     0.7354    0.6479    0.6821      6700\n",
            " weighted avg     0.8651    0.7406    0.7908      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0LPCsrMoJYm"
      },
      "source": [
        "## GLOVE (fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7KzsnJxvbDN"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE_R3XoqvbDP"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQU0DDgvbDQ"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvYtfwsNzuZd"
      },
      "source": [
        "## GLOVE (fixed, window=5) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pCZ2NJ_zfvQ",
        "outputId": "d6e5df6e-2f51-4b05-b26c-ce1a0ff5b5cc"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJlUl4tnzfvb",
        "outputId": "7634715c-7844-441e-c406-f018e55c71e1"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_-CTKgczfvb"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBN8OPD0zfvb",
        "outputId": "9c4864a2-a804-48dd-be3f-853182916fde"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6897    0.4000    0.5063       150\n",
            " I-DOCAGRDATE     0.7121    0.5341    0.6104        88\n",
            "  B-DOCAGRNUM     0.7656    0.5475    0.6384       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8766    0.6002    0.7125      1243\n",
            "  I-DOCAMOUNT     0.8028    0.5645    0.6629       620\n",
            "    B-DOCCPTY     0.8942    0.8235    0.8574       595\n",
            "    I-DOCCPTY     0.8946    0.7979    0.8435       564\n",
            " B-DOCCPTYINN     0.9361    0.8830    0.9088       282\n",
            "B-DOCCUSTOMER     0.9777    0.9360    0.9564       609\n",
            "I-DOCCUSTOMER     0.9386    0.9264    0.9325       462\n",
            "    B-DOCDATE     0.8696    0.7550    0.8083       645\n",
            "    I-DOCDATE     0.8640    0.8926    0.8780       605\n",
            "     B-DOCNUM     0.8991    0.6022    0.7213       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8850    0.7330    0.8019      6700\n",
            "    macro avg     0.8080    0.6556    0.7176      6700\n",
            " weighted avg     0.8800    0.7330    0.7945      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mj6XiDy65yt"
      },
      "source": [
        "## GLOVE (fixed, window=10) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r-ARNPS61Ib",
        "outputId": "92a2e686-0786-445a-8ad8-bf9af909da07"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=10)\n",
        "\n",
        "glove = Glove(no_components=30, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjcyEbXN7GM0",
        "outputId": "66f979fa-76f1-43c0-8ac5-873ccef50f5c"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 10\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPYrbq2m7GM1",
        "outputId": "1863edf3-1e3f-4dad-9fbf-f0e370c175ce"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 10\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_V0-ls47GM1"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqI-aOY37GM1",
        "outputId": "2d2df68b-b448-44d9-bb3d-65b64489a46a"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6837    0.4467    0.5403       150\n",
            " I-DOCAGRDATE     0.7123    0.5909    0.6460        88\n",
            "  B-DOCAGRNUM     0.7339    0.5084    0.6007       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8851    0.6195    0.7288      1243\n",
            "  I-DOCAMOUNT     0.8423    0.6032    0.7030       620\n",
            "    B-DOCCPTY     0.8830    0.8118    0.8459       595\n",
            "    I-DOCCPTY     0.9036    0.8475    0.8747       564\n",
            " B-DOCCPTYINN     0.9643    0.8617    0.9101       282\n",
            "B-DOCCUSTOMER     0.9693    0.8801    0.9225       609\n",
            "I-DOCCUSTOMER     0.9591    0.9134    0.9357       462\n",
            "    B-DOCDATE     0.8966    0.7798    0.8342       645\n",
            "    I-DOCDATE     0.9066    0.9140    0.9103       605\n",
            "     B-DOCNUM     0.8968    0.6006    0.7194       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8964    0.7413    0.8115      6700\n",
            "    macro avg     0.8158    0.6633    0.7266      6700\n",
            " weighted avg     0.8921    0.7413    0.8055      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYzIBS7IjLwK"
      },
      "source": [
        "## GLOVE (fixed, window=25) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VICcoqOVjLwL",
        "outputId": "6e332dee-5857-43eb-fa1b-bf4eeb74454e"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=25)\n",
        "\n",
        "glove = Glove(no_components=10, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQncFeCOjLwL",
        "outputId": "074759ed-da24-4911-8478-6fedc0e1ee05"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMFCFVQWjLwL",
        "outputId": "12b0eac3-bb57-47c5-8a1e-2c53a8a6ec45"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0uYfrCUjLwL"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k600p1NVjLwM",
        "outputId": "35d2ae57-09e8-4ab3-a989-c7b2f6019cfc"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6264    0.3800    0.4730       150\n",
            " I-DOCAGRDATE     0.7703    0.6477    0.7037        88\n",
            "  B-DOCAGRNUM     0.7315    0.4413    0.5505       179\n",
            "  I-DOCAGRNUM     1.0000    0.4286    0.6000         7\n",
            "  B-DOCAMOUNT     0.9018    0.6058    0.7247      1243\n",
            "  I-DOCAMOUNT     0.8178    0.5935    0.6879       620\n",
            "    B-DOCCPTY     0.8587    0.7765    0.8155       595\n",
            "    I-DOCCPTY     0.8926    0.8103    0.8494       564\n",
            " B-DOCCPTYINN     0.9563    0.8546    0.9026       282\n",
            "B-DOCCUSTOMER     0.9677    0.8358    0.8969       609\n",
            "I-DOCCUSTOMER     0.9589    0.9091    0.9333       462\n",
            "    B-DOCDATE     0.8993    0.7612    0.8245       645\n",
            "    I-DOCDATE     0.9211    0.9256    0.9233       605\n",
            "     B-DOCNUM     0.9175    0.5975    0.7237       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8966    0.7233    0.8007      6700\n",
            "    macro avg     0.8146    0.6378    0.7073      6700\n",
            " weighted avg     0.8923    0.7233    0.7941      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBIZP9Wqn4Xe"
      },
      "source": [
        "## GLOVE (fixed, window=20) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtnxKj_ln4Xe",
        "outputId": "c2071c84-d3d4-4811-ad90-f1473830bc61"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=20)\n",
        "\n",
        "glove = Glove(no_components=10, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9QiUfNKn4Xe",
        "outputId": "7d7dc265-001a-4b71-fe86-fb44d1fc07be"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6OkahAUn4Xf",
        "outputId": "335bce4a-f64e-4f7a-eefd-a85e6506b3fe"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Picoj7eUn4Xf"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7utYKHkHn4Xf",
        "outputId": "000bd8ff-c17b-4227-c292-3e99fd321d8f"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6250    0.3333    0.4348       150\n",
            " I-DOCAGRDATE     0.8154    0.6023    0.6928        88\n",
            "  B-DOCAGRNUM     0.7596    0.4413    0.5583       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8927    0.6026    0.7195      1243\n",
            "  I-DOCAMOUNT     0.8060    0.6032    0.6900       620\n",
            "    B-DOCCPTY     0.8835    0.7899    0.8341       595\n",
            "    I-DOCCPTY     0.8980    0.8121    0.8529       564\n",
            " B-DOCCPTYINN     0.9753    0.8404    0.9029       282\n",
            "B-DOCCUSTOMER     0.9610    0.8506    0.9024       609\n",
            "I-DOCCUSTOMER     0.9653    0.9026    0.9329       462\n",
            "    B-DOCDATE     0.8839    0.7318    0.8007       645\n",
            "    I-DOCDATE     0.9058    0.9058    0.9058       605\n",
            "     B-DOCNUM     0.9236    0.5945    0.7234       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8968    0.7188    0.7980      6700\n",
            "    macro avg     0.8197    0.6388    0.7118      6700\n",
            " weighted avg     0.8919    0.7188    0.7912      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl-kdToFKHn0"
      },
      "source": [
        "## Подбор гиперпараметров для CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxr9cm5gKNIx",
        "outputId": "9fec40d7-81c5-4120-ae51-c02dc577eeda"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "window_sizes = range(2, 25)\n",
        "EMBEDDING_LENGTH = 10\n",
        "\n",
        "for window_size in tqdm(window_sizes):\n",
        "    corpus = Corpus() \n",
        "\n",
        "    corpus.fit(df['tokens'], window=window_size)\n",
        "\n",
        "    glove = Glove(no_components=EMBEDDING_LENGTH, learning_rate=0.05) \n",
        "    glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=False)\n",
        "    glove.add_dictionary(corpus.dictionary)\n",
        "    for d in all_dfs:\n",
        "        d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "        d['int_tokens'] = d.apply(find_glove_token, axis=1)\n",
        "    \n",
        "    catboost_x_train = []\n",
        "    catboost_y_train = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_train.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    train.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    catboost_x_test = []\n",
        "    catboost_y_test = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_test.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    test.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "    cb.fit(catboost_x_train, catboost_y_train)\n",
        "    pred = cb.predict(catboost_x_test)\n",
        "    f1_scores.append(f1_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    precision_scores.append(precision_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    recall_scores.append(recall_score(catboost_y_test, pred, average='weighted', labels=int_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/23 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 23/23 [1:09:53<00:00, 182.33s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3kXaDebHr0FR",
        "outputId": "50627931-97c9-4963-c5ca-da5bfc76bc33"
      },
      "source": [
        "plt.plot(window_sizes, f1_scores, label='f1')\n",
        "plt.plot(window_sizes, precision_scores, label='precision')\n",
        "plt.plot(window_sizes, recall_scores, label='recall')\n",
        "plt.title('Metrics dependency on window size')\n",
        "plt.xlabel('Window size')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbgOyEPrAXL0",
        "outputId": "9a12bebb-d183-4279-8c52-61fecb3ad487"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "window_size = 7\n",
        "EMBEDDING_LENGTH = 30\n",
        "\n",
        "for o_weight in tqdm(np.arange(0.05, 1.0000001, 0.05)):\n",
        "    corpus = Corpus() \n",
        "\n",
        "    corpus.fit(df['tokens'], window=window_size)\n",
        "\n",
        "    glove = Glove(no_components=EMBEDDING_LENGTH, learning_rate=0.05) \n",
        "    glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=False)\n",
        "    glove.add_dictionary(corpus.dictionary)\n",
        "    for d in all_dfs:\n",
        "        d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "        d['int_tokens'] = d.apply(find_glove_token, axis=1)\n",
        "    \n",
        "    catboost_x_train = []\n",
        "    catboost_y_train = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_train.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    train.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    catboost_x_test = []\n",
        "    catboost_y_test = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_test.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    test.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1] * 15 + [o_weight], iterations=1000)\n",
        "    cb.fit(catboost_x_train, catboost_y_train)\n",
        "    pred = cb.predict(catboost_x_test)\n",
        "    f1_scores.append(f1_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    precision_scores.append(precision_score(catboost_y_test, pred, average='weighted', labels=int_labels))\n",
        "    recall_scores.append(recall_score(catboost_y_test, pred, average='weighted', labels=int_labels))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 20/20 [1:23:28<00:00, 250.45s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "X7aD5-aKAXL-",
        "outputId": "64875f26-a063-4398-8573-3b2c0abc5bfb"
      },
      "source": [
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), f1_scores, label='f1')\n",
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), precision_scores, label='precision')\n",
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), recall_scores, label='recall')\n",
        "plt.title('Metrics dependency on O weight')\n",
        "plt.xlabel('O weight')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2QR8DRAXm2t"
      },
      "source": [
        "## GLOVE (fixed, window=7, O_weight=0.4) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgjHucwQXm23",
        "outputId": "b5d78dcb-a697-4c91-b165-c9287b3ad1af"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=7)\n",
        "\n",
        "glove = Glove(no_components=30, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0SQSRAZXm23",
        "outputId": "78f91470-9cf4-4a8e-a7c2-f3902270dda1"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 7\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       None\n",
              "1       None\n",
              "2       None\n",
              "3       None\n",
              "4       None\n",
              "        ... \n",
              "3195    None\n",
              "3196    None\n",
              "3197    None\n",
              "3198    None\n",
              "3199    None\n",
              "Length: 3200, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByE22v1wXm24",
        "outputId": "58b4b0d2-03e8-48e2-a8cd-e4572e23fd37"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 7\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "798    None\n",
              "799    None\n",
              "Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WflxHpukXm24"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1] * 15 + [0.4], iterations=25000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrjV1cLjXm24",
        "outputId": "a81c8fe0-6916-4b68-c1cb-dde8397240e5"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            " B-DOCAGRDATE     0.6807    0.5400    0.6022       150\n",
            " I-DOCAGRDATE     0.7191    0.7273    0.7232        88\n",
            "  B-DOCAGRNUM     0.7188    0.6425    0.6785       179\n",
            "  I-DOCAGRNUM     1.0000    0.5714    0.7273         7\n",
            "  B-DOCAMOUNT     0.8507    0.7152    0.7771      1243\n",
            "  I-DOCAMOUNT     0.7817    0.6871    0.7313       620\n",
            "    B-DOCCPTY     0.8470    0.8655    0.8562       595\n",
            "    I-DOCCPTY     0.8731    0.9025    0.8875       564\n",
            " B-DOCCPTYINN     0.9442    0.9007    0.9220       282\n",
            "B-DOCCUSTOMER     0.9707    0.9245    0.9470       609\n",
            "I-DOCCUSTOMER     0.9581    0.9416    0.9498       462\n",
            "    B-DOCDATE     0.8631    0.8310    0.8468       645\n",
            "    I-DOCDATE     0.8825    0.9438    0.9121       605\n",
            "     B-DOCNUM     0.8367    0.6298    0.7187       651\n",
            "     I-DOCNUM     0.0000    0.0000    0.0000         0\n",
            "\n",
            "    micro avg     0.8645    0.8018    0.8320      6700\n",
            "    macro avg     0.7951    0.7215    0.7520      6700\n",
            " weighted avg     0.8619    0.8018    0.8285      6700\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9bT06PkUHFB"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}