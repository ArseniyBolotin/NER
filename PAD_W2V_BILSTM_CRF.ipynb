{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "PAD_W2V/BILSTM-CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raJ-rDdCJt_",
        "outputId": "22d06524-4039-4a37-a988-ea004fa5a53e"
      },
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install tensorflow==1.15.0 keras==2.2.4\n",
        "!pip3 install glove-python-binary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEfFyYZVph-B"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNJIwNGCp3yV"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiMGvd2mph-J"
      },
      "source": [
        "## ADDITIONAL FUNCTIONS\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "    \n",
        "pStopWordsList = stopwords.words('english') + stopwords.words('russian')\n",
        "\n",
        "def convert_amount(pAmount, rubles = False):\n",
        "    try:\n",
        "        if rubles:\n",
        "            cAmount = pytils.numeral.rubles(abs(float(pAmount)), zero_for_kopeck=True)    \n",
        "        else:\n",
        "            cAmount = pytils.numeral.in_words(abs(int(pAmount)))    \n",
        "    except Exception as e:\n",
        "        cAmount = pAmount  \n",
        "    return cAmount\n",
        "\n",
        "def convert_date(pDate, format_mode, formatDate = None):\n",
        "    formatDates = ['%Y-%m-%d',\n",
        "                   '%d-%m-%Y',\n",
        "                   '%d/%m/%Y',\n",
        "                   '%d.%m.%Y',\n",
        "                   '%y-%m-%d',\n",
        "                   '%d-%m-%y',\n",
        "                   '%d/%m/%y',\n",
        "                   '%d.%m.%y',\n",
        "                   '%Y-%m-%d %H:%M:%S',\n",
        "                   '%d-%m-%Y %H:%M:%S',\n",
        "                   '%d/%m/%Y %H:%M:%S',\n",
        "                   '%d.%m.%Y %H:%M:%S',\n",
        "                   '%y-%m-%d %H:%M:%S',\n",
        "                   '%d-%m-%y %H:%M:%S',\n",
        "                   '%d/%m/%y %H:%M:%S',\n",
        "                   '%d.%m.%y %H:%M:%S']\n",
        "    if formatDate!=None:\n",
        "        cDate = datetime.datetime.strptime(pDate, formatDate).date()\n",
        "    else:\n",
        "        for fd in formatDates:\n",
        "            try:\n",
        "                cDate = datetime.datetime.strptime(pDate, fd).date()\n",
        "                break\n",
        "            except Exception as e:\n",
        "                cDate=None\n",
        "    if cDate == None:\n",
        "        print('convert_date: Can not define date format for \"%s\"' % pDate)\n",
        "        return ''\n",
        "    if format_mode == 1:\n",
        "        dmonth = {1: '01', 2: '02', 3: '03', 4: '04', 5: '05', 6: '06', 7: '07', 8: '08', 9: '09', 10: '10', 11: '11', 12: '12'}\n",
        "        dformat = '{}.{}.{}'\n",
        "        res = dformat.format(cDate.day, dmonth[cDate.month], cDate.year - 2000)\n",
        "    if format_mode == 2:\n",
        "        dmonth = {1: 'января', 2: 'февраля', 3: 'марта', 4: 'апреля', 5: 'мая', 6: 'июня', 7: 'июля', 8: 'августа', 9: 'сентября', 10: 'октября', 11: 'ноября', 12: 'декабря'}   \n",
        "        dformat = '{} {} {}'\n",
        "        res = dformat.format(cDate.day, dmonth[cDate.month], cDate.year)\n",
        "    if format_mode == 3:\n",
        "        dmonth = {1: 'января', 2: 'февраля', 3: 'марта', 4: 'апреля', 5: 'мая', 6: 'июня', 7: 'июля', 8: 'августа', 9: 'сентября', 10: 'октября', 11: 'ноября', 12: 'декабря'}   \n",
        "        dformat = '\"{}\" {} {}'\n",
        "        res = dformat.format(str(cDate.day).zfill(2), dmonth[cDate.month], cDate.year)            \n",
        "    if format_mode == 4:\n",
        "        dmonth = {1: '01', 2: '02', 3: '03', 4: '04', 5: '05', 6: '06', 7: '07', 8: '08', 9: '09', 10: '10', 11: '11', 12: '12'}\n",
        "        dformat = '{}.{}.{}'\n",
        "        res = dformat.format(cDate.day, dmonth[cDate.month], cDate.year)            \n",
        "    return res\n",
        "\n",
        "def checkdate(text, pattern):\n",
        "    res = ''\n",
        "    if pattern==None: return ''\n",
        "    text = text.lower()\n",
        "    pattern = pattern.lower()\n",
        "    res = pattern\n",
        "    if res in text: return res\n",
        "    res = convert_date(pattern, format_mode=1).lower()\n",
        "    if res in text: return res\n",
        "    res = convert_date(pattern, format_mode=4).lower()\n",
        "    if res in text: return res   \n",
        "    res = res.replace('.','/')\n",
        "    if res in text: return res   \n",
        "    res = res.replace('/','-')\n",
        "    if res in text: return res       \n",
        "    res = convert_date(pattern, format_mode=2).lower()\n",
        "    if res in text: return res\n",
        "    res = convert_date(pattern, format_mode=3).lower()\n",
        "    if res in text: return res\n",
        "    res = res[1:]\n",
        "    if res in text: return res\n",
        "    res = res.replace('\"\"', '')\n",
        "    if res in text: return res\n",
        "    \n",
        "    if \" \".join([w for w in convert_date(pattern, format_mode=1).lower()]) in text:\n",
        "        res = \" \".join([w for w in convert_date(pattern, format_mode=1)])\n",
        "    if \" \".join([w for w in convert_date(pattern, format_mode=2).lower()]) in text:\n",
        "        res = \" \".join([w for w in convert_date(pattern, format_mode=2)])\n",
        "    \n",
        "    return ''\n",
        "    \n",
        "def checkamount(text, pattern, space =3):\n",
        "    digits = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
        "    if pattern in (None,''): return ''\n",
        "    res = ''\n",
        "    \n",
        "    if pattern in (None,'','nan'): return ''\n",
        "    \n",
        "    if pattern == 'nan':\n",
        "        return res\n",
        "    if pattern in text:\n",
        "        res = pattern\n",
        "    res=pattern\n",
        "    if res in text: return res\n",
        "    \n",
        "    pattern = pattern.lower().replace(' ','').replace(',', '.')#.replace('-', '')\n",
        "    res = pattern\n",
        "    if res in text: return res\n",
        "    \n",
        "    res = pattern.replace('.', ',')\n",
        "    if res in text: return res\n",
        "    \n",
        "    res = pattern.replace(',', '.')\n",
        "    if res in text: return res\n",
        "\n",
        "    res = pattern.replace(',', '-')\n",
        "    if res in text: return res\n",
        "\n",
        "    res = pattern.replace('.', '-')\n",
        "    if res in text: return res\n",
        "    \n",
        "    try:\n",
        "        res = '{:_}'.format(float(pattern)).replace('_', ' ')\n",
        "        if res in text: return res\n",
        "        res = res.replace('.',',')\n",
        "        if res in text: return res\n",
        "        \n",
        "        res = res.replace('.','-')\n",
        "        if res in text: return res\n",
        "    except Exception as e:\n",
        "        tmp = None\n",
        "    \n",
        "    res = convert_amount(pattern).lower()\n",
        "    if convert_amount(pattern, rubles=True).lower() in text:\n",
        "    \n",
        "        res = convert_amount(pattern, rubles=True).lower()        \n",
        "    if res in text: return res\n",
        "        \n",
        "    tmp = pattern.split('.')\n",
        "    res = convert_amount(tmp[0]).lower()\n",
        "    tmp[0] = '{:,}'.format(int(tmp[0])).replace(',', ' ')\n",
        "    \n",
        "    res = ','.join(tmp)\n",
        "    if res in text: return res\n",
        "    \n",
        "    res = '.'.join(tmp)\n",
        "    if res in text: return res\n",
        "    \n",
        "    reg = ''\n",
        "    for l in pattern:\n",
        "        if l in digits:\n",
        "            reg = '%s%s.{0,%s}' % (reg, l,space)\n",
        "    m = re.search(reg, text)\n",
        "    if m!=None:\n",
        "        return m.string[m.start(0):m.end(0)][:-space]\n",
        "\n",
        "    for w in pattern.split():\n",
        "        reg = '%s%s.{0,%s}' % (reg, w,space)\n",
        "    m = re.search(reg, text)\n",
        "    if m!=None:\n",
        "        return m.string[m.start(0):m.end(0)][:-space]\n",
        "    \n",
        "    return ''\n",
        "\n",
        "def checkstring(text, target, spaces = 2):\n",
        "    if target in (None,'','nan'): return ''\n",
        "    text = text.lower()\n",
        "    target = target.lower()\n",
        "    '''\n",
        "    reg = ''\n",
        "    for l in target:\n",
        "        reg = '%s%s.{0,%s}' % (re.escape(reg), l,spaces)\n",
        "    \n",
        "    m = re.search(reg, text)\n",
        "    if m!=None:\n",
        "        return m.string[m.start(0):m.end(0)][:-spaces]\n",
        "    '''\n",
        "    target = target.replace('ооо','').replace('ао бывш.зао', '').\\\n",
        "             replace('зао','').replace('оао','').replace('ао','').\\\n",
        "             replace('ип','').replace(',','').strip()\n",
        "    if target in text:\n",
        "        return target\n",
        "    if target in ['бн', 'б/н']:\n",
        "        return ''\n",
        "    if target.replace('0','o') in text.replace('0','o'):\n",
        "        return target.replace('0','o')\n",
        "    if target.replace('з','3') in text.replace('з','3'):\n",
        "        return target.replace('з','3')    \n",
        "    if target.replace('э','3') in text.replace('э','3'):\n",
        "        return target.replace('э','3')    \n",
        "    if target.replace('э','9') in text.replace('э','9'):\n",
        "        return target.replace('э','9')    \n",
        "    if target.replace('б','6') in text.replace('б','6'):\n",
        "        return target.replace('б','6')    \n",
        "    for ch in [' ','_', '\\\\','`','*','{','}','[',']','(',')','>','#','+','-','.','!','$','\\'', ' ']:\n",
        "        if ch in target:\n",
        "            target = target.replace(ch,\"\")\n",
        "            if target in text:\n",
        "                return target\n",
        "    return ''\n",
        "\n",
        "def process_text_layer(TextLayer, pStopWordsList = []):\n",
        "    txt =  \" \".join([w for w in TextLayer.lower().split() \\\n",
        "                     if (not w in pStopWordsList)])\n",
        "\n",
        "    txt = txt. \\\n",
        "        replace('«', ''). \\\n",
        "        replace('»', ''). \\\n",
        "        replace('(', ''). \\\n",
        "        replace(')', ''). \\\n",
        "        replace('\\[)', ''). \\\n",
        "        replace('\\]', ''). \\\n",
        "        replace('^', ''). \\\n",
        "        replace('\\\\', '')\n",
        "\n",
        "    return txt\n",
        "\n",
        "def tagging_sentence_by_targets(ptag, sentence_tagged, df_targets, pmodel_name):\n",
        "    ret = sentence_tagged\n",
        "    for r in df_targets[df_targets['tag']==ptag]['string_value']:\n",
        "        tagging_sentence(ret, r, pmodel_name)\n",
        "    \n",
        "    return ret\n",
        "\n",
        "def word2features2(sent, i, exclude = 'O', bias=3):\n",
        "    word = sent[i][0]\n",
        "    if sent[i][2] == exclude:\n",
        "        return None\n",
        "\n",
        "    features = {\n",
        "        'bias': bias,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[:3]': word[:3],\n",
        "        'word[:2]': word[:2],\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'BOS': False,\n",
        "        'EOS': False\n",
        "    }\n",
        "    for w in range(1, bias+1):\n",
        "        if i > w:\n",
        "            word1 = sent[i-w][0]\n",
        "            features.update({\n",
        "                '-%s:word.lower()' % (w): word1.lower()\n",
        "            })\n",
        "            \n",
        "    if i < 1:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    for w in range(1, bias+1):\n",
        "        if i < len(sent)-w:\n",
        "            word1 = sent[i+w][0]\n",
        "            features.update({\n",
        "                '+%s:word.lower()' % (w): word1.lower()\n",
        "            })\n",
        "            \n",
        "    if i >= len(sent)-1:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "def sent2features(sent, exclude = 'O'):\n",
        "    result = list()\n",
        "    for i in range(len(sent)):\n",
        "        ret = word2features2(sent, i, exclude = exclude, bias=10)\n",
        "        if ret !=None:\n",
        "            result.append(ret)\n",
        "    return result\n",
        "\n",
        "def sent2labels(sent, exclude = 'O'):\n",
        "    result = list()\n",
        "    for token, postag, label in sent:\n",
        "        if label !=exclude:\n",
        "            result.append(label)        \n",
        "    return result\n",
        "\n",
        "def tagging_sentence(sentence, target, tag):\n",
        "    sentence_text=  ' '.join([w['Word'] for w in sentence])\n",
        "    r_tag = ''\n",
        "\n",
        "    try:\n",
        "        res_find  = re.finditer(target.lower(), sentence_text.lower())\n",
        "    except:\n",
        "        return sentence\n",
        "\n",
        "    for m in res_find:\n",
        "        r_tag = 'B-%s' % tag\n",
        "        for i in range(len(sentence_text[:m.start()].split()), len(sentence_text[:m.end()].split())):\n",
        "            \"\"\"\n",
        "            if r_tag==('B-%s' % tag):\n",
        "                if i>0:\n",
        "                    sentence[i-1]['Tag']= 'B1-%s' % tag\n",
        "                if i>1:\n",
        "                    sentence[i-2]['Tag']= 'B2-%s' % tag                      \n",
        "                if i>2:\n",
        "                    sentence[i-3]['Tag']= 'B3-%s' % tag\n",
        "                if i>3:\n",
        "                    sentence[i-4]['Tag']= 'B4-%s' % tag  \n",
        "            \"\"\"\n",
        "            sentence[i]['Tag']= r_tag\n",
        "            r_tag = 'I-%s' % tag   \n",
        "            \"\"\"\n",
        "            for j in range(1,5):\n",
        "                if i+j < len(sentence):\n",
        "                    sentence[i+j]['Tag']='E%s-%s' % (str(j), tag)\n",
        "            \"\"\"\n",
        "    return sentence\n",
        "\n",
        "def prepare_sentence(num, sentence):\n",
        "    words = sentence.replace('\"', '').split()\n",
        "    tmp = []\n",
        "    for w in words:\n",
        "        tmp.append({'Sentence #': 'Sentence: %s' % num, 'Word' : w, 'POS' : 'NN', 'Tag': 'O'})\n",
        "    return tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBiLcpwnqGAW"
      },
      "source": [
        "!gdown --id 1hYI4ovDNu2jUUBOMAEKya6BPbYEBd5An"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxW5mjflph-X"
      },
      "source": [
        "data = pd.read_csv('NER PAD.csv')\n",
        "for column in data.columns:\n",
        "    data[column] = data[column].astype(str)\n",
        "data['DOCCPTYINN'] = data['DOCCPTYINN'].apply(lambda r: r[:-2] if type(r) == str else r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-9bZdDph-l"
      },
      "source": [
        "PADData = data.copy()\n",
        "PADData['string_value'] = PADData.apply(lambda r: process_text_layer(r['string_value'], pStopWordsList), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFbDSbI4tGjM"
      },
      "source": [
        "PADData.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bLJpN-Rph-o"
      },
      "source": [
        "models = ['DOCNUM',\n",
        "            'DOCDATE',\n",
        "            'DOCAMOUNT',\n",
        "            'DOCCPTY',\n",
        "            'DOCAGRNUM',\n",
        "            'DOCAGRDATE',\n",
        "            'DOCCUSTOMER',\n",
        "            'DOCCPTYINN']\n",
        "\n",
        "datasets = {}\n",
        "for model_name in models:\n",
        "    ds = PADData[['tag','string_value', model_name]].rename(columns={'string_value': 'x', model_name: 'target'})\n",
        "    if 'DATE' in model_name:\n",
        "        ds['target'] = ds.apply(lambda r: checkdate(r['x'], r['target']),axis=1).copy()\n",
        "    if model_name in ['DOCNUM', 'DOCAGRNUM', 'DOCCUSTOMER', 'DOCCPTY']:\n",
        "        ds['target'] = ds.apply(lambda r: checkstring(r[\"x\"], r['target']),axis=1).copy()      \n",
        "    if 'AMOUNT' in model_name:\n",
        "        ds['target'] = ds.apply(lambda r: checkamount(r['x'], r['target']),axis=1).copy()\n",
        "        \n",
        "    ds = ds[ds['target']!=''].drop_duplicates().copy()\n",
        "    ds[\"x_tagged\"] = ds.apply(lambda r: prepare_sentence(r.name, r[\"x\"]), axis=1)\n",
        "    ds[\"x_tagged\"] = ds.apply(lambda r: tagging_sentence(r['x_tagged'], r['target'], model_name), axis=1)\n",
        "    \n",
        "    datasets[model_name] = ds.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMvp_cCsgl8X"
      },
      "source": [
        "def choose(word, x, y):\n",
        "    x = x.strip()\n",
        "    y = y.strip()\n",
        "    word = word.strip()\n",
        "    nx = len(x)\n",
        "    ny = len(y)\n",
        "    n = len(word)\n",
        "\n",
        "    find_x = -1\n",
        "    find_y = -1\n",
        "    if x.find(word) != -1:\n",
        "        find_x = max(len(word), find_x)\n",
        "    if word.find(x) != -1:\n",
        "        find_x = max(len(x), find_x)\n",
        "    if y.find(word) != -1:\n",
        "        find_y = max(len(word), find_y)\n",
        "    if word.find(y) != -1:\n",
        "        find_y = max(len(y), find_y)\n",
        "\n",
        "    if find_x != -1 or find_y != -1:\n",
        "        if find_x >= find_y:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "    \n",
        "    index = 0\n",
        "    while index < nx and index < ny and index < n:\n",
        "        if x[index] != word[index] and y[index] == word[index]:\n",
        "            return 1\n",
        "        elif x[index] == word[index] and y[index] != word[index]:\n",
        "             return 0\n",
        "        index += 1\n",
        "\n",
        "    if index < ny - 1 and index < n - 1 and y[index + 1] == word[index + 1]:\n",
        "        return 1\n",
        "    elif index < nx - 1 and index < n - 1 and x[index + 1] == word[index + 1]:\n",
        "        return 0\n",
        "    \n",
        "    return 0 #default\n",
        "\n",
        "def merge_tags(row):\n",
        "    x = row.tags_x\n",
        "    y = row.tags_y\n",
        "    if type(y) != list:\n",
        "        return\n",
        "    if type(x) != list:\n",
        "        x = y\n",
        "        return\n",
        "    assert len(x) == len(y)\n",
        "    for i in range(len(x)):\n",
        "        if x[i] == 'O' and y[i] != 'O':\n",
        "            x[i] = y[i]\n",
        "        if x[i] != 'O' and y[i] != 'O' and x[i] != y[i]: #labels conflict\n",
        "            print(f'Labels conflict with word {row.words_x[i]} --- {x[i]} : {row.target_x}; {y[i]} : {row.target_y}')\n",
        "            if pd.isnull(row.target_x):\n",
        "                x[i] = y[i]\n",
        "                continue\n",
        "            if pd.isnull(row.target_y):\n",
        "                continue\n",
        "            choosed = choose(row.words_x[i], row.target_x, row.target_y)\n",
        "            if choosed == 0:\n",
        "                print(f'Selected : {row.target_x}')\n",
        "            else:\n",
        "                print(f'Selected : {row.target_y}')\n",
        "                x[i] = y[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImrULTX1UeTB"
      },
      "source": [
        "d_merged = datasets[\"DOCNUM\"].copy()\n",
        "d_merged[\"tags\"] = d_merged.x_tagged.apply(lambda sent : [elem['Tag'] for elem in sent])\n",
        "d_merged[\"words\"] = d_merged.x_tagged.apply(lambda sent : [elem['Word'] for elem in sent])\n",
        "d_merged.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc04sVMqV77L"
      },
      "source": [
        "for model in models[1:]:\n",
        "    d_new = datasets[model].copy()\n",
        "    d_new[\"tags\"] = d_new.x_tagged.apply(lambda sent : [elem['Tag'] for elem in sent])\n",
        "    d_new[\"words\"] = d_new.x_tagged.apply(lambda sent : [elem['Word'] for elem in sent])\n",
        "    d_new.head(1)\n",
        "    d_merged = pd.merge(d_merged, d_new.loc[:, [\"tags\", \"target\", \"words\", \"tag\"]], left_index=True, right_index=True, how=\"outer\")\n",
        "    d_merged.loc[pd.isna(d_merged.tags_x), 'tags_x'] = d_merged.loc[pd.isna(d_merged.tags_x), 'tags_y']\n",
        "    d_merged.loc[pd.isna(d_merged.words_x), 'words_x'] = d_merged.loc[pd.isna(d_merged.words_x), 'words_y']\n",
        "    d_merged.loc[pd.isna(d_merged.tag_x), 'tag_x'] = d_merged.loc[pd.isna(d_merged.tag_x), 'tag_y']\n",
        "    d_merged.apply(merge_tags, axis=1)\n",
        "    d_merged.drop(columns=['target_y', 'tags_y', 'words_y', 'tag_y'], inplace=True)\n",
        "    d_merged.rename(columns={'target_x' : 'target', 'tags_x' : 'tags', 'words_x' : 'words', 'tag_x' : 'tag'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czFZD6fqZFDo"
      },
      "source": [
        "df = d_merged.loc[:, ['tag', 'words', 'tags']].rename(columns={'tag' : 'id', 'tags' : 'ner_tags', 'words' : 'tokens'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_gjQrcfLsAi"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rzneg_XLs5I"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw2v8MtdMRov"
      },
      "source": [
        "df.to_csv(\"NER_PAD_agg.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3bi5TQyWgmE"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "pretrained_w2v = api.load(\"word2vec-ruscorpora-300\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAl784dWnJkR"
      },
      "source": [
        "pretrained_w2v.save_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthif1zkvsok"
      },
      "source": [
        "def add_suffix(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in pretrained_w2v.vocab.keys():\n",
        "                res.append(w + suffix)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(w)\n",
        "    return res\n",
        "\n",
        "df['tokens_with_suffix'] = df.apply(add_suffix, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rp-IeYsnJf"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "w2v = Word2Vec(sentences=df['tokens_with_suffix'], size=300, window=15, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqqSfYYmY-p"
      },
      "source": [
        "w2v.intersect_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz_dGApGKoB"
      },
      "source": [
        "all_tags = set()\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wxpfE8Hx0u"
      },
      "source": [
        "def find_token(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ', '']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in w2v.wv.vocab.keys():\n",
        "                res.append(w2v.wv.vocab[w + suffix].index)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "df['encoded_ner_tags'] = df.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "df['int_tokens'] = df.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBnlJN5-HwcE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgw-JENBsTDS"
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Uvof38gWhS"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from sklearn_crfsuite import metrics\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBokW5kspLO"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=1.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqAcUZxSMT2c"
      },
      "source": [
        "### PRETRAINED W2V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1S7oW2BWoX",
        "outputId": "d844d125-7dc9-4bc4-bac3-5d42f860d543"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 7,765,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "LAVZ0buRG02d",
        "outputId": "a0c58a75-8c1e-4581-c644-aca75c8b624a"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 33s 11ms/step - loss: 0.8468 - crf_marginal_accuracy: 0.0020 - val_loss: 0.6788 - val_crf_marginal_accuracy: 0.0033\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.6148 - crf_marginal_accuracy: 0.0077 - val_loss: 0.5010 - val_crf_marginal_accuracy: 0.0494\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.4503 - crf_marginal_accuracy: 0.5836 - val_loss: 0.3565 - val_crf_marginal_accuracy: 0.9038\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.3271 - crf_marginal_accuracy: 0.9320 - val_loss: 0.2665 - val_crf_marginal_accuracy: 0.9568\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.2413 - crf_marginal_accuracy: 0.9677 - val_loss: 0.2017 - val_crf_marginal_accuracy: 0.9709\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.1803 - crf_marginal_accuracy: 0.9683 - val_loss: 0.1661 - val_crf_marginal_accuracy: 0.9644\n",
            "Epoch 7/30\n",
            " 412/2880 [===>..........................] - ETA: 25s - loss: 0.1599 - crf_marginal_accuracy: 0.9651"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-6180d4b931f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m412\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNVGThAXHeL",
        "outputId": "6d2f4e7f-129c-453a-a3cd-8228563a3bf2"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0483    0.3467    0.0848       150\n",
            "           1     0.3735    0.6760    0.4811       179\n",
            "           2     0.0613    0.8150    0.1140      1243\n",
            "           3     0.3775    0.8672    0.5260       595\n",
            "           4     0.4811    0.9043    0.6281       282\n",
            "           5     0.6634    0.8966    0.7626       609\n",
            "           6     0.3323    0.8248    0.4737       645\n",
            "           7     0.3511    0.6359    0.4525       651\n",
            "           8     0.0000    0.0000    0.0000        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.2978    0.3242    0.3104       620\n",
            "          11     0.5360    0.8440    0.6556       564\n",
            "          12     0.2305    0.9329    0.3696       462\n",
            "          13     0.5579    0.9802    0.7110       605\n",
            "          15     0.9919    0.8391    0.9091    137847\n",
            "\n",
            "    accuracy                         0.8358    144547\n",
            "   macro avg     0.3535    0.6591    0.4319    144547\n",
            "weighted avg     0.9617    0.8358    0.8874    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV6QMPc3cyy",
        "outputId": "dce62338-f621-4573-aac4-261003f07e44"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 943, 300)          7440900   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 7,765,476\n",
            "Trainable params: 324,576\n",
            "Non-trainable params: 7,440,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19U1yO8c3czD",
        "outputId": "12a83e6e-f9d6-4ca4-96de-7a1a51a132f2"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.7720 - crf_marginal_accuracy: 0.1673 - val_loss: 0.5614 - val_crf_marginal_accuracy: 0.1097\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.4955 - crf_marginal_accuracy: 0.8009 - val_loss: 0.3783 - val_crf_marginal_accuracy: 0.9209\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.3571 - crf_marginal_accuracy: 0.9326 - val_loss: 0.2913 - val_crf_marginal_accuracy: 0.9323\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2869 - crf_marginal_accuracy: 0.9396 - val_loss: 0.2446 - val_crf_marginal_accuracy: 0.9445\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2438 - crf_marginal_accuracy: 0.9471 - val_loss: 0.2134 - val_crf_marginal_accuracy: 0.9491\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2132 - crf_marginal_accuracy: 0.9495 - val_loss: 0.1917 - val_crf_marginal_accuracy: 0.9551\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1905 - crf_marginal_accuracy: 0.9561 - val_loss: 0.1761 - val_crf_marginal_accuracy: 0.9575\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1743 - crf_marginal_accuracy: 0.9589 - val_loss: 0.1648 - val_crf_marginal_accuracy: 0.9622\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1611 - crf_marginal_accuracy: 0.9629 - val_loss: 0.1566 - val_crf_marginal_accuracy: 0.9656\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1489 - crf_marginal_accuracy: 0.9669 - val_loss: 0.1472 - val_crf_marginal_accuracy: 0.9648\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1380 - crf_marginal_accuracy: 0.9681 - val_loss: 0.1416 - val_crf_marginal_accuracy: 0.9652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU37zLsF3czD",
        "outputId": "70c9b835-002b-4653-954a-5ba0e673ecb5"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.1165    0.6200    0.1962       150\n",
            "           1     0.2046    0.6480    0.3110       179\n",
            "           2     0.0738    0.8632    0.1359      1243\n",
            "           3     0.2234    0.8202    0.3512       595\n",
            "           4     0.1784    0.8794    0.2967       282\n",
            "           5     0.4331    0.8768    0.5798       609\n",
            "           6     0.3094    0.8202    0.4493       645\n",
            "           7     0.1778    0.6390    0.2782       651\n",
            "           8     0.3467    0.7841    0.4808        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.2653    0.7629    0.3937       620\n",
            "          11     0.4989    0.8404    0.6262       564\n",
            "          12     0.4076    0.9113    0.5632       462\n",
            "          13     0.6868    0.9570    0.7997       605\n",
            "          15     0.9935    0.8286    0.9036    137847\n",
            "\n",
            "    accuracy                         0.8283    144547\n",
            "   macro avg     0.3277    0.7501    0.4244    144547\n",
            "weighted avg     0.9612    0.8283    0.8807    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZCqkOHtMW19"
      },
      "source": [
        "### BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4F8rx-E7rq9"
      },
      "source": [
        "all_tags = set()\n",
        "word_to_ix = {}\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "    for word in row.tokens:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "# tag_to_idx['EOS'] = len(tag_to_idx)\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "# label_list[len(label_list)] = 'EOS'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KrZeMrT3eo-",
        "outputId": "0f4fbad1-8cd3-4363-d85e-bf08bfd10942"
      },
      "source": [
        "MAX_WORDS = len(word_to_ix)\n",
        "EMBEDDING_LENGTH = 300\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "# model.add(Dense(50))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 943, 300)          19955400  \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 20,279,976\n",
            "Trainable params: 20,279,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FveQSE6t3epA",
        "outputId": "df9c17bf-fa34-4f48-9e8d-d756136c484d"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=MAX_WORDS)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 34s 12ms/step - loss: 0.9006 - crf_marginal_accuracy: 0.0022 - val_loss: 0.7973 - val_crf_marginal_accuracy: 0.0020\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.6824 - crf_marginal_accuracy: 0.0039 - val_loss: 0.5395 - val_crf_marginal_accuracy: 0.0049\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.4482 - crf_marginal_accuracy: 0.2425 - val_loss: 0.3449 - val_crf_marginal_accuracy: 0.8683\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.2728 - crf_marginal_accuracy: 0.9321 - val_loss: 0.2335 - val_crf_marginal_accuracy: 0.9712\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1769 - crf_marginal_accuracy: 0.9824 - val_loss: 0.1817 - val_crf_marginal_accuracy: 0.9869\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1240 - crf_marginal_accuracy: 0.9900 - val_loss: 0.1647 - val_crf_marginal_accuracy: 0.9934\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0928 - crf_marginal_accuracy: 0.9940 - val_loss: 0.1542 - val_crf_marginal_accuracy: 0.9942\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0737 - crf_marginal_accuracy: 0.9959 - val_loss: 0.1629 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0602 - crf_marginal_accuracy: 0.9967 - val_loss: 0.1682 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0507 - crf_marginal_accuracy: 0.9973 - val_loss: 0.1724 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0437 - crf_marginal_accuracy: 0.9977 - val_loss: 0.1727 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0376 - crf_marginal_accuracy: 0.9981 - val_loss: 0.1886 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0327 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1959 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0293 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1974 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0257 - crf_marginal_accuracy: 0.9985 - val_loss: 0.2130 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0226 - crf_marginal_accuracy: 0.9987 - val_loss: 0.2252 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0202 - crf_marginal_accuracy: 0.9988 - val_loss: 0.2265 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0180 - crf_marginal_accuracy: 0.9989 - val_loss: 0.2467 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0167 - crf_marginal_accuracy: 0.9990 - val_loss: 0.2404 - val_crf_marginal_accuracy: 0.9965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgGsK_Yc3epA",
        "outputId": "a4c05531-1ebe-4619-c407-f4947cd2b55d"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7706    0.5600    0.6486       150\n",
            "           1     0.7767    0.4469    0.5674       179\n",
            "           2     0.8035    0.5527    0.6549      1243\n",
            "           3     0.8976    0.8252    0.8599       595\n",
            "           4     0.9633    0.8369    0.8956       282\n",
            "           5     0.9476    0.9507    0.9492       609\n",
            "           6     0.9314    0.8000    0.8607       645\n",
            "           7     0.7651    0.5853    0.6632       651\n",
            "           8     0.7273    0.7273    0.7273        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.7462    0.4694    0.5762       620\n",
            "          11     0.8858    0.8528    0.8690       564\n",
            "          12     0.9364    0.9567    0.9465       462\n",
            "          13     0.8990    0.9273    0.9129       605\n",
            "          15     0.9876    0.9952    0.9914    137847\n",
            "\n",
            "    accuracy                         0.9829    144547\n",
            "   macro avg     0.8025    0.6991    0.7415    144547\n",
            "weighted avg     0.9815    0.9829    0.9817    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doR8vcjvMNnS"
      },
      "source": [
        "### NOT PRETRAINED W2V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRins3GMDd-"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYv7a7bMMEI",
        "outputId": "46900d40-ded8-46d0-edfa-31d20726adea"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_4 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 3,450,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9AHayBOMMEK",
        "outputId": "be572f1a-ee94-4bd0-e89c-44f2c0dfe206"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 33s 11ms/step - loss: 0.8149 - crf_marginal_accuracy: 0.0515 - val_loss: 0.6067 - val_crf_marginal_accuracy: 0.0874\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.5138 - crf_marginal_accuracy: 0.0860 - val_loss: 0.3813 - val_crf_marginal_accuracy: 0.1648\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.3415 - crf_marginal_accuracy: 0.8348 - val_loss: 0.2754 - val_crf_marginal_accuracy: 0.9515\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.2638 - crf_marginal_accuracy: 0.9558 - val_loss: 0.2267 - val_crf_marginal_accuracy: 0.9607\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2196 - crf_marginal_accuracy: 0.9632 - val_loss: 0.1952 - val_crf_marginal_accuracy: 0.9691\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1874 - crf_marginal_accuracy: 0.9691 - val_loss: 0.1726 - val_crf_marginal_accuracy: 0.9709\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1629 - crf_marginal_accuracy: 0.9736 - val_loss: 0.1561 - val_crf_marginal_accuracy: 0.9781\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1439 - crf_marginal_accuracy: 0.9768 - val_loss: 0.1415 - val_crf_marginal_accuracy: 0.9740\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1264 - crf_marginal_accuracy: 0.9802 - val_loss: 0.1307 - val_crf_marginal_accuracy: 0.9843\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1118 - crf_marginal_accuracy: 0.9848 - val_loss: 0.1271 - val_crf_marginal_accuracy: 0.9868\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0992 - crf_marginal_accuracy: 0.9882 - val_loss: 0.1193 - val_crf_marginal_accuracy: 0.9904\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0880 - crf_marginal_accuracy: 0.9906 - val_loss: 0.1132 - val_crf_marginal_accuracy: 0.9905\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0787 - crf_marginal_accuracy: 0.9919 - val_loss: 0.1110 - val_crf_marginal_accuracy: 0.9923\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0716 - crf_marginal_accuracy: 0.9938 - val_loss: 0.1115 - val_crf_marginal_accuracy: 0.9943\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0653 - crf_marginal_accuracy: 0.9945 - val_loss: 0.1071 - val_crf_marginal_accuracy: 0.9948\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0591 - crf_marginal_accuracy: 0.9953 - val_loss: 0.1079 - val_crf_marginal_accuracy: 0.9947\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0539 - crf_marginal_accuracy: 0.9962 - val_loss: 0.1102 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0499 - crf_marginal_accuracy: 0.9965 - val_loss: 0.1099 - val_crf_marginal_accuracy: 0.9955\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0466 - crf_marginal_accuracy: 0.9969 - val_loss: 0.1094 - val_crf_marginal_accuracy: 0.9954\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.0439 - crf_marginal_accuracy: 0.9971 - val_loss: 0.1182 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.0408 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1149 - val_crf_marginal_accuracy: 0.9957\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.0379 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1199 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.0354 - crf_marginal_accuracy: 0.9979 - val_loss: 0.1177 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 24/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.0328 - crf_marginal_accuracy: 0.9979 - val_loss: 0.1208 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 25/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0311 - crf_marginal_accuracy: 0.9981 - val_loss: 0.1250 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 26/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.0292 - crf_marginal_accuracy: 0.9983 - val_loss: 0.1275 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 27/30\n",
            "2880/2880 [==============================] - 30s 11ms/step - loss: 0.0276 - crf_marginal_accuracy: 0.9983 - val_loss: 0.1293 - val_crf_marginal_accuracy: 0.9959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cofffkTqMMEK",
        "outputId": "5aadcf12-d4dc-41c0-cfb8-7ab918c8cd4e"
      },
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5714    0.7467    0.6474       150\n",
            "           1     0.7325    0.6425    0.6845       179\n",
            "           2     0.6867    0.6879    0.6873      1243\n",
            "           3     0.8723    0.8958    0.8839       595\n",
            "           4     0.8308    0.9574    0.8896       282\n",
            "           5     0.9120    0.9015    0.9067       609\n",
            "           6     0.8773    0.8310    0.8535       645\n",
            "           7     0.8710    0.6221    0.7258       651\n",
            "           8     0.6296    0.7727    0.6939        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.6651    0.6758    0.6704       620\n",
            "          11     0.8891    0.8954    0.8922       564\n",
            "          12     0.9100    0.9632    0.9359       462\n",
            "          13     0.8697    0.9488    0.9075       605\n",
            "          15     0.9911    0.9914    0.9912    137847\n",
            "\n",
            "    accuracy                         0.9827    144547\n",
            "   macro avg     0.7539    0.7688    0.7580    144547\n",
            "weighted avg     0.9827    0.9827    0.9826    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKFIa_0IMMEL",
        "outputId": "a8e3ba72-322b-4f4f-99ff-527761b80892"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_5 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 3,325,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSFEq-vMMEL",
        "outputId": "00dcf458-c72f-42dc-b117-fc563a81d06f"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 34s 12ms/step - loss: 0.8792 - crf_marginal_accuracy: 0.0015 - val_loss: 0.7295 - val_crf_marginal_accuracy: 0.0031\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.6578 - crf_marginal_accuracy: 0.0042 - val_loss: 0.5458 - val_crf_marginal_accuracy: 0.0048\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.4801 - crf_marginal_accuracy: 0.0191 - val_loss: 0.3729 - val_crf_marginal_accuracy: 0.0917\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.3362 - crf_marginal_accuracy: 0.6958 - val_loss: 0.2713 - val_crf_marginal_accuracy: 0.9497\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.2604 - crf_marginal_accuracy: 0.9593 - val_loss: 0.2210 - val_crf_marginal_accuracy: 0.9618\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.2212 - crf_marginal_accuracy: 0.9686 - val_loss: 0.1950 - val_crf_marginal_accuracy: 0.9646\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1963 - crf_marginal_accuracy: 0.9675 - val_loss: 0.1751 - val_crf_marginal_accuracy: 0.9597\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1785 - crf_marginal_accuracy: 0.9691 - val_loss: 0.1620 - val_crf_marginal_accuracy: 0.9737\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1654 - crf_marginal_accuracy: 0.9754 - val_loss: 0.1553 - val_crf_marginal_accuracy: 0.9736\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1549 - crf_marginal_accuracy: 0.9744 - val_loss: 0.1451 - val_crf_marginal_accuracy: 0.9682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-v-3tFMMEL",
        "outputId": "6fdc52e0-53e8-4d06-88a3-e93f4d7f57d3"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.1482    0.4467    0.2226       150\n",
            "           1     0.0998    0.6927    0.1745       179\n",
            "           2     0.0835    0.8656    0.1523      1243\n",
            "           3     0.4424    0.8521    0.5824       595\n",
            "           4     0.1125    0.9539    0.2012       282\n",
            "           5     0.5737    0.8752    0.6931       609\n",
            "           6     0.1954    0.7752    0.3121       645\n",
            "           7     0.3093    0.6728    0.4238       651\n",
            "           8     0.1429    0.0682    0.0923        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.2176    0.4355    0.2902       620\n",
            "          11     0.6108    0.8794    0.7209       564\n",
            "          12     0.4294    0.9416    0.5898       462\n",
            "          13     0.4837    0.9835    0.6485       605\n",
            "          15     0.9939    0.8449    0.9134    137847\n",
            "\n",
            "    accuracy                         0.8425    144547\n",
            "   macro avg     0.3229    0.6858    0.4011    144547\n",
            "weighted avg     0.9623    0.8425    0.8905    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cFsMLIHi76D"
      },
      "source": [
        "## window=5, min_count=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGPObsQWal6"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDnQ8VNWal-",
        "outputId": "14f708f5-e4dc-40f8-a18b-617d31d93558"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_6 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 3,450,476\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqCw-lOWamB",
        "outputId": "2b9b36b5-6298-4f3f-c955-195a0641e28a"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 35s 12ms/step - loss: 0.8562 - crf_marginal_accuracy: 0.0022 - val_loss: 0.6870 - val_crf_marginal_accuracy: 0.0049\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.6179 - crf_marginal_accuracy: 0.0226 - val_loss: 0.4982 - val_crf_marginal_accuracy: 0.0525\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.4442 - crf_marginal_accuracy: 0.7812 - val_loss: 0.3484 - val_crf_marginal_accuracy: 0.9453\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.3204 - crf_marginal_accuracy: 0.9650 - val_loss: 0.2617 - val_crf_marginal_accuracy: 0.9765\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.2471 - crf_marginal_accuracy: 0.9742 - val_loss: 0.2114 - val_crf_marginal_accuracy: 0.9749\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.2009 - crf_marginal_accuracy: 0.9748 - val_loss: 0.1772 - val_crf_marginal_accuracy: 0.9808\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1669 - crf_marginal_accuracy: 0.9798 - val_loss: 0.1543 - val_crf_marginal_accuracy: 0.9830\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1408 - crf_marginal_accuracy: 0.9818 - val_loss: 0.1394 - val_crf_marginal_accuracy: 0.9856\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1215 - crf_marginal_accuracy: 0.9839 - val_loss: 0.1320 - val_crf_marginal_accuracy: 0.9860\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1067 - crf_marginal_accuracy: 0.9876 - val_loss: 0.1220 - val_crf_marginal_accuracy: 0.9879\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0931 - crf_marginal_accuracy: 0.9899 - val_loss: 0.1162 - val_crf_marginal_accuracy: 0.9914\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0827 - crf_marginal_accuracy: 0.9914 - val_loss: 0.1128 - val_crf_marginal_accuracy: 0.9916\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0748 - crf_marginal_accuracy: 0.9926 - val_loss: 0.1117 - val_crf_marginal_accuracy: 0.9929\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0675 - crf_marginal_accuracy: 0.9942 - val_loss: 0.1098 - val_crf_marginal_accuracy: 0.9939\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0609 - crf_marginal_accuracy: 0.9951 - val_loss: 0.1080 - val_crf_marginal_accuracy: 0.9939\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0562 - crf_marginal_accuracy: 0.9956 - val_loss: 0.1073 - val_crf_marginal_accuracy: 0.9940\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0519 - crf_marginal_accuracy: 0.9962 - val_loss: 0.1085 - val_crf_marginal_accuracy: 0.9953\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0474 - crf_marginal_accuracy: 0.9967 - val_loss: 0.1153 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0441 - crf_marginal_accuracy: 0.9969 - val_loss: 0.1160 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0405 - crf_marginal_accuracy: 0.9974 - val_loss: 0.1157 - val_crf_marginal_accuracy: 0.9961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCujGbXWamC",
        "outputId": "31e78367-fdc3-4cd1-87d7-db187b05e72a"
      },
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5249    0.6333    0.5740       150\n",
            "           1     0.6513    0.7095    0.6791       179\n",
            "           2     0.6837    0.6766    0.6801      1243\n",
            "           3     0.8642    0.8235    0.8434       595\n",
            "           4     0.7695    0.9468    0.8490       282\n",
            "           5     0.8869    0.9015    0.8941       609\n",
            "           6     0.7531    0.8558    0.8012       645\n",
            "           7     0.7811    0.6359    0.7011       651\n",
            "           8     0.6804    0.7500    0.7135        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.7193    0.6242    0.6684       620\n",
            "          11     0.8384    0.8830    0.8601       564\n",
            "          12     0.8433    0.9437    0.8907       462\n",
            "          13     0.8910    0.9455    0.9174       605\n",
            "          15     0.9904    0.9897    0.9901    137847\n",
            "\n",
            "    accuracy                         0.9805    144547\n",
            "   macro avg     0.7252    0.7546    0.7375    144547\n",
            "weighted avg     0.9806    0.9805    0.9804    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jRCZwwNWamC",
        "outputId": "9fab01e2-4613-47e8-fce7-389a043e8a12"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 943, 50)           3325900   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_7 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 3,450,476\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 3,325,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy3tg6aWamD",
        "outputId": "6c2a1dab-2c18-4318-b52a-88d464e5ef59"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 34s 12ms/step - loss: 0.7601 - crf_marginal_accuracy: 0.3145 - val_loss: 0.5484 - val_crf_marginal_accuracy: 0.1410\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.4764 - crf_marginal_accuracy: 0.6969 - val_loss: 0.3612 - val_crf_marginal_accuracy: 0.9332\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.3275 - crf_marginal_accuracy: 0.9488 - val_loss: 0.2543 - val_crf_marginal_accuracy: 0.9480\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2470 - crf_marginal_accuracy: 0.9527 - val_loss: 0.2050 - val_crf_marginal_accuracy: 0.9516\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2086 - crf_marginal_accuracy: 0.9589 - val_loss: 0.1780 - val_crf_marginal_accuracy: 0.9605\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1839 - crf_marginal_accuracy: 0.9674 - val_loss: 0.1606 - val_crf_marginal_accuracy: 0.9684\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1675 - crf_marginal_accuracy: 0.9698 - val_loss: 0.1496 - val_crf_marginal_accuracy: 0.9645\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1563 - crf_marginal_accuracy: 0.9705 - val_loss: 0.1417 - val_crf_marginal_accuracy: 0.9726\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1454 - crf_marginal_accuracy: 0.9747 - val_loss: 0.1343 - val_crf_marginal_accuracy: 0.9712\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1375 - crf_marginal_accuracy: 0.9735 - val_loss: 0.1301 - val_crf_marginal_accuracy: 0.9768\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1307 - crf_marginal_accuracy: 0.9759 - val_loss: 0.1271 - val_crf_marginal_accuracy: 0.9805\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1241 - crf_marginal_accuracy: 0.9790 - val_loss: 0.1226 - val_crf_marginal_accuracy: 0.9779\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1187 - crf_marginal_accuracy: 0.9795 - val_loss: 0.1197 - val_crf_marginal_accuracy: 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuStVCRzWamD",
        "outputId": "cb4bf515-0b31-40aa-f0a5-98b8f3b5fcc5"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2512    0.6733    0.3659       150\n",
            "           1     0.2531    0.6927    0.3707       179\n",
            "           2     0.2091    0.8093    0.3323      1243\n",
            "           3     0.2918    0.8891    0.4394       595\n",
            "           4     0.2647    0.9397    0.4131       282\n",
            "           5     0.5630    0.8883    0.6892       609\n",
            "           6     0.2492    0.8341    0.3837       645\n",
            "           7     0.2392    0.6575    0.3508       651\n",
            "           8     0.5593    0.7500    0.6408        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.2367    0.8435    0.3696       620\n",
            "          11     0.3676    0.9326    0.5273       564\n",
            "          12     0.3917    0.9545    0.5554       462\n",
            "          13     0.6589    0.9868    0.7902       605\n",
            "          15     0.9943    0.9040    0.9470    137847\n",
            "\n",
            "    accuracy                         0.9015    144547\n",
            "   macro avg     0.3687    0.7837    0.4784    144547\n",
            "weighted avg     0.9637    0.9015    0.9248    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBED-952jGa_"
      },
      "source": [
        "## window=5, max_vocab_size=15000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBV_xu9jJ7O"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, max_vocab_size=15000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWAPWdOxjJ7P",
        "outputId": "bc1813b7-f1f4-432b-a9ea-84937033089f"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 943, 50)           238250    \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_8 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 362,826\n",
            "Trainable params: 362,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmtqjRfCjJ7c",
        "outputId": "3c06d42f-66dd-4b0a-caac-f286a20c1ac0"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 35s 12ms/step - loss: 0.7767 - crf_marginal_accuracy: 0.0238 - val_loss: 0.5682 - val_crf_marginal_accuracy: 0.0854\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.4952 - crf_marginal_accuracy: 0.3229 - val_loss: 0.3734 - val_crf_marginal_accuracy: 0.9122\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.3420 - crf_marginal_accuracy: 0.9404 - val_loss: 0.2698 - val_crf_marginal_accuracy: 0.9545\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2632 - crf_marginal_accuracy: 0.9547 - val_loss: 0.2231 - val_crf_marginal_accuracy: 0.9610\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.2213 - crf_marginal_accuracy: 0.9636 - val_loss: 0.1914 - val_crf_marginal_accuracy: 0.9632\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.1928 - crf_marginal_accuracy: 0.9668 - val_loss: 0.1715 - val_crf_marginal_accuracy: 0.9685\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1703 - crf_marginal_accuracy: 0.9700 - val_loss: 0.1570 - val_crf_marginal_accuracy: 0.9719\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1532 - crf_marginal_accuracy: 0.9744 - val_loss: 0.1440 - val_crf_marginal_accuracy: 0.9751\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1393 - crf_marginal_accuracy: 0.9733 - val_loss: 0.1350 - val_crf_marginal_accuracy: 0.9771\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1272 - crf_marginal_accuracy: 0.9782 - val_loss: 0.1283 - val_crf_marginal_accuracy: 0.9757\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1176 - crf_marginal_accuracy: 0.9801 - val_loss: 0.1242 - val_crf_marginal_accuracy: 0.9784\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1084 - crf_marginal_accuracy: 0.9823 - val_loss: 0.1170 - val_crf_marginal_accuracy: 0.9796\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1009 - crf_marginal_accuracy: 0.9836 - val_loss: 0.1154 - val_crf_marginal_accuracy: 0.9868\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0937 - crf_marginal_accuracy: 0.9866 - val_loss: 0.1143 - val_crf_marginal_accuracy: 0.9864\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0873 - crf_marginal_accuracy: 0.9885 - val_loss: 0.1100 - val_crf_marginal_accuracy: 0.9892\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0818 - crf_marginal_accuracy: 0.9895 - val_loss: 0.1059 - val_crf_marginal_accuracy: 0.9879\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0758 - crf_marginal_accuracy: 0.9908 - val_loss: 0.1019 - val_crf_marginal_accuracy: 0.9899\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0708 - crf_marginal_accuracy: 0.9923 - val_loss: 0.1012 - val_crf_marginal_accuracy: 0.9908\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0676 - crf_marginal_accuracy: 0.9926 - val_loss: 0.0998 - val_crf_marginal_accuracy: 0.9930\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0638 - crf_marginal_accuracy: 0.9934 - val_loss: 0.1009 - val_crf_marginal_accuracy: 0.9935\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0596 - crf_marginal_accuracy: 0.9943 - val_loss: 0.0981 - val_crf_marginal_accuracy: 0.9921\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0573 - crf_marginal_accuracy: 0.9941 - val_loss: 0.1013 - val_crf_marginal_accuracy: 0.9945\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0535 - crf_marginal_accuracy: 0.9954 - val_loss: 0.0998 - val_crf_marginal_accuracy: 0.9945\n",
            "Epoch 24/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0506 - crf_marginal_accuracy: 0.9952 - val_loss: 0.1004 - val_crf_marginal_accuracy: 0.9948\n",
            "Epoch 25/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0479 - crf_marginal_accuracy: 0.9956 - val_loss: 0.1060 - val_crf_marginal_accuracy: 0.9955\n",
            "Epoch 26/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0463 - crf_marginal_accuracy: 0.9958 - val_loss: 0.1043 - val_crf_marginal_accuracy: 0.9950\n",
            "Epoch 27/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0442 - crf_marginal_accuracy: 0.9963 - val_loss: 0.1046 - val_crf_marginal_accuracy: 0.9951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBqJIeRajJ7d",
        "outputId": "be4ebfbc-e88c-4d33-f3d5-3c339f3b3b6f"
      },
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4778    0.5733    0.5212       150\n",
            "           1     0.4638    0.6089    0.5266       179\n",
            "           2     0.5879    0.7104    0.6434      1243\n",
            "           3     0.7704    0.8739    0.8189       595\n",
            "           4     0.7745    0.9255    0.8433       282\n",
            "           5     0.8788    0.8933    0.8860       609\n",
            "           6     0.6628    0.8930    0.7609       645\n",
            "           7     0.7367    0.6406    0.6853       651\n",
            "           8     0.5649    0.8409    0.6758        88\n",
            "           9     1.0000    0.2857    0.4444         7\n",
            "          10     0.7239    0.6597    0.6903       620\n",
            "          11     0.7681    0.9220    0.8380       564\n",
            "          12     0.8222    0.9307    0.8731       462\n",
            "          13     0.8381    0.9752    0.9015       605\n",
            "          15     0.9913    0.9849    0.9881    137847\n",
            "\n",
            "    accuracy                         0.9767    144547\n",
            "   macro avg     0.7374    0.7812    0.7398    144547\n",
            "weighted avg     0.9787    0.9767    0.9775    144547\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaebcYB-jJ7d",
        "outputId": "1943a712-8e9e-4161-b42a-6ea6228431ea"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 943, 50)           238250    \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_9 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 362,826\n",
            "Trainable params: 124,576\n",
            "Non-trainable params: 238,250\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk48dUX-jJ7e",
        "outputId": "67d257e6-e298-4108-88bc-dbe94be75d35"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=2),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 35s 12ms/step - loss: 0.8174 - crf_marginal_accuracy: 0.0037 - val_loss: 0.6230 - val_crf_marginal_accuracy: 0.0250\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.5464 - crf_marginal_accuracy: 0.0336 - val_loss: 0.4215 - val_crf_marginal_accuracy: 0.0759\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.3826 - crf_marginal_accuracy: 0.5616 - val_loss: 0.2946 - val_crf_marginal_accuracy: 0.9357\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2822 - crf_marginal_accuracy: 0.9436 - val_loss: 0.2282 - val_crf_marginal_accuracy: 0.9508\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.2290 - crf_marginal_accuracy: 0.9565 - val_loss: 0.1956 - val_crf_marginal_accuracy: 0.9546\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.2007 - crf_marginal_accuracy: 0.9575 - val_loss: 0.1765 - val_crf_marginal_accuracy: 0.9583\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1794 - crf_marginal_accuracy: 0.9607 - val_loss: 0.1608 - val_crf_marginal_accuracy: 0.9615\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1641 - crf_marginal_accuracy: 0.9647 - val_loss: 0.1516 - val_crf_marginal_accuracy: 0.9682\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1533 - crf_marginal_accuracy: 0.9682 - val_loss: 0.1463 - val_crf_marginal_accuracy: 0.9692\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1442 - crf_marginal_accuracy: 0.9682 - val_loss: 0.1385 - val_crf_marginal_accuracy: 0.9664\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1364 - crf_marginal_accuracy: 0.9716 - val_loss: 0.1355 - val_crf_marginal_accuracy: 0.9722\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1293 - crf_marginal_accuracy: 0.9726 - val_loss: 0.1318 - val_crf_marginal_accuracy: 0.9746\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1230 - crf_marginal_accuracy: 0.9740 - val_loss: 0.1267 - val_crf_marginal_accuracy: 0.9753\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1184 - crf_marginal_accuracy: 0.9751 - val_loss: 0.1255 - val_crf_marginal_accuracy: 0.9752\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1133 - crf_marginal_accuracy: 0.9770 - val_loss: 0.1241 - val_crf_marginal_accuracy: 0.9787\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 28s 10ms/step - loss: 0.1084 - crf_marginal_accuracy: 0.9791 - val_loss: 0.1226 - val_crf_marginal_accuracy: 0.9763\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.1048 - crf_marginal_accuracy: 0.9783 - val_loss: 0.1205 - val_crf_marginal_accuracy: 0.9764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRxCwd2njJ7e",
        "outputId": "90eb656a-2ef9-4f2f-98e7-5fb09bda977a"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.1647    0.7467    0.2699       150\n",
            "           1     0.2095    0.7151    0.3241       179\n",
            "           2     0.1477    0.8311    0.2509      1243\n",
            "           3     0.3006    0.8706    0.4469       595\n",
            "           4     0.2274    0.9362    0.3659       282\n",
            "           5     0.3356    0.8818    0.4862       609\n",
            "           6     0.1996    0.8775    0.3253       645\n",
            "           7     0.2177    0.6636    0.3279       651\n",
            "           8     0.5468    0.8636    0.6696        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.3958    0.7290    0.5131       620\n",
            "          11     0.6120    0.9007    0.7288       564\n",
            "          12     0.6505    0.9264    0.7643       462\n",
            "          13     0.6728    0.9719    0.7951       605\n",
            "          15     0.9943    0.8895    0.9390    137847\n",
            "\n",
            "    accuracy                         0.8873    144547\n",
            "   macro avg     0.3783    0.7869    0.4805    144547\n",
            "weighted avg     0.9642    0.8873    0.9170    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4WKYxHZuT9p"
      },
      "source": [
        "## SOME MORE TO COME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgm2UrFtuT9p"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=25, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si5Zc-UjuEN3",
        "outputId": "f2fe1d2f-8bb8-464a-dcc3-d263b4a45579"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 943, 50)           1240150   \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 943, 200)          120800    \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_14 (CRF)                 (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 1,364,726\n",
            "Trainable params: 1,364,726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EN4RSuMuEN9",
        "outputId": "339bc740-bb84-4bf0-d6b4-230a1d1680f9"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0075 - crf_marginal_accuracy: 0.9995 - val_loss: 0.1830 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0072 - crf_marginal_accuracy: 0.9996 - val_loss: 0.1899 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0068 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2008 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0065 - crf_marginal_accuracy: 0.9996 - val_loss: 0.1971 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0065 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2081 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0061 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2141 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0057 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2089 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0055 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2142 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0051 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2134 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0050 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2115 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0048 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2218 - val_crf_marginal_accuracy: 0.9971\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0048 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2265 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0044 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2265 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0042 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2238 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 30s 10ms/step - loss: 0.0039 - crf_marginal_accuracy: 0.9998 - val_loss: 0.2352 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 29s 10ms/step - loss: 0.0039 - crf_marginal_accuracy: 0.9998 - val_loss: 0.2412 - val_crf_marginal_accuracy: 0.9970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGjQQcIDuEN9",
        "outputId": "d2064edf-015a-4e8b-a535-455b72a1c8d0"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7913    0.6067    0.6868       150\n",
            "           1     0.7448    0.6034    0.6667       179\n",
            "           2     0.8340    0.6951    0.7582      1243\n",
            "           3     0.9092    0.8756    0.8921       595\n",
            "           4     0.9430    0.8794    0.9101       282\n",
            "           5     0.9736    0.9097    0.9406       609\n",
            "           6     0.8920    0.8326    0.8613       645\n",
            "           7     0.7274    0.6436    0.6830       651\n",
            "           8     0.6739    0.7045    0.6889        88\n",
            "           9     1.0000    0.5714    0.7273         7\n",
            "          10     0.7438    0.6274    0.6807       620\n",
            "          11     0.8986    0.8954    0.8970       564\n",
            "          12     0.9729    0.9329    0.9525       462\n",
            "          13     0.9103    0.9388    0.9243       605\n",
            "          15     0.9905    0.9946    0.9925    137847\n",
            "\n",
            "    accuracy                         0.9852    144547\n",
            "   macro avg     0.8670    0.7807    0.8175    144547\n",
            "weighted avg     0.9845    0.9852    0.9847    144547\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAsUlkf-ap4n"
      },
      "source": [
        "## GLOVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNrzxYz3ar3x",
        "outputId": "b17c14a0-de04-4f32-f503-00eb19b3d744"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=15)\n",
        "\n",
        "glove = Glove(no_components=300, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtUIADA6a6h-",
        "outputId": "b3be7489-4295-4589-af22-8b3055f1c8ed"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 943, 300)          19955400  \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 943, 200)          320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 943, 16)           3216      \n",
            "_________________________________________________________________\n",
            "crf_7 (CRF)                  (None, 943, 16)           560       \n",
            "=================================================================\n",
            "Total params: 20,279,976\n",
            "Trainable params: 20,279,976\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxAndSBa6iK",
        "outputId": "bb521f90-2835-4734-f9cb-cce9201df8e5"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 37s 13ms/step - loss: 0.8392 - crf_marginal_accuracy: 0.0362 - val_loss: 0.6756 - val_crf_marginal_accuracy: 0.1628\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.5870 - crf_marginal_accuracy: 0.3821 - val_loss: 0.4515 - val_crf_marginal_accuracy: 0.9718\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.3902 - crf_marginal_accuracy: 0.9703 - val_loss: 0.2995 - val_crf_marginal_accuracy: 0.9740\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.2448 - crf_marginal_accuracy: 0.9761 - val_loss: 0.1972 - val_crf_marginal_accuracy: 0.9810\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 33s 11ms/step - loss: 0.1562 - crf_marginal_accuracy: 0.9835 - val_loss: 0.1545 - val_crf_marginal_accuracy: 0.9877\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 33s 11ms/step - loss: 0.1122 - crf_marginal_accuracy: 0.9884 - val_loss: 0.1411 - val_crf_marginal_accuracy: 0.9919\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0862 - crf_marginal_accuracy: 0.9923 - val_loss: 0.1321 - val_crf_marginal_accuracy: 0.9932\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0689 - crf_marginal_accuracy: 0.9948 - val_loss: 0.1364 - val_crf_marginal_accuracy: 0.9952\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0572 - crf_marginal_accuracy: 0.9961 - val_loss: 0.1442 - val_crf_marginal_accuracy: 0.9958\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0486 - crf_marginal_accuracy: 0.9970 - val_loss: 0.1385 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 11/30\n",
            "2880/2880 [==============================] - 33s 11ms/step - loss: 0.0407 - crf_marginal_accuracy: 0.9975 - val_loss: 0.1465 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 12/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0349 - crf_marginal_accuracy: 0.9980 - val_loss: 0.1570 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 13/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0311 - crf_marginal_accuracy: 0.9982 - val_loss: 0.1624 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 14/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0270 - crf_marginal_accuracy: 0.9984 - val_loss: 0.1712 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 15/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0238 - crf_marginal_accuracy: 0.9986 - val_loss: 0.1788 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 16/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0208 - crf_marginal_accuracy: 0.9988 - val_loss: 0.1892 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 17/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0187 - crf_marginal_accuracy: 0.9989 - val_loss: 0.1737 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 18/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0170 - crf_marginal_accuracy: 0.9989 - val_loss: 0.1880 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 19/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0152 - crf_marginal_accuracy: 0.9991 - val_loss: 0.2068 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 20/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0138 - crf_marginal_accuracy: 0.9992 - val_loss: 0.2161 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 21/30\n",
            "2880/2880 [==============================] - 33s 11ms/step - loss: 0.0126 - crf_marginal_accuracy: 0.9993 - val_loss: 0.2100 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 22/30\n",
            "2880/2880 [==============================] - 33s 11ms/step - loss: 0.0113 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2129 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 23/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0106 - crf_marginal_accuracy: 0.9993 - val_loss: 0.2357 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 24/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0096 - crf_marginal_accuracy: 0.9995 - val_loss: 0.2450 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 25/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0083 - crf_marginal_accuracy: 0.9995 - val_loss: 0.2417 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 26/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0074 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2518 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 27/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0065 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2788 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 28/30\n",
            "2880/2880 [==============================] - 32s 11ms/step - loss: 0.0061 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2722 - val_crf_marginal_accuracy: 0.9969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fQo3JKAa6iL",
        "outputId": "66f7bf26-5dec-4378-dd88-910e94742719"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7788    0.5867    0.6692       150\n",
            "           1     0.8350    0.4804    0.6099       179\n",
            "           2     0.8074    0.6002    0.6885      1243\n",
            "           3     0.9067    0.8655    0.8856       595\n",
            "           4     0.9567    0.8617    0.9067       282\n",
            "           5     0.9729    0.9442    0.9583       609\n",
            "           6     0.9109    0.8403    0.8742       645\n",
            "           7     0.9169    0.5929    0.7201       651\n",
            "           8     0.7108    0.6705    0.6901        88\n",
            "           9     1.0000    0.5714    0.7273         7\n",
            "          10     0.7646    0.4661    0.5792       620\n",
            "          11     0.9060    0.8883    0.8970       564\n",
            "          12     0.9775    0.9394    0.9581       462\n",
            "          13     0.9135    0.9421    0.9276       605\n",
            "          15     0.9885    0.9960    0.9922    137847\n",
            "\n",
            "    accuracy                         0.9847    144547\n",
            "   macro avg     0.8897    0.7497    0.8056    144547\n",
            "weighted avg     0.9836    0.9847    0.9836    144547\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7KzsnJxvbDN"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE_R3XoqvbDP",
        "outputId": "7f1b59f9-0233-4e99-96d4-73d56888dd2d"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=412,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2880 samples, validate on 320 samples\n",
            "Epoch 1/30\n",
            "2880/2880 [==============================] - 36s 12ms/step - loss: 0.8995 - crf_marginal_accuracy: 0.1284 - val_loss: 0.8082 - val_crf_marginal_accuracy: 0.8848\n",
            "Epoch 2/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.7697 - crf_marginal_accuracy: 0.9253 - val_loss: 0.6789 - val_crf_marginal_accuracy: 0.9481\n",
            "Epoch 3/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.6457 - crf_marginal_accuracy: 0.9438 - val_loss: 0.5597 - val_crf_marginal_accuracy: 0.9357\n",
            "Epoch 4/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.5387 - crf_marginal_accuracy: 0.9198 - val_loss: 0.4755 - val_crf_marginal_accuracy: 0.9153\n",
            "Epoch 5/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.4574 - crf_marginal_accuracy: 0.9300 - val_loss: 0.3930 - val_crf_marginal_accuracy: 0.9534\n",
            "Epoch 6/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.3859 - crf_marginal_accuracy: 0.9469 - val_loss: 0.3405 - val_crf_marginal_accuracy: 0.9500\n",
            "Epoch 7/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.3350 - crf_marginal_accuracy: 0.9445 - val_loss: 0.2981 - val_crf_marginal_accuracy: 0.9405\n",
            "Epoch 8/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.2984 - crf_marginal_accuracy: 0.9484 - val_loss: 0.2714 - val_crf_marginal_accuracy: 0.9476\n",
            "Epoch 9/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.2705 - crf_marginal_accuracy: 0.9437 - val_loss: 0.2429 - val_crf_marginal_accuracy: 0.9426\n",
            "Epoch 10/30\n",
            "2880/2880 [==============================] - 31s 11ms/step - loss: 0.2475 - crf_marginal_accuracy: 0.9503 - val_loss: 0.2302 - val_crf_marginal_accuracy: 0.9495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRQU0DDgvbDQ",
        "outputId": "b0cc4589-b6cc-4e81-ed67-c232eb888efb"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "print(metrics.flat_classification_report(test['encoded_ner_tags'], truncated_preds, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000       150\n",
            "           1     0.1954    0.0950    0.1278       179\n",
            "           2     0.0448    0.6911    0.0842      1243\n",
            "           3     0.0971    0.7160    0.1710       595\n",
            "           4     0.2500    0.4255    0.3150       282\n",
            "           5     0.1107    0.7307    0.1923       609\n",
            "           6     0.2074    0.4961    0.2925       645\n",
            "           7     0.2793    0.5161    0.3625       651\n",
            "           8     0.0000    0.0000    0.0000        88\n",
            "           9     0.0000    0.0000    0.0000         7\n",
            "          10     0.0000    0.0000    0.0000       620\n",
            "          11     0.5141    0.4521    0.4811       564\n",
            "          12     0.1290    0.6537    0.2155       462\n",
            "          13     0.3918    0.8083    0.5278       605\n",
            "          15     0.9827    0.7812    0.8705    137847\n",
            "\n",
            "    accuracy                         0.7697    144547\n",
            "   macro avg     0.2135    0.4244    0.2427    144547\n",
            "weighted avg     0.9454    0.7697    0.8408    144547\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWSpAUjhXbVN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}