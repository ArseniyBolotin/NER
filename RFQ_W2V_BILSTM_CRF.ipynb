{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RFQ_W2V_BILSTM_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raJ-rDdCJt_",
        "outputId": "6a6ec7e3-7750-4794-e588-bc529d60ff49"
      },
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install tensorflow==1.15.0 keras==2.2.4\n",
        "!pip3 install glove-python-binary\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\r\u001b[K     |▍                               | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 30.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 35.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 38.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 30.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 32.8MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 28.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 26.2MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 27.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 29.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 184kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 245kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 266kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 276kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 286kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 296kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 481kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 491kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 501kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 522kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 532kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 542kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 552kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 563kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 573kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 583kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 593kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675kB 29.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706kB 29.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 716kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 727kB 29.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 737kB 29.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 747kB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-nog1jer9\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-nog1jer9\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=04a359240eb0dd44d22778451a905c8a858d6e46cc1a1dac44799f1721a06f3c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dztnxdow/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 39kB/s \n",
            "\u001b[?25hCollecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=6645fd16452e1034cf86f4a75622a4f10545f6e76f9b26198c6c18b16da1049c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, keras-applications, tensorflow, keras\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed gast-0.2.2 keras-2.2.4 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting glove-python-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/11/d8510a80110f736822856db566341dd2e1e7c3af536f77e409a6c09e0c22/glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 23.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-s7lxgg7h\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-s7lxgg7h\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=593d0cdf460724eea027e92353df37b9a3217b060e949ad20d2d2508bf64bab6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mjak64zt/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx7wVx0OiYyv",
        "outputId": "a1cc7941-6aa2-4de3-e4e8-6b782a91795d"
      },
      "source": [
        "!gdown --id 1L6dd0FnYqgn-eoQ-gFnBiNji7R1ul9n_\n",
        "!gdown --id 1-5mE9XjocmyCKGlkpW1YGuCnNsGwQioD\n",
        "!gdown --id 1d4er4I7x4VIwy7BsWFpsPuC2z6aZ3P6s"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L6dd0FnYqgn-eoQ-gFnBiNji7R1ul9n_\n",
            "To: /content/NER_RFQ_agg.csv\n",
            "4.39MB [00:00, 39.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5mE9XjocmyCKGlkpW1YGuCnNsGwQioD\n",
            "To: /content/NER_RFQ_agg_train.csv\n",
            "3.48MB [00:00, 55.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d4er4I7x4VIwy7BsWFpsPuC2z6aZ3P6s\n",
            "To: /content/NER_RFQ_agg_test.csv\n",
            "100% 909k/909k [00:00<00:00, 14.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEfFyYZVph-B",
        "outputId": "af774d0f-2c72-41af-980e-b7434d0ef559"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "import gensim.downloader as api"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYiqiimi1vV"
      },
      "source": [
        "df = pd.read_csv('NER_RFQ_agg.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "train = pd.read_csv('NER_RFQ_agg_train.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "test = pd.read_csv('NER_RFQ_agg_test.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "\n",
        "all_dfs = [df, train, test]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAl784dWnJkR",
        "outputId": "1639d555-9f72-40ba-e1e2-f40cffa39217"
      },
      "source": [
        "pretrained_w2v = api.load(\"word2vec-ruscorpora-300\")\n",
        "pretrained_w2v.save_word2vec_format('tmp')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthif1zkvsok"
      },
      "source": [
        "def add_suffix(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in pretrained_w2v.vocab.keys():\n",
        "                res.append(w + suffix)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(w)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['tokens_with_suffix'] = d.apply(add_suffix, axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rp-IeYsnJf"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v = Word2Vec(sentences=df['tokens_with_suffix'], size=300, window=15, min_count=2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqqSfYYmY-p"
      },
      "source": [
        "w2v.intersect_word2vec_format('tmp')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz_dGApGKoB"
      },
      "source": [
        "all_tags = set()\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "labels = list(tag_to_idx.keys())\n",
        "labels.remove('O')\n",
        "labels = sorted(labels, key=lambda name: (name[1:], name[0]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wxpfE8Hx0u"
      },
      "source": [
        "def find_token(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ', '']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in w2v.wv.vocab.keys():\n",
        "                res.append(w2v.wv.vocab[w + suffix].index)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "J7BswpbHlVW2",
        "outputId": "cfc0afde-ffa7-432f-ac59-2ae549def6bc"
      },
      "source": [
        "df"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>tokens_with_suffix</th>\n",
              "      <th>encoded_ner_tags</th>\n",
              "      <th>int_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119287R.msg</td>\n",
              "      <td>[name, 119287r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 119287r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 206, 744, 293, 22, 190, 0, 30, 36, 237...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>119735R.msg</td>\n",
              "      <td>[name, 119735r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 119735r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 206, 744, 293, 22, 190, 6707, 624, 106...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>120421R.msg</td>\n",
              "      <td>[name, 120421r.msg, d.klebcha@s7.ru, &lt;d.klebch...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-GoodsString, I-Good...</td>\n",
              "      <td>[name_NOUN, 120421r.msg, d.klebcha@s7.ru, &lt;d.k...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 5524, 5525, 5526, 2961, 22, 57, 874, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120660R.msg</td>\n",
              "      <td>[name, 120660r.msg, yuliya, a., kondratova, &lt;y...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 120660r.msg, yuliya, a., kondratov...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>120660R.msg</td>\n",
              "      <td>[name, 120660r.msg, yuliya, a., kondratova, &lt;y...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 120660r.msg, yuliya, a., kondratov...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>123527R.msg</td>\n",
              "      <td>[name, 123527r.msg, =?utf-8?b?0kprincw0lrqvtcy...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-GoodsString, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123527r.msg, =?utf-8?b?0kprincw0lr...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 1249, 1250, 1251, 12, 22, 679, 0, 1026...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>123088R.msg</td>\n",
              "      <td>[name, 123088r.msg, lakshmi, suresh, &lt;lakshmi@...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123088r.msg, lakshmi, suresh, &lt;lak...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 6241, 4264, 4265, 6242, 2961, 22, 147, 62...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1189</th>\n",
              "      <td>123508R.msg</td>\n",
              "      <td>[name, 123508r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123508r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 7935, 206, 744, 293, 22, 190, 7936, 30, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1190</th>\n",
              "      <td>124894R.msg</td>\n",
              "      <td>[name, 124894r.msg, &lt;anton.peshko@utair.ru&gt;, a...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 124894r.msg, &lt;anton.peshko@utair.r...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 304, 47, 305, 304, 22, 115, 5523, 278,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191</th>\n",
              "      <td>124484R.msg</td>\n",
              "      <td>[name, 124484r.msg, &lt;gennadiy.moskatov@utair.r...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 124484r.msg, &lt;gennadiy.moskatov@ut...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 485, 220, 486, 485, 22, 115, 6706, 472...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1192 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                         int_tokens\n",
              "0     119287R.msg  ...  [19, 0, 206, 744, 293, 22, 190, 0, 30, 36, 237...\n",
              "1     119735R.msg  ...  [19, 0, 206, 744, 293, 22, 190, 6707, 624, 106...\n",
              "2     120421R.msg  ...  [19, 0, 5524, 5525, 5526, 2961, 22, 57, 874, 2...\n",
              "3     120660R.msg  ...  [19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...\n",
              "4     120660R.msg  ...  [19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...\n",
              "...           ...  ...                                                ...\n",
              "1187  123527R.msg  ...  [19, 0, 1249, 1250, 1251, 12, 22, 679, 0, 1026...\n",
              "1188  123088R.msg  ...  [19, 6241, 4264, 4265, 6242, 2961, 22, 147, 62...\n",
              "1189  123508R.msg  ...  [19, 7935, 206, 744, 293, 22, 190, 7936, 30, 3...\n",
              "1190  124894R.msg  ...  [19, 0, 304, 47, 305, 304, 22, 115, 5523, 278,...\n",
              "1191  124484R.msg  ...  [19, 0, 485, 220, 486, 485, 22, 115, 6706, 472...\n",
              "\n",
              "[1192 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QUuM6AhjxyK"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBokW5kspLO"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=1.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqAcUZxSMT2c"
      },
      "source": [
        "### PRETRAINED W2V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1S7oW2BWoX",
        "outputId": "9ab29d20-ba1c-4775-f225-a8216a1de593"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_1 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 2,866,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVZ0buRG02d",
        "outputId": "68a52250-d834-4642-dc5d-baeb3d44f706"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.8598 - crf_marginal_accuracy: 0.9966 - val_loss: 0.7978 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.7475 - crf_marginal_accuracy: 0.9966 - val_loss: 0.7143 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.6707 - crf_marginal_accuracy: 0.9966 - val_loss: 0.6430 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.6063 - crf_marginal_accuracy: 0.9966 - val_loss: 0.5838 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5529 - crf_marginal_accuracy: 0.9966 - val_loss: 0.5358 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5097 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4968 - val_crf_marginal_accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNVGThAXHeL",
        "outputId": "a88e0cd6-5792-4daf-dd4e-35f0f2288f44"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV6QMPc3cyy",
        "outputId": "72b8b8b2-60da-4988-8e07-7070aeae1ce3"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 321,430\n",
            "Non-trainable params: 2,544,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19U1yO8c3czD",
        "outputId": "2af9b223-fe72-48d1-b732-95ac54b41d15"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.8408 - crf_marginal_accuracy: 0.0013 - val_loss: 0.7039 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.6668 - crf_marginal_accuracy: 0.0013 - val_loss: 0.6323 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.6011 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5742 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.5496 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5307 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.5117 - crf_marginal_accuracy: 0.0014 - val_loss: 0.4999 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4854 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4795 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4684 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4672 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4585 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4609 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.4537 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4584 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.4519 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.0021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU37zLsF3czD",
        "outputId": "626ad886-8930-4b80-c694-d9b0466f8b80"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0217    1.0000    0.0425      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0217    0.3923    0.0411      2827\n",
            "    macro avg     0.0108    0.5000    0.0212      2827\n",
            " weighted avg     0.0085    0.3923    0.0167      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZCqkOHtMW19"
      },
      "source": [
        "### BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4F8rx-E7rq9"
      },
      "source": [
        "all_tags = set()\n",
        "word_to_ix = {}\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "    for word in row.tokens:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "# tag_to_idx['EOS'] = len(tag_to_idx)\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "# label_list[len(label_list)] = 'EOS'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KrZeMrT3eo-",
        "outputId": "fbfcdc1d-90a0-4697-c7ea-1e66ef8b7c0f"
      },
      "source": [
        "MAX_WORDS = len(word_to_ix)\n",
        "EMBEDDING_LENGTH = 300\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "# model.add(Dense(50))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 3004, 300)         3708300   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 4,029,730\n",
            "Trainable params: 4,029,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FveQSE6t3epA",
        "outputId": "63a5da72-9fad-4a94-a743-616fe9e5d24e"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=MAX_WORDS)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.7834 - crf_marginal_accuracy: 0.0019 - val_loss: 0.6100 - val_crf_marginal_accuracy: 0.0087\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.5189 - crf_marginal_accuracy: 0.4064 - val_loss: 0.4878 - val_crf_marginal_accuracy: 0.9901\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4379 - crf_marginal_accuracy: 0.9954 - val_loss: 0.4427 - val_crf_marginal_accuracy: 0.9975\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3846 - crf_marginal_accuracy: 0.9981 - val_loss: 0.4084 - val_crf_marginal_accuracy: 0.9979\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.3170 - crf_marginal_accuracy: 0.9985 - val_loss: 0.3729 - val_crf_marginal_accuracy: 0.9985\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.2407 - crf_marginal_accuracy: 0.9991 - val_loss: 0.3551 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.1810 - crf_marginal_accuracy: 0.9995 - val_loss: 0.3616 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.1387 - crf_marginal_accuracy: 0.9996 - val_loss: 0.3727 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1118 - crf_marginal_accuracy: 0.9997 - val_loss: 0.3536 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0952 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3787 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0774 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3600 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0620 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3687 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0516 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3850 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0472 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4093 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0380 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4106 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.0349 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4247 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0310 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4157 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0274 - crf_marginal_accuracy: 1.0000 - val_loss: 0.3992 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0238 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4466 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.0231 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4713 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0221 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4113 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0188 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4380 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0170 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4613 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 89s 103ms/step - loss: 0.0167 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4769 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0154 - crf_marginal_accuracy: 1.0000 - val_loss: 0.5387 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 26/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.0151 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4748 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 27/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.0168 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4514 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 28/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.0154 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4718 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 29/30\n",
            "857/857 [==============================] - 89s 103ms/step - loss: 0.0160 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4342 - val_crf_marginal_accuracy: 0.9994\n",
            "Epoch 30/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.0144 - crf_marginal_accuracy: 1.0000 - val_loss: 0.5019 - val_crf_marginal_accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgGsK_Yc3epA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071afd88-b372-4b52-e0c7-1ff18b12ab2f"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9252    0.8584    0.8906      1109\n",
            "I-GoodsString     0.9281    0.8411    0.8824      1718\n",
            "\n",
            "    micro avg     0.9269    0.8479    0.8856      2827\n",
            "    macro avg     0.9266    0.8498    0.8865      2827\n",
            " weighted avg     0.9269    0.8479    0.8856      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doR8vcjvMNnS"
      },
      "source": [
        "### NOT PRETRAINED W2V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRins3GMDd-"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, min_count=2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYYv7a7bMMEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d328f5a-0d09-4d7d-a1ae-4d1ac745c03e"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_4 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 2,866,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9AHayBOMMEK",
        "outputId": "e8e8ee34-d0b8-4e13-ca76-5e03dac09a72"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.8281 - crf_marginal_accuracy: 0.4165 - val_loss: 0.5660 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5053 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4819 - val_crf_marginal_accuracy: 0.9958\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.4559 - crf_marginal_accuracy: 0.9950 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9938\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.4340 - crf_marginal_accuracy: 0.9955 - val_loss: 0.4420 - val_crf_marginal_accuracy: 0.9942\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.4118 - crf_marginal_accuracy: 0.9956 - val_loss: 0.4254 - val_crf_marginal_accuracy: 0.9944\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.3818 - crf_marginal_accuracy: 0.9969 - val_loss: 0.3987 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3394 - crf_marginal_accuracy: 0.9978 - val_loss: 0.3650 - val_crf_marginal_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.2839 - crf_marginal_accuracy: 0.9985 - val_loss: 0.3294 - val_crf_marginal_accuracy: 0.9982\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.2295 - crf_marginal_accuracy: 0.9991 - val_loss: 0.3077 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1849 - crf_marginal_accuracy: 0.9994 - val_loss: 0.2864 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1478 - crf_marginal_accuracy: 0.9996 - val_loss: 0.2829 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1197 - crf_marginal_accuracy: 0.9997 - val_loss: 0.2776 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0987 - crf_marginal_accuracy: 0.9998 - val_loss: 0.2941 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.0897 - crf_marginal_accuracy: 0.9998 - val_loss: 0.2788 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.0787 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3065 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0680 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3203 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0584 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3303 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.0511 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3513 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0445 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3489 - val_crf_marginal_accuracy: 0.9992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cofffkTqMMEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4698b19c-637a-4bc9-80cd-211665d3f17c"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.8785    0.8801    0.8793      1109\n",
            "I-GoodsString     0.8928    0.8626    0.8774      1718\n",
            "\n",
            "    micro avg     0.8870    0.8695    0.8782      2827\n",
            "    macro avg     0.8856    0.8714    0.8784      2827\n",
            " weighted avg     0.8872    0.8695    0.8782      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKFIa_0IMMEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1fcbae-c075-4c9c-b4c9-54bc3bae988e"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_5 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 321,430\n",
            "Non-trainable params: 2,544,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSFEq-vMMEL",
        "outputId": "488d183d-f2ce-4c51-8b7c-22f33284d7db"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.7808 - crf_marginal_accuracy: 0.9966 - val_loss: 0.7331 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.6922 - crf_marginal_accuracy: 0.9966 - val_loss: 0.6599 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.6248 - crf_marginal_accuracy: 0.9966 - val_loss: 0.5984 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 84s 99ms/step - loss: 0.5693 - crf_marginal_accuracy: 0.9966 - val_loss: 0.5482 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.5242 - crf_marginal_accuracy: 0.9966 - val_loss: 0.5081 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.4887 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4816 - val_crf_marginal_accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-v-3tFMMEL",
        "outputId": "1e0fea3f-66dc-48dd-99a8-c6a1497b1e94"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cFsMLIHi76D"
      },
      "source": [
        "## window=5, min_count=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGPObsQWal6"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, min_count=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDnQ8VNWal-",
        "outputId": "30867e63-4246-4ddf-84c6-dad3efa01696"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 3004, 300)         3708300   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_6 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 4,029,730\n",
            "Trainable params: 4,029,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqCw-lOWamB",
        "outputId": "d359cdb5-a21a-4ed5-b788-12907d159947"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 93s 109ms/step - loss: 0.5392 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4942 - val_crf_marginal_accuracy: 0.0016\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.4665 - crf_marginal_accuracy: 0.1112 - val_loss: 0.4630 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.4543 - crf_marginal_accuracy: 0.9965 - val_loss: 0.4590 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4498 - crf_marginal_accuracy: 0.9941 - val_loss: 0.4581 - val_crf_marginal_accuracy: 0.9902\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4469 - crf_marginal_accuracy: 0.9952 - val_loss: 0.4561 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4417 - crf_marginal_accuracy: 0.9972 - val_loss: 0.4524 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4313 - crf_marginal_accuracy: 0.9973 - val_loss: 0.4468 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4094 - crf_marginal_accuracy: 0.9974 - val_loss: 0.4360 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3700 - crf_marginal_accuracy: 0.9975 - val_loss: 0.4237 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3269 - crf_marginal_accuracy: 0.9977 - val_loss: 0.4207 - val_crf_marginal_accuracy: 0.9971\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3042 - crf_marginal_accuracy: 0.9978 - val_loss: 0.4450 - val_crf_marginal_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.2814 - crf_marginal_accuracy: 0.9979 - val_loss: 0.4295 - val_crf_marginal_accuracy: 0.9975\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.2496 - crf_marginal_accuracy: 0.9980 - val_loss: 0.4045 - val_crf_marginal_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.2215 - crf_marginal_accuracy: 0.9981 - val_loss: 0.3974 - val_crf_marginal_accuracy: 0.9974\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1992 - crf_marginal_accuracy: 0.9982 - val_loss: 0.3925 - val_crf_marginal_accuracy: 0.9976\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1827 - crf_marginal_accuracy: 0.9983 - val_loss: 0.4025 - val_crf_marginal_accuracy: 0.9977\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1665 - crf_marginal_accuracy: 0.9983 - val_loss: 0.4481 - val_crf_marginal_accuracy: 0.9978\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1574 - crf_marginal_accuracy: 0.9985 - val_loss: 0.4286 - val_crf_marginal_accuracy: 0.9978\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1606 - crf_marginal_accuracy: 0.9985 - val_loss: 0.4608 - val_crf_marginal_accuracy: 0.9980\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1489 - crf_marginal_accuracy: 0.9986 - val_loss: 0.4568 - val_crf_marginal_accuracy: 0.9981\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1412 - crf_marginal_accuracy: 0.9987 - val_loss: 0.4901 - val_crf_marginal_accuracy: 0.9981\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1385 - crf_marginal_accuracy: 0.9987 - val_loss: 0.4663 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1327 - crf_marginal_accuracy: 0.9990 - val_loss: 0.4770 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1233 - crf_marginal_accuracy: 0.9993 - val_loss: 0.4901 - val_crf_marginal_accuracy: 0.9986\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1162 - crf_marginal_accuracy: 0.9993 - val_loss: 0.5041 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1090 - crf_marginal_accuracy: 0.9994 - val_loss: 0.4858 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 27/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1015 - crf_marginal_accuracy: 0.9995 - val_loss: 0.5584 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 28/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0952 - crf_marginal_accuracy: 0.9996 - val_loss: 0.5582 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 29/30\n",
            "857/857 [==============================] - 89s 103ms/step - loss: 0.0890 - crf_marginal_accuracy: 0.9997 - val_loss: 0.5513 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 30/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.0812 - crf_marginal_accuracy: 0.9997 - val_loss: 0.5762 - val_crf_marginal_accuracy: 0.9990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCujGbXWamC",
        "outputId": "69acc499-ba4a-485f-ea7d-edefb6001d33"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9130    0.8512    0.8810      1109\n",
            "I-GoodsString     0.8340    0.8335    0.8338      1718\n",
            "\n",
            "    micro avg     0.8637    0.8405    0.8519      2827\n",
            "    macro avg     0.8735    0.8424    0.8574      2827\n",
            " weighted avg     0.8650    0.8405    0.8523      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jRCZwwNWamC"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipy3tg6aWamD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac9552f-ca75-4eed-a1ee-6eb9e024c9d2"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.6836 - crf_marginal_accuracy: 0.0029 - val_loss: 0.6254 - val_crf_marginal_accuracy: 0.0018\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.5899 - crf_marginal_accuracy: 0.0014 - val_loss: 0.5625 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.5366 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5185 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4988 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4886 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 85s 100ms/step - loss: 0.4741 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4707 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4603 - crf_marginal_accuracy: 0.0016 - val_loss: 0.4619 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4540 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4585 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4518 - crf_marginal_accuracy: 0.0024 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.0031\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4513 - crf_marginal_accuracy: 0.5517 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4513 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuStVCRzWamD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4dfe637-403c-40ac-f9e2-0d2b35f039c4"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBED-952jGa_"
      },
      "source": [
        "## window=5, max_vocab_size=15000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBV_xu9jJ7O"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, max_vocab_size=15000)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWAPWdOxjJ7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8d6511-e394-4bcb-9586-cab31965fdcb"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 3004, 300)         1419600   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_8 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 1,741,030\n",
            "Trainable params: 1,741,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmtqjRfCjJ7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c38777-0c43-48f6-a95f-504218ebffde"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 135s 158ms/step - loss: 0.5672 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5213 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.4992 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4927 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 126s 147ms/step - loss: 0.4757 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4734 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.4607 - crf_marginal_accuracy: 0.0017 - val_loss: 0.4626 - val_crf_marginal_accuracy: 0.0024\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.4538 - crf_marginal_accuracy: 0.0026 - val_loss: 0.4587 - val_crf_marginal_accuracy: 0.0028\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 122s 142ms/step - loss: 0.4520 - crf_marginal_accuracy: 0.0027 - val_loss: 0.4579 - val_crf_marginal_accuracy: 0.0028\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 122s 143ms/step - loss: 0.4520 - crf_marginal_accuracy: 0.1060 - val_loss: 0.4579 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 121s 142ms/step - loss: 0.4520 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4580 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 122s 142ms/step - loss: 0.4519 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4580 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 121s 141ms/step - loss: 0.4517 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 122s 142ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.4485 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.0028\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 118s 137ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.0027 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBqJIeRajJ7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fbd83d-402d-4936-c9df-d474a5c85931"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaebcYB-jJ7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb326308-6091-474c-d2a3-fb22fae0807d"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 3004, 300)         1419600   \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_10 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 1,741,030\n",
            "Trainable params: 321,430\n",
            "Non-trainable params: 1,419,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk48dUX-jJ7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aadcf954-a5b5-43fe-88da-661f9ee721e7"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.5790 - crf_marginal_accuracy: 0.0019 - val_loss: 0.4979 - val_crf_marginal_accuracy: 0.0080\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4748 - crf_marginal_accuracy: 0.5495 - val_loss: 0.4782 - val_crf_marginal_accuracy: 0.9737\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4612 - crf_marginal_accuracy: 0.9812 - val_loss: 0.4644 - val_crf_marginal_accuracy: 0.9859\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4527 - crf_marginal_accuracy: 0.8922 - val_loss: 0.4603 - val_crf_marginal_accuracy: 0.9858\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4495 - crf_marginal_accuracy: 0.9893 - val_loss: 0.4592 - val_crf_marginal_accuracy: 0.9932\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4472 - crf_marginal_accuracy: 0.9948 - val_loss: 0.4578 - val_crf_marginal_accuracy: 0.9950\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4456 - crf_marginal_accuracy: 0.9955 - val_loss: 0.4562 - val_crf_marginal_accuracy: 0.9952\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4436 - crf_marginal_accuracy: 0.9953 - val_loss: 0.4547 - val_crf_marginal_accuracy: 0.9947\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.4408 - crf_marginal_accuracy: 0.9946 - val_loss: 0.4544 - val_crf_marginal_accuracy: 0.9930\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4391 - crf_marginal_accuracy: 0.9931 - val_loss: 0.4545 - val_crf_marginal_accuracy: 0.9861\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.4354 - crf_marginal_accuracy: 0.9894 - val_loss: 0.4495 - val_crf_marginal_accuracy: 0.9885\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4317 - crf_marginal_accuracy: 0.9865 - val_loss: 0.4482 - val_crf_marginal_accuracy: 0.9754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRxCwd2njJ7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6616bcb-32a3-42e2-dac7-1bcf43825213"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.2814    0.2687    0.2749      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.2166    0.1054    0.1418      2827\n",
            "    macro avg     0.1407    0.1344    0.1375      2827\n",
            " weighted avg     0.1104    0.1054    0.1078      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4WKYxHZuT9p"
      },
      "source": [
        "## SOME MORE TO COME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgm2UrFtuT9p"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=25, min_count=2)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si5Zc-UjuEN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c65c058-09c2-44fe-f3ba-047cc36244dc"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_11 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 2,866,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EN4RSuMuEN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e863fc91-ce79-4ff0-89b7-ee26b46a70bd"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 97s 113ms/step - loss: 0.7928 - crf_marginal_accuracy: 0.0043 - val_loss: 0.7336 - val_crf_marginal_accuracy: 0.0073\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.6980 - crf_marginal_accuracy: 0.0069 - val_loss: 0.6589 - val_crf_marginal_accuracy: 0.0120\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.6320 - crf_marginal_accuracy: 0.0085 - val_loss: 0.6064 - val_crf_marginal_accuracy: 0.0101\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5851 - crf_marginal_accuracy: 0.0082 - val_loss: 0.5657 - val_crf_marginal_accuracy: 0.0108\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5470 - crf_marginal_accuracy: 0.0079 - val_loss: 0.5319 - val_crf_marginal_accuracy: 0.0100\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5160 - crf_marginal_accuracy: 0.0078 - val_loss: 0.5051 - val_crf_marginal_accuracy: 0.0098\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.4919 - crf_marginal_accuracy: 0.0078 - val_loss: 0.4856 - val_crf_marginal_accuracy: 0.0102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGjQQcIDuEN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862c2766-b5bf-4755-a975-f539e5cbad1f"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0379    1.0000    0.0730      1718\n",
            "\n",
            "    micro avg     0.0379    0.6077    0.0713      2827\n",
            "    macro avg     0.0189    0.5000    0.0365      2827\n",
            " weighted avg     0.0230    0.6077    0.0444      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAsUlkf-ap4n"
      },
      "source": [
        "## GLOVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNrzxYz3ar3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e13046-a894-4677-8a3f-118e4becb80d"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=15)\n",
        "\n",
        "glove = Glove(no_components=300, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtUIADA6a6h-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c32745-3145-4360-b885-ac8c0d837ec7"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 3004, 300)         3708300   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_8 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 4,029,730\n",
            "Trainable params: 4,029,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTxAndSBa6iK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a69d1f1-46bd-4d92-f903-4daaa707e87e"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 96s 112ms/step - loss: 0.6774 - crf_marginal_accuracy: 0.6809 - val_loss: 0.5828 - val_crf_marginal_accuracy: 0.9818\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.5395 - crf_marginal_accuracy: 0.9945 - val_loss: 0.4977 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.4692 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4607 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.4422 - crf_marginal_accuracy: 0.3044 - val_loss: 0.4531 - val_crf_marginal_accuracy: 0.0040\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.4294 - crf_marginal_accuracy: 0.0041 - val_loss: 0.4457 - val_crf_marginal_accuracy: 0.0042\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.4005 - crf_marginal_accuracy: 0.0042 - val_loss: 0.4259 - val_crf_marginal_accuracy: 0.0053\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.3530 - crf_marginal_accuracy: 0.0067 - val_loss: 0.4126 - val_crf_marginal_accuracy: 0.0192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fQo3JKAa6iL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56bb3825-51c6-43a6-9e0a-8b692b98967b"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7KzsnJxvbDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9cc649-83bf-45dc-d7e5-8c6b8251af2a"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 3004, 300)         3708300   \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_9 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 4,029,730\n",
            "Trainable params: 321,430\n",
            "Non-trainable params: 3,708,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE_R3XoqvbDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4faec9-a230-4902-8b18-546825760ded"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 94s 110ms/step - loss: 0.6839 - crf_marginal_accuracy: 0.0013 - val_loss: 0.6462 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.6071 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5798 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.5482 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5297 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.5057 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4958 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.4786 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4752 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.4632 - crf_marginal_accuracy: 0.0014 - val_loss: 0.4647 - val_crf_marginal_accuracy: 0.0018\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.4557 - crf_marginal_accuracy: 0.0017 - val_loss: 0.4599 - val_crf_marginal_accuracy: 0.0018\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.4525 - crf_marginal_accuracy: 0.0019 - val_loss: 0.4580 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.0024\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.5509 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9959 - val_loss: 0.4574 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9959 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 85s 100ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.9962 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.8562 - val_loss: 0.4574 - val_crf_marginal_accuracy: 0.0034\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.3922 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQU0DDgvbDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3feb035-964f-4516-c324-522a8fbab6b5"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWSpAUjhXbVN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}