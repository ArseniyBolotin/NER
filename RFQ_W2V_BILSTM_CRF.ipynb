{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RFQ_W2V_BILSTM_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raJ-rDdCJt_",
        "outputId": "ee464815-020f-46b1-de53-2b7c8346c953"
      },
      "source": [
        "!pip install sklearn_crfsuite\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install tensorflow==1.15.0 keras==2.2.4\n",
        "!pip3 install glove-python-binary\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-jjluljp6\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-jjluljp6\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=828cec8f6f5098b2f200cc759539aeb6d3285b4daec31b996e37b59d958300be\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cslh213u/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hCollecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.12.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 59.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=a78c655d402bdfd498aa4ac71487f23e5a25b80db4e2721b872a75152ff85d22\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, gast, tensorboard, tensorflow, keras\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed gast-0.2.2 keras-2.2.4 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting glove-python-binary\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/11/d8510a80110f736822856db566341dd2e1e7c3af536f77e409a6c09e0c22/glove_python_binary-0.2.0-cp37-cp37m-manylinux1_x86_64.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Installing collected packages: glove-python-binary\n",
            "Successfully installed glove-python-binary-0.2.0\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-f1r82yoe\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-f1r82yoe\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=64a3d3b1fa1a9d0dfeec0d8845a5bf855ca94f9b46598a0da8decddbf2e0cfc4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3eu6eyms/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx7wVx0OiYyv",
        "outputId": "8f6df766-6bb0-4c97-adeb-29219d07fd77"
      },
      "source": [
        "!gdown --id 1L6dd0FnYqgn-eoQ-gFnBiNji7R1ul9n_\n",
        "!gdown --id 1-5mE9XjocmyCKGlkpW1YGuCnNsGwQioD\n",
        "!gdown --id 1d4er4I7x4VIwy7BsWFpsPuC2z6aZ3P6s"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L6dd0FnYqgn-eoQ-gFnBiNji7R1ul9n_\n",
            "To: /content/NER_RFQ_agg.csv\n",
            "4.39MB [00:00, 39.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5mE9XjocmyCKGlkpW1YGuCnNsGwQioD\n",
            "To: /content/NER_RFQ_agg_train.csv\n",
            "3.48MB [00:00, 55.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d4er4I7x4VIwy7BsWFpsPuC2z6aZ3P6s\n",
            "To: /content/NER_RFQ_agg_test.csv\n",
            "100% 909k/909k [00:00<00:00, 14.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEfFyYZVph-B",
        "outputId": "5b67f62e-f0ef-4fec-ffd3-a37bc93d9e34"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "import gensim.downloader as api"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYiqiimi1vV"
      },
      "source": [
        "df = pd.read_csv('NER_RFQ_agg.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "train = pd.read_csv('NER_RFQ_agg_train.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "test = pd.read_csv('NER_RFQ_agg_test.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "\n",
        "all_dfs = [df, train, test]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz_dGApGKoB"
      },
      "source": [
        "all_tags = set()\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "labels = list(tag_to_idx.keys())\n",
        "labels.remove('O')\n",
        "labels = sorted(labels, key=lambda name: (name[1:], name[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAl784dWnJkR",
        "outputId": "c10ef5bc-3a84-4f9c-bbc1-5e4b2dae7498"
      },
      "source": [
        "pretrained_w2v = api.load(\"word2vec-ruscorpora-300\")\n",
        "pretrained_w2v.save_word2vec_format('tmp')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthif1zkvsok"
      },
      "source": [
        "def add_suffix(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in pretrained_w2v.vocab.keys():\n",
        "                res.append(w + suffix)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(w)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['tokens_with_suffix'] = d.apply(add_suffix, axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rp-IeYsnJf"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v = Word2Vec(sentences=df['tokens_with_suffix'], size=300, window=5, min_count=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyqqSfYYmY-p"
      },
      "source": [
        "w2v.intersect_word2vec_format('tmp')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75wxpfE8Hx0u"
      },
      "source": [
        "def find_token(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ', '']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in w2v.wv.vocab.keys():\n",
        "                res.append(w2v.wv.vocab[w + suffix].index)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "J7BswpbHlVW2",
        "outputId": "bc273c9a-f272-47df-eeda-b3047724b8cc"
      },
      "source": [
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>tokens_with_suffix</th>\n",
              "      <th>encoded_ner_tags</th>\n",
              "      <th>int_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119287R.msg</td>\n",
              "      <td>[name, 119287r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 119287r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 206, 744, 293, 22, 190, 0, 30, 36, 237...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>119735R.msg</td>\n",
              "      <td>[name, 119735r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 119735r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 206, 744, 293, 22, 190, 6707, 624, 106...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>120421R.msg</td>\n",
              "      <td>[name, 120421r.msg, d.klebcha@s7.ru, &lt;d.klebch...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-GoodsString, I-Good...</td>\n",
              "      <td>[name_NOUN, 120421r.msg, d.klebcha@s7.ru, &lt;d.k...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 5524, 5525, 5526, 2961, 22, 57, 874, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120660R.msg</td>\n",
              "      <td>[name, 120660r.msg, yuliya, a., kondratova, &lt;y...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 120660r.msg, yuliya, a., kondratov...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>120660R.msg</td>\n",
              "      <td>[name, 120660r.msg, yuliya, a., kondratova, &lt;y...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 120660r.msg, yuliya, a., kondratov...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>123527R.msg</td>\n",
              "      <td>[name, 123527r.msg, =?utf-8?b?0kprincw0lrqvtcy...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-GoodsString, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123527r.msg, =?utf-8?b?0kprincw0lr...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 1249, 1250, 1251, 12, 22, 679, 0, 1026...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>123088R.msg</td>\n",
              "      <td>[name, 123088r.msg, lakshmi, suresh, &lt;lakshmi@...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123088r.msg, lakshmi, suresh, &lt;lak...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 6241, 4264, 4265, 6242, 2961, 22, 147, 62...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1189</th>\n",
              "      <td>123508R.msg</td>\n",
              "      <td>[name, 123508r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123508r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 7935, 206, 744, 293, 22, 190, 7936, 30, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1190</th>\n",
              "      <td>124894R.msg</td>\n",
              "      <td>[name, 124894r.msg, &lt;anton.peshko@utair.ru&gt;, a...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 124894r.msg, &lt;anton.peshko@utair.r...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 304, 47, 305, 304, 22, 115, 5523, 278,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191</th>\n",
              "      <td>124484R.msg</td>\n",
              "      <td>[name, 124484r.msg, &lt;gennadiy.moskatov@utair.r...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 124484r.msg, &lt;gennadiy.moskatov@ut...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 485, 220, 486, 485, 22, 115, 6706, 472...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1192 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                         int_tokens\n",
              "0     119287R.msg  ...  [19, 0, 206, 744, 293, 22, 190, 0, 30, 36, 237...\n",
              "1     119735R.msg  ...  [19, 0, 206, 744, 293, 22, 190, 6707, 624, 106...\n",
              "2     120421R.msg  ...  [19, 0, 5524, 5525, 5526, 2961, 22, 57, 874, 2...\n",
              "3     120660R.msg  ...  [19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...\n",
              "4     120660R.msg  ...  [19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...\n",
              "...           ...  ...                                                ...\n",
              "1187  123527R.msg  ...  [19, 0, 1249, 1250, 1251, 12, 22, 679, 0, 1026...\n",
              "1188  123088R.msg  ...  [19, 6241, 4264, 4265, 6242, 2961, 22, 147, 62...\n",
              "1189  123508R.msg  ...  [19, 7935, 206, 744, 293, 22, 190, 7936, 30, 3...\n",
              "1190  124894R.msg  ...  [19, 0, 304, 47, 305, 304, 22, 115, 5523, 278,...\n",
              "1191  124484R.msg  ...  [19, 0, 485, 220, 486, 485, 22, 115, 6706, 472...\n",
              "\n",
              "[1192 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QUuM6AhjxyK"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBokW5kspLO"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=1.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqAcUZxSMT2c"
      },
      "source": [
        "## PRETRAINED W2V(not fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1S7oW2BWoX",
        "outputId": "552c7af4-b1c6-472f-fe4e-7de70f3d0438"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 2,866,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVZ0buRG02d",
        "outputId": "886e8fae-59f1-4f27-abc8-76f5f671276c"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='pretrained_best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('pretrained_best_model.h5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 94s 110ms/step - loss: 0.6816 - crf_marginal_accuracy: 0.8232 - val_loss: 0.5591 - val_crf_marginal_accuracy: 0.9385\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.5166 - crf_marginal_accuracy: 0.5827 - val_loss: 0.4881 - val_crf_marginal_accuracy: 0.0336\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.4625 - crf_marginal_accuracy: 0.5531 - val_loss: 0.4596 - val_crf_marginal_accuracy: 0.9944\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 93s 109ms/step - loss: 0.4430 - crf_marginal_accuracy: 0.9971 - val_loss: 0.4523 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.4267 - crf_marginal_accuracy: 0.9974 - val_loss: 0.4438 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 92s 108ms/step - loss: 0.3968 - crf_marginal_accuracy: 0.9975 - val_loss: 0.4340 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 93s 108ms/step - loss: 0.3611 - crf_marginal_accuracy: 0.9978 - val_loss: 0.4241 - val_crf_marginal_accuracy: 0.9973\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 92s 108ms/step - loss: 0.3289 - crf_marginal_accuracy: 0.9981 - val_loss: 0.4169 - val_crf_marginal_accuracy: 0.9975\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.2971 - crf_marginal_accuracy: 0.9985 - val_loss: 0.4078 - val_crf_marginal_accuracy: 0.9980\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.2610 - crf_marginal_accuracy: 0.9989 - val_loss: 0.3823 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.2185 - crf_marginal_accuracy: 0.9992 - val_loss: 0.3798 - val_crf_marginal_accuracy: 0.9986\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.1867 - crf_marginal_accuracy: 0.9995 - val_loss: 0.3834 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.1604 - crf_marginal_accuracy: 0.9996 - val_loss: 0.4381 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.1407 - crf_marginal_accuracy: 0.9997 - val_loss: 0.4305 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.1850 - crf_marginal_accuracy: 0.9996 - val_loss: 0.4239 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.1870 - crf_marginal_accuracy: 0.9996 - val_loss: 0.3890 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.1576 - crf_marginal_accuracy: 0.9997 - val_loss: 0.4067 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.1398 - crf_marginal_accuracy: 0.9997 - val_loss: 0.3881 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.1202 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3943 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.1055 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3988 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0908 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4222 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0805 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4266 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0747 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4414 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.0649 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4527 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0616 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4775 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 26/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0579 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5037 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 27/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0534 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4828 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 28/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0509 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4985 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 29/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.0455 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5202 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 30/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.0431 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5338 - val_crf_marginal_accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNVGThAXHeL",
        "outputId": "4f946c1d-c5b7-49c1-ccfd-a046e8f5ffb9"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9153    0.8377    0.8748      1109\n",
            "I-GoodsString     0.9250    0.8038    0.8602      1718\n",
            "\n",
            "    micro avg     0.9211    0.8171    0.8660      2827\n",
            "    macro avg     0.9201    0.8208    0.8675      2827\n",
            " weighted avg     0.9212    0.8171    0.8659      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JNx5ntzrHuK"
      },
      "source": [
        "## PRETRAINED W2V(fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV6QMPc3cyy",
        "outputId": "77f9221b-ee03-479c-fa07-afc8de4288cc"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 20\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 3004, 40)          51360     \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 3004, 3)           123       \n",
            "_________________________________________________________________\n",
            "crf_7 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,596,410\n",
            "Trainable params: 51,510\n",
            "Non-trainable params: 2,544,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19U1yO8c3czD",
        "outputId": "0b59ed11-bd42-47a3-88f1-c631c226a065"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='pretrained_best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('pretrained_best_model_fixed_embeds.h5')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.5753 - crf_marginal_accuracy: 0.9856 - val_loss: 0.4858 - val_crf_marginal_accuracy: 0.0375\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.4676 - crf_marginal_accuracy: 0.5657 - val_loss: 0.4711 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4607 - crf_marginal_accuracy: 0.9918 - val_loss: 0.4660 - val_crf_marginal_accuracy: 0.9772\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.4562 - crf_marginal_accuracy: 0.9901 - val_loss: 0.4625 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.4548 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4610 - val_crf_marginal_accuracy: 0.9958\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 89s 103ms/step - loss: 0.4533 - crf_marginal_accuracy: 0.9925 - val_loss: 0.4608 - val_crf_marginal_accuracy: 0.9921\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.4532 - crf_marginal_accuracy: 0.9954 - val_loss: 0.4610 - val_crf_marginal_accuracy: 0.9960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU37zLsF3czD",
        "outputId": "ddc00da6-1dbe-40e5-91b2-ef91ee5b9171"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.3455    0.1190    0.1771      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.3455    0.0467    0.0823      2827\n",
            "    macro avg     0.1728    0.0595    0.0885      2827\n",
            " weighted avg     0.1356    0.0467    0.0695      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0M6U9bFpeSI"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRins3GMDd-"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, min_count=2)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYYv7a7bMMEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e606edad-488e-42a9-f3c3-240acee7719d"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 3004, 100)         140400    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_11 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,685,630\n",
            "Trainable params: 2,685,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9AHayBOMMEK",
        "outputId": "5ca96473-9a50-4111-91c6-685c649207b1"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='not_pretrained_best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('not_pretrained_best_model.h5')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 98s 114ms/step - loss: 0.4957 - crf_marginal_accuracy: 0.6872 - val_loss: 0.4646 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.4535 - crf_marginal_accuracy: 0.4771 - val_loss: 0.4569 - val_crf_marginal_accuracy: 0.0709\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.4468 - crf_marginal_accuracy: 0.8567 - val_loss: 0.4542 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.4386 - crf_marginal_accuracy: 0.9969 - val_loss: 0.4468 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.4189 - crf_marginal_accuracy: 0.9970 - val_loss: 0.4338 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.3850 - crf_marginal_accuracy: 0.9977 - val_loss: 0.4165 - val_crf_marginal_accuracy: 0.9975\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.3317 - crf_marginal_accuracy: 0.9983 - val_loss: 0.4171 - val_crf_marginal_accuracy: 0.9977\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.2653 - crf_marginal_accuracy: 0.9988 - val_loss: 0.4012 - val_crf_marginal_accuracy: 0.9982\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.2121 - crf_marginal_accuracy: 0.9992 - val_loss: 0.3723 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.1718 - crf_marginal_accuracy: 0.9995 - val_loss: 0.3861 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.1476 - crf_marginal_accuracy: 0.9995 - val_loss: 0.4065 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.1200 - crf_marginal_accuracy: 0.9996 - val_loss: 0.3672 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.0898 - crf_marginal_accuracy: 0.9997 - val_loss: 0.3499 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0734 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3959 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0604 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3799 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0551 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3644 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0511 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3988 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0427 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4072 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0372 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4425 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0344 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4732 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0320 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4689 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5235 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0281 - crf_marginal_accuracy: 0.9998 - val_loss: 0.5479 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0261 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5762 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0240 - crf_marginal_accuracy: 0.9999 - val_loss: 0.6077 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 26/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0217 - crf_marginal_accuracy: 0.9999 - val_loss: 0.6101 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 27/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0225 - crf_marginal_accuracy: 0.9999 - val_loss: 0.6157 - val_crf_marginal_accuracy: 0.9992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cofffkTqMMEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab28ce8a-e2d4-4ab7-e8c4-f256d7990c29"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9026    0.8602    0.8809      1109\n",
            "I-GoodsString     0.8842    0.8487    0.8661      1718\n",
            "\n",
            "    micro avg     0.8914    0.8532    0.8719      2827\n",
            "    macro avg     0.8934    0.8544    0.8735      2827\n",
            " weighted avg     0.8914    0.8532    0.8719      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9pIp5Zpjqo"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKFIa_0IMMEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843c78e3-02d9-43f3-8a40-279148bcacdc"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 3004, 100)         140400    \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_14 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,685,630\n",
            "Trainable params: 140,730\n",
            "Non-trainable params: 2,544,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSFEq-vMMEL",
        "outputId": "c58e87b3-2bed-456e-b820-4339cf032c4a"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='not_pretrained_best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('not_pretrained_best_model_fixed_embeds.h5')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 94s 110ms/step - loss: 0.8406 - crf_marginal_accuracy: 0.7011 - val_loss: 0.6911 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.6389 - crf_marginal_accuracy: 0.9966 - val_loss: 0.5791 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.5386 - crf_marginal_accuracy: 0.9966 - val_loss: 0.5046 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 85s 100ms/step - loss: 0.4817 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4678 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4562 - crf_marginal_accuracy: 0.9965 - val_loss: 0.4586 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4531 - crf_marginal_accuracy: 0.1504 - val_loss: 0.4596 - val_crf_marginal_accuracy: 0.0021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-v-3tFMMEL",
        "outputId": "1e0fea3f-66dc-48dd-99a8-c6a1497b1e94"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Rxo5d1o93d"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGPObsQWal6"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, min_count=1)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDnQ8VNWal-",
        "outputId": "30867e63-4246-4ddf-84c6-dad3efa01696"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 3004, 300)         3708300   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_6 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 4,029,730\n",
            "Trainable params: 4,029,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqCw-lOWamB",
        "outputId": "d359cdb5-a21a-4ed5-b788-12907d159947"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 93s 109ms/step - loss: 0.5392 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4942 - val_crf_marginal_accuracy: 0.0016\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.4665 - crf_marginal_accuracy: 0.1112 - val_loss: 0.4630 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.4543 - crf_marginal_accuracy: 0.9965 - val_loss: 0.4590 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4498 - crf_marginal_accuracy: 0.9941 - val_loss: 0.4581 - val_crf_marginal_accuracy: 0.9902\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4469 - crf_marginal_accuracy: 0.9952 - val_loss: 0.4561 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4417 - crf_marginal_accuracy: 0.9972 - val_loss: 0.4524 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4313 - crf_marginal_accuracy: 0.9973 - val_loss: 0.4468 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.4094 - crf_marginal_accuracy: 0.9974 - val_loss: 0.4360 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3700 - crf_marginal_accuracy: 0.9975 - val_loss: 0.4237 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3269 - crf_marginal_accuracy: 0.9977 - val_loss: 0.4207 - val_crf_marginal_accuracy: 0.9971\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.3042 - crf_marginal_accuracy: 0.9978 - val_loss: 0.4450 - val_crf_marginal_accuracy: 0.9946\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.2814 - crf_marginal_accuracy: 0.9979 - val_loss: 0.4295 - val_crf_marginal_accuracy: 0.9975\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.2496 - crf_marginal_accuracy: 0.9980 - val_loss: 0.4045 - val_crf_marginal_accuracy: 0.9973\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.2215 - crf_marginal_accuracy: 0.9981 - val_loss: 0.3974 - val_crf_marginal_accuracy: 0.9974\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1992 - crf_marginal_accuracy: 0.9982 - val_loss: 0.3925 - val_crf_marginal_accuracy: 0.9976\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1827 - crf_marginal_accuracy: 0.9983 - val_loss: 0.4025 - val_crf_marginal_accuracy: 0.9977\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1665 - crf_marginal_accuracy: 0.9983 - val_loss: 0.4481 - val_crf_marginal_accuracy: 0.9978\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1574 - crf_marginal_accuracy: 0.9985 - val_loss: 0.4286 - val_crf_marginal_accuracy: 0.9978\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1606 - crf_marginal_accuracy: 0.9985 - val_loss: 0.4608 - val_crf_marginal_accuracy: 0.9980\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1489 - crf_marginal_accuracy: 0.9986 - val_loss: 0.4568 - val_crf_marginal_accuracy: 0.9981\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1412 - crf_marginal_accuracy: 0.9987 - val_loss: 0.4901 - val_crf_marginal_accuracy: 0.9981\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1385 - crf_marginal_accuracy: 0.9987 - val_loss: 0.4663 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1327 - crf_marginal_accuracy: 0.9990 - val_loss: 0.4770 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1233 - crf_marginal_accuracy: 0.9993 - val_loss: 0.4901 - val_crf_marginal_accuracy: 0.9986\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1162 - crf_marginal_accuracy: 0.9993 - val_loss: 0.5041 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 26/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1090 - crf_marginal_accuracy: 0.9994 - val_loss: 0.4858 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 27/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.1015 - crf_marginal_accuracy: 0.9995 - val_loss: 0.5584 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 28/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.0952 - crf_marginal_accuracy: 0.9996 - val_loss: 0.5582 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 29/30\n",
            "857/857 [==============================] - 89s 103ms/step - loss: 0.0890 - crf_marginal_accuracy: 0.9997 - val_loss: 0.5513 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 30/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.0812 - crf_marginal_accuracy: 0.9997 - val_loss: 0.5762 - val_crf_marginal_accuracy: 0.9990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCujGbXWamC",
        "outputId": "69acc499-ba4a-485f-ea7d-edefb6001d33"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9130    0.8512    0.8810      1109\n",
            "I-GoodsString     0.8340    0.8335    0.8338      1718\n",
            "\n",
            "    micro avg     0.8637    0.8405    0.8519      2827\n",
            "    macro avg     0.8735    0.8424    0.8574      2827\n",
            " weighted avg     0.8650    0.8405    0.8523      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1mf60mpD9t"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jRCZwwNWamC"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipy3tg6aWamD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac9552f-ca75-4eed-a1ee-6eb9e024c9d2"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.6836 - crf_marginal_accuracy: 0.0029 - val_loss: 0.6254 - val_crf_marginal_accuracy: 0.0018\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.5899 - crf_marginal_accuracy: 0.0014 - val_loss: 0.5625 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.5366 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5185 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4988 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4886 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 85s 100ms/step - loss: 0.4741 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4707 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4603 - crf_marginal_accuracy: 0.0016 - val_loss: 0.4619 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4540 - crf_marginal_accuracy: 0.0020 - val_loss: 0.4585 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4518 - crf_marginal_accuracy: 0.0024 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.0031\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4513 - crf_marginal_accuracy: 0.5517 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.4513 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuStVCRzWamD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4dfe637-403c-40ac-f9e2-0d2b35f039c4"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vELTeX7To1uV"
      },
      "source": [
        "## W2V(not fixed, window=5, max_vocab_size=15000) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBV_xu9jJ7O"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=5, max_vocab_size=15000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWAPWdOxjJ7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8d6511-e394-4bcb-9586-cab31965fdcb"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "\n",
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 3004, 300)         1419600   \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_8 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 1,741,030\n",
            "Trainable params: 1,741,030\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmtqjRfCjJ7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c38777-0c43-48f6-a95f-504218ebffde"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 135s 158ms/step - loss: 0.5672 - crf_marginal_accuracy: 0.0013 - val_loss: 0.5213 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.4992 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4927 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 126s 147ms/step - loss: 0.4757 - crf_marginal_accuracy: 0.0013 - val_loss: 0.4734 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.4607 - crf_marginal_accuracy: 0.0017 - val_loss: 0.4626 - val_crf_marginal_accuracy: 0.0024\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 125s 146ms/step - loss: 0.4538 - crf_marginal_accuracy: 0.0026 - val_loss: 0.4587 - val_crf_marginal_accuracy: 0.0028\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 122s 142ms/step - loss: 0.4520 - crf_marginal_accuracy: 0.0027 - val_loss: 0.4579 - val_crf_marginal_accuracy: 0.0028\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 122s 143ms/step - loss: 0.4520 - crf_marginal_accuracy: 0.1060 - val_loss: 0.4579 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 121s 142ms/step - loss: 0.4520 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4580 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 122s 142ms/step - loss: 0.4519 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4580 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 121s 141ms/step - loss: 0.4517 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 122s 142ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.4485 - val_loss: 0.4575 - val_crf_marginal_accuracy: 0.0028\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 118s 137ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.0027 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBqJIeRajJ7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fbd83d-402d-4936-c9df-d474a5c85931"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewN4XiuiosKq"
      },
      "source": [
        "## W2V(fixed, window=5, max_vocab_size=15000) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaebcYB-jJ7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb326308-6091-474c-d2a3-fb22fae0807d"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 3004, 300)         1419600   \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_10 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 1,741,030\n",
            "Trainable params: 321,430\n",
            "Non-trainable params: 1,419,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk48dUX-jJ7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aadcf954-a5b5-43fe-88da-661f9ee721e7"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('best_model_fixed_embeds.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.5790 - crf_marginal_accuracy: 0.0019 - val_loss: 0.4979 - val_crf_marginal_accuracy: 0.0080\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4748 - crf_marginal_accuracy: 0.5495 - val_loss: 0.4782 - val_crf_marginal_accuracy: 0.9737\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4612 - crf_marginal_accuracy: 0.9812 - val_loss: 0.4644 - val_crf_marginal_accuracy: 0.9859\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4527 - crf_marginal_accuracy: 0.8922 - val_loss: 0.4603 - val_crf_marginal_accuracy: 0.9858\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4495 - crf_marginal_accuracy: 0.9893 - val_loss: 0.4592 - val_crf_marginal_accuracy: 0.9932\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4472 - crf_marginal_accuracy: 0.9948 - val_loss: 0.4578 - val_crf_marginal_accuracy: 0.9950\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4456 - crf_marginal_accuracy: 0.9955 - val_loss: 0.4562 - val_crf_marginal_accuracy: 0.9952\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4436 - crf_marginal_accuracy: 0.9953 - val_loss: 0.4547 - val_crf_marginal_accuracy: 0.9947\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.4408 - crf_marginal_accuracy: 0.9946 - val_loss: 0.4544 - val_crf_marginal_accuracy: 0.9930\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4391 - crf_marginal_accuracy: 0.9931 - val_loss: 0.4545 - val_crf_marginal_accuracy: 0.9861\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.4354 - crf_marginal_accuracy: 0.9894 - val_loss: 0.4495 - val_crf_marginal_accuracy: 0.9885\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.4317 - crf_marginal_accuracy: 0.9865 - val_loss: 0.4482 - val_crf_marginal_accuracy: 0.9754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRxCwd2njJ7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6616bcb-32a3-42e2-dac7-1bcf43825213"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.2814    0.2687    0.2749      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.2166    0.1054    0.1418      2827\n",
            "    macro avg     0.1407    0.1344    0.1375      2827\n",
            " weighted avg     0.1104    0.1054    0.1078      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4WKYxHZuT9p"
      },
      "source": [
        "## W2V(not fixed, window=25) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgm2UrFtuT9p"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=300, window=25, min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si5Zc-UjuEN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c65c058-09c2-44fe-f3ba-047cc36244dc"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.005), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf_11 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 2,866,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EN4RSuMuEN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e863fc91-ce79-4ff0-89b7-ee26b46a70bd"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 97s 113ms/step - loss: 0.7928 - crf_marginal_accuracy: 0.0043 - val_loss: 0.7336 - val_crf_marginal_accuracy: 0.0073\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.6980 - crf_marginal_accuracy: 0.0069 - val_loss: 0.6589 - val_crf_marginal_accuracy: 0.0120\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.6320 - crf_marginal_accuracy: 0.0085 - val_loss: 0.6064 - val_crf_marginal_accuracy: 0.0101\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5851 - crf_marginal_accuracy: 0.0082 - val_loss: 0.5657 - val_crf_marginal_accuracy: 0.0108\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5470 - crf_marginal_accuracy: 0.0079 - val_loss: 0.5319 - val_crf_marginal_accuracy: 0.0100\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.5160 - crf_marginal_accuracy: 0.0078 - val_loss: 0.5051 - val_crf_marginal_accuracy: 0.0098\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 90s 105ms/step - loss: 0.4919 - crf_marginal_accuracy: 0.0078 - val_loss: 0.4856 - val_crf_marginal_accuracy: 0.0102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGjQQcIDuEN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862c2766-b5bf-4755-a975-f539e5cbad1f"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0379    1.0000    0.0730      1718\n",
            "\n",
            "    micro avg     0.0379    0.6077    0.0713      2827\n",
            "    macro avg     0.0189    0.5000    0.0365      2827\n",
            " weighted avg     0.0230    0.6077    0.0444      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAsUlkf-ap4n"
      },
      "source": [
        "## GLOVE (not fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNrzxYz3ar3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61a3dbb-f3ac-47dc-8ef5-df5e1dcc182b"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=5)\n",
        "\n",
        "glove = Glove(no_components=50, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAHDPc4gr72e"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtUIADA6a6h-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59073a71-68fd-4c4b-9041-c2017ede4d4a"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 3004, 50)          618050    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 658,780\n",
            "Trainable params: 658,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTxAndSBa6iK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba5b880-ec78-4cf9-a90e-c718f320e8b0"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='not_pretrained_glove_best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('not_pretrained_glove_best_model.h5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.6272 - crf_marginal_accuracy: 0.9930 - val_loss: 0.4888 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4588 - crf_marginal_accuracy: 0.9936 - val_loss: 0.4634 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4333 - crf_marginal_accuracy: 0.9970 - val_loss: 0.4511 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.3979 - crf_marginal_accuracy: 0.9973 - val_loss: 0.4313 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.3423 - crf_marginal_accuracy: 0.9977 - val_loss: 0.4080 - val_crf_marginal_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.2862 - crf_marginal_accuracy: 0.9982 - val_loss: 0.3913 - val_crf_marginal_accuracy: 0.9978\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.2469 - crf_marginal_accuracy: 0.9985 - val_loss: 0.3634 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1953 - crf_marginal_accuracy: 0.9990 - val_loss: 0.3370 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1507 - crf_marginal_accuracy: 0.9994 - val_loss: 0.3280 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1160 - crf_marginal_accuracy: 0.9997 - val_loss: 0.3239 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0869 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3280 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0618 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3355 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.0449 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3476 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0317 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3802 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0257 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3844 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0222 - crf_marginal_accuracy: 1.0000 - val_loss: 0.3878 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0184 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4099 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0150 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4020 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0129 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4173 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0092 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4032 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0081 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4399 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0075 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4624 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0070 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4771 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0068 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4615 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0068 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4605 - val_crf_marginal_accuracy: 0.9993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fQo3JKAa6iL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694b0e81-a541-4e8d-ca86-ab3df77b2344"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9172    0.8693    0.8926      1109\n",
            "I-GoodsString     0.8951    0.8737    0.8842      1718\n",
            "\n",
            "    micro avg     0.9036    0.8719    0.8875      2827\n",
            "    macro avg     0.9061    0.8715    0.8884      2827\n",
            " weighted avg     0.9037    0.8719    0.8875      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0LPCsrMoJYm"
      },
      "source": [
        "## GLOVE (fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7KzsnJxvbDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30f619f-9117-4c62-b932-a40566ed98e3"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 3004, 50)          618050    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_3 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 658,780\n",
            "Trainable params: 40,730\n",
            "Non-trainable params: 618,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE_R3XoqvbDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3d95c2-3bce-4b03-b954-74dea92e6fdc"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='not_pretrained_glove_best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('not_pretrained_glove_best_model_fixed_embeds.h5')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.4954 - crf_marginal_accuracy: 0.9474 - val_loss: 0.4703 - val_crf_marginal_accuracy: 0.9340\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4561 - crf_marginal_accuracy: 0.9475 - val_loss: 0.4598 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4555 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4620 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4546 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4588 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4520 - crf_marginal_accuracy: 0.9838 - val_loss: 0.4594 - val_crf_marginal_accuracy: 0.9255\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4524 - crf_marginal_accuracy: 0.9412 - val_loss: 0.4588 - val_crf_marginal_accuracy: 0.9247\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 82s 95ms/step - loss: 0.4522 - crf_marginal_accuracy: 0.9416 - val_loss: 0.4578 - val_crf_marginal_accuracy: 0.9844\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4516 - crf_marginal_accuracy: 0.9950 - val_loss: 0.4577 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4516 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9955\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.9609 - val_loss: 0.4577 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4515 - crf_marginal_accuracy: 0.9733 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 82s 96ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4577 - val_crf_marginal_accuracy: 0.9241\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 83s 96ms/step - loss: 0.4514 - crf_marginal_accuracy: 0.9402 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQU0DDgvbDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9487027-2365-4b5f-d09a-acd392ec2bdc"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0000    0.0000    0.0000      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.0000    0.0000    0.0000      2827\n",
            "    macro avg     0.0000    0.0000    0.0000      2827\n",
            " weighted avg     0.0000    0.0000    0.0000      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWSpAUjhXbVN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}