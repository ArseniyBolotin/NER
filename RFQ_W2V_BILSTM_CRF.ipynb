{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RFQ_W2V_BILSTM_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O18QSWjJcwxa",
        "outputId": "84d4dd85-7e76-4c75-9b09-6ed030be2b22"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raJ-rDdCJt_",
        "outputId": "4cd6c6af-47f4-40e6-a849-24d594df1e6e"
      },
      "source": [
        "!pip install 'h5py<3.0.0'\n",
        "!pip install sklearn_crfsuite\n",
        "# !pip install tensorflow==1.15.2 keras==2.3.1\n",
        "!pip3 install glove-python-binary\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git --upgrade\n",
        "!pip install catboost"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py<3.0.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py<3.0.0) (1.19.5)\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-oo0bniej\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-oo0bniej\n",
            "Requirement already satisfied, skipping upgrade: keras in /tensorflow-1.15.2/python3.7 (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.7 (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp37-none-any.whl size=101065 sha256=2631ed9af3a15cf80b48bc02dd5cbae95dc69e9d535d17bc3a145ebec3dce56c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k1zbx6oe/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "  Found existing installation: keras-contrib 2.0.8\n",
            "    Uninstalling keras-contrib-2.0.8:\n",
            "      Successfully uninstalled keras-contrib-2.0.8\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx7wVx0OiYyv",
        "outputId": "021da48a-a9d3-4c39-a9d8-bd844b816e69"
      },
      "source": [
        "!gdown --id 1L6dd0FnYqgn-eoQ-gFnBiNji7R1ul9n_\n",
        "!gdown --id 1-5mE9XjocmyCKGlkpW1YGuCnNsGwQioD\n",
        "!gdown --id 1d4er4I7x4VIwy7BsWFpsPuC2z6aZ3P6s"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L6dd0FnYqgn-eoQ-gFnBiNji7R1ul9n_\n",
            "To: /content/NER_RFQ_agg.csv\n",
            "4.39MB [00:00, 142MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5mE9XjocmyCKGlkpW1YGuCnNsGwQioD\n",
            "To: /content/NER_RFQ_agg_train.csv\n",
            "3.48MB [00:00, 109MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d4er4I7x4VIwy7BsWFpsPuC2z6aZ3P6s\n",
            "To: /content/NER_RFQ_agg_test.csv\n",
            "100% 909k/909k [00:00<00:00, 60.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEfFyYZVph-B",
        "outputId": "71e26ec3-117a-49af-ff96-3746e42c9484"
      },
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import *\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy, crf_marginal_accuracy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "\n",
        "import gensim.downloader as api\n",
        "import matplotlib.pyplot as plt\n",
        "from catboost import CatBoostClassifier\n",
        "from gensim.models import Word2Vec\n",
        "from glove import Corpus, Glove\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTYiqiimi1vV"
      },
      "source": [
        "df = pd.read_csv('NER_RFQ_agg.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "train = pd.read_csv('NER_RFQ_agg_train.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "test = pd.read_csv('NER_RFQ_agg_test.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
        "\n",
        "all_dfs = [df, train, test]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXz_dGApGKoB"
      },
      "source": [
        "def find_token(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ', '']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in w2v.wv.vocab.keys():\n",
        "                res.append(w2v.wv.vocab[w + suffix].index)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "all_tags = set()\n",
        "for _, row in df.iterrows():\n",
        "    for tag in row.ner_tags:\n",
        "        all_tags.add(tag)\n",
        "all_tags = sorted(list(all_tags))\n",
        "tag_to_idx = {t: i for i, t in enumerate(all_tags)}\n",
        "label_list = {i: t for i, t in enumerate(all_tags)}\n",
        "labels = list(tag_to_idx.keys())\n",
        "labels.remove('O')\n",
        "labels = sorted(labels, key=lambda name: (name[1:], name[0]))\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAl784dWnJkR"
      },
      "source": [
        "pretrained_w2v = api.load(\"word2vec-ruscorpora-300\")\n",
        "pretrained_w2v.save_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthif1zkvsok"
      },
      "source": [
        "def add_suffix(x):\n",
        "    SUFFIXES = ['_DET', '_NOUN', '_VERB', '_ADJ']\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        has_found = False\n",
        "        for suffix in SUFFIXES:\n",
        "            if w + suffix in pretrained_w2v.vocab.keys():\n",
        "                res.append(w + suffix)\n",
        "                has_found = True\n",
        "                break\n",
        "        if not has_found:\n",
        "            res.append(w)\n",
        "    return res\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['tokens_with_suffix'] = d.apply(add_suffix, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1rp-IeYsnJf"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens_with_suffix'], size=300, window=5, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UyqqSfYYmY-p"
      },
      "source": [
        "w2v.intersect_word2vec_format('tmp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXIPpJJeAg-a"
      },
      "source": [
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "J7BswpbHlVW2",
        "outputId": "ec36b1c9-f188-45de-b0ef-c7b2239ea795"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tokens</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>tokens_with_suffix</th>\n",
              "      <th>encoded_ner_tags</th>\n",
              "      <th>int_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119287R.msg</td>\n",
              "      <td>[name, 119287r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 119287r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 206, 744, 293, 22, 190, 0, 30, 36, 237...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>119735R.msg</td>\n",
              "      <td>[name, 119735r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 119735r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 206, 744, 293, 22, 190, 6707, 624, 106...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>120421R.msg</td>\n",
              "      <td>[name, 120421r.msg, d.klebcha@s7.ru, &lt;d.klebch...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-GoodsString, I-Good...</td>\n",
              "      <td>[name_NOUN, 120421r.msg, d.klebcha@s7.ru, &lt;d.k...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 5524, 5525, 5526, 2961, 22, 57, 874, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120660R.msg</td>\n",
              "      <td>[name, 120660r.msg, yuliya, a., kondratova, &lt;y...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 120660r.msg, yuliya, a., kondratov...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>120660R.msg</td>\n",
              "      <td>[name, 120660r.msg, yuliya, a., kondratova, &lt;y...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 120660r.msg, yuliya, a., kondratov...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>123527R.msg</td>\n",
              "      <td>[name, 123527r.msg, =?utf-8?b?0kprincw0lrqvtcy...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-GoodsString, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123527r.msg, =?utf-8?b?0kprincw0lr...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 1249, 1250, 1251, 12, 22, 679, 0, 1026...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>123088R.msg</td>\n",
              "      <td>[name, 123088r.msg, lakshmi, suresh, &lt;lakshmi@...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123088r.msg, lakshmi, suresh, &lt;lak...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 6241, 4264, 4265, 6242, 2961, 22, 147, 62...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1189</th>\n",
              "      <td>123508R.msg</td>\n",
              "      <td>[name, 123508r.msg, &lt;aogdesk@nordstar.ru&gt;, &lt;mv...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 123508r.msg, &lt;aogdesk@nordstar.ru&gt;...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 7935, 206, 744, 293, 22, 190, 7936, 30, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1190</th>\n",
              "      <td>124894R.msg</td>\n",
              "      <td>[name, 124894r.msg, &lt;anton.peshko@utair.ru&gt;, a...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 124894r.msg, &lt;anton.peshko@utair.r...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 304, 47, 305, 304, 22, 115, 5523, 278,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191</th>\n",
              "      <td>124484R.msg</td>\n",
              "      <td>[name, 124484r.msg, &lt;gennadiy.moskatov@utair.r...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[name_NOUN, 124484r.msg, &lt;gennadiy.moskatov@ut...</td>\n",
              "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
              "      <td>[19, 0, 485, 220, 486, 485, 22, 115, 6706, 472...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1192 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                         int_tokens\n",
              "0     119287R.msg  ...  [19, 0, 206, 744, 293, 22, 190, 0, 30, 36, 237...\n",
              "1     119735R.msg  ...  [19, 0, 206, 744, 293, 22, 190, 6707, 624, 106...\n",
              "2     120421R.msg  ...  [19, 0, 5524, 5525, 5526, 2961, 22, 57, 874, 2...\n",
              "3     120660R.msg  ...  [19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...\n",
              "4     120660R.msg  ...  [19, 5530, 846, 833, 518, 847, 12, 22, 57, 255...\n",
              "...           ...  ...                                                ...\n",
              "1187  123527R.msg  ...  [19, 0, 1249, 1250, 1251, 12, 22, 679, 0, 1026...\n",
              "1188  123088R.msg  ...  [19, 6241, 4264, 4265, 6242, 2961, 22, 147, 62...\n",
              "1189  123508R.msg  ...  [19, 7935, 206, 744, 293, 22, 190, 7936, 30, 3...\n",
              "1190  124894R.msg  ...  [19, 0, 304, 47, 305, 304, 22, 115, 5523, 278,...\n",
              "1191  124484R.msg  ...  [19, 0, 485, 220, 486, 485, 22, 115, 6706, 472...\n",
              "\n",
              "[1192 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QUuM6AhjxyK"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBokW5kspLO"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=1.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {1.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqAcUZxSMT2c"
      },
      "source": [
        "## PRETRAINED W2V(not fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1S7oW2BWoX",
        "outputId": "0295b4ca-6e2d-40ad-cbf3-6d53ac90407a"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 3004, 200)         320800    \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 3004, 3)           603       \n",
            "_________________________________________________________________\n",
            "crf (CRF)                    (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,866,330\n",
            "Trainable params: 2,866,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LAVZ0buRG02d",
        "outputId": "4ef4f2a9-c749-4641-ea92-e21c2fb4dd78"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='pretrained_best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('pretrained_best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 66s 77ms/step - loss: 0.4820 - crf_marginal_accuracy: 0.7108 - val_loss: 0.4655 - val_crf_marginal_accuracy: 0.9684\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.4570 - crf_marginal_accuracy: 0.9915 - val_loss: 0.4606 - val_crf_marginal_accuracy: 0.9699\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.4507 - crf_marginal_accuracy: 0.9738 - val_loss: 0.4561 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.4438 - crf_marginal_accuracy: 0.9965 - val_loss: 0.4492 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 64s 75ms/step - loss: 0.4209 - crf_marginal_accuracy: 0.9947 - val_loss: 0.4205 - val_crf_marginal_accuracy: 0.9878\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.3621 - crf_marginal_accuracy: 0.9852 - val_loss: 0.3917 - val_crf_marginal_accuracy: 0.9868\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.3044 - crf_marginal_accuracy: 0.9941 - val_loss: 0.3533 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.2561 - crf_marginal_accuracy: 0.9979 - val_loss: 0.3357 - val_crf_marginal_accuracy: 0.9979\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.2148 - crf_marginal_accuracy: 0.9988 - val_loss: 0.3207 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.1916 - crf_marginal_accuracy: 0.9990 - val_loss: 0.3418 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 64s 75ms/step - loss: 0.1721 - crf_marginal_accuracy: 0.9992 - val_loss: 0.3326 - val_crf_marginal_accuracy: 0.9986\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 64s 75ms/step - loss: 0.1515 - crf_marginal_accuracy: 0.9994 - val_loss: 0.3328 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.1342 - crf_marginal_accuracy: 0.9995 - val_loss: 0.3383 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.1187 - crf_marginal_accuracy: 0.9996 - val_loss: 0.3535 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.1057 - crf_marginal_accuracy: 0.9997 - val_loss: 0.3790 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.0951 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3902 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0841 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4131 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.0779 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4304 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0730 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4146 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0619 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4539 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.0520 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4451 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0439 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4361 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0412 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4613 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 64s 75ms/step - loss: 0.0377 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4530 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 64s 75ms/step - loss: 0.0347 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4755 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 26/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0307 - crf_marginal_accuracy: 0.9999 - val_loss: 0.4693 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 27/30\n",
            "857/857 [==============================] - 63s 74ms/step - loss: 0.0275 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4869 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 28/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0251 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5048 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 29/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0232 - crf_marginal_accuracy: 1.0000 - val_loss: 0.5257 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 30/30\n",
            "857/857 [==============================] - 64s 74ms/step - loss: 0.0230 - crf_marginal_accuracy: 1.0000 - val_loss: 0.5384 - val_crf_marginal_accuracy: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d9298111173b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrained_best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1230\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \"\"\"\n\u001b[1;32m   1182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'keras_version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZNVGThAXHeL",
        "outputId": "bf23d7b0-d9c3-460b-8296-8f6f944abb1c"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9294    0.8548    0.8906      1109\n",
            "I-GoodsString     0.9505    0.8166    0.8785      1718\n",
            "\n",
            "    micro avg     0.9419    0.8316    0.8833      2827\n",
            "    macro avg     0.9400    0.8357    0.8845      2827\n",
            " weighted avg     0.9423    0.8316    0.8832      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JNx5ntzrHuK"
      },
      "source": [
        "## PRETRAINED W2V(fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nV6QMPc3cyy",
        "outputId": "8e37d1cd-53f5-4790-9275-fbef90841bc3"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(alpha=4), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 3004, 100)         140400    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,685,630\n",
            "Trainable params: 140,730\n",
            "Non-trainable params: 2,544,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19U1yO8c3czD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be29db51-7e2e-476a-82bf-a97c1a52133f"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='pretrained_best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('pretrained_best_model_fixed_embeds.h5')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 61s 71ms/step - loss: 2.8965 - crf_marginal_accuracy: 0.0021 - val_loss: 2.4423 - val_crf_marginal_accuracy: 0.0023\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 2.0859 - crf_marginal_accuracy: 0.2775 - val_loss: 1.9679 - val_crf_marginal_accuracy: 0.9443\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8852 - crf_marginal_accuracy: 0.9659 - val_loss: 1.8872 - val_crf_marginal_accuracy: 0.9786\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8381 - crf_marginal_accuracy: 0.9926 - val_loss: 1.8552 - val_crf_marginal_accuracy: 0.9948\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8215 - crf_marginal_accuracy: 0.9944 - val_loss: 1.8512 - val_crf_marginal_accuracy: 0.9931\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8171 - crf_marginal_accuracy: 0.9952 - val_loss: 1.8434 - val_crf_marginal_accuracy: 0.9957\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8125 - crf_marginal_accuracy: 0.9963 - val_loss: 1.8413 - val_crf_marginal_accuracy: 0.9957\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8099 - crf_marginal_accuracy: 0.9960 - val_loss: 1.8394 - val_crf_marginal_accuracy: 0.9948\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8078 - crf_marginal_accuracy: 0.9954 - val_loss: 1.8389 - val_crf_marginal_accuracy: 0.9954\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8067 - crf_marginal_accuracy: 0.9964 - val_loss: 1.8385 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8060 - crf_marginal_accuracy: 0.9963 - val_loss: 1.8368 - val_crf_marginal_accuracy: 0.9953\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8049 - crf_marginal_accuracy: 0.9960 - val_loss: 1.8365 - val_crf_marginal_accuracy: 0.9958\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8047 - crf_marginal_accuracy: 0.9964 - val_loss: 1.8383 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8045 - crf_marginal_accuracy: 0.9963 - val_loss: 1.8365 - val_crf_marginal_accuracy: 0.9957\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 60s 70ms/step - loss: 1.8035 - crf_marginal_accuracy: 0.9962 - val_loss: 1.8355 - val_crf_marginal_accuracy: 0.9958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU37zLsF3czD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995ecb44-451c-4e1f-bff1-607f8efbd101"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.4027    0.5861    0.4774      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.3930    0.2299    0.2901      2827\n",
            "    macro avg     0.2014    0.2931    0.2387      2827\n",
            " weighted avg     0.1580    0.2299    0.1873      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0M6U9bFpeSI"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRins3GMDd-"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYv7a7bMMEI",
        "outputId": "e606edad-488e-42a9-f3c3-240acee7719d"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 3004, 300)         2544900   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 3004, 100)         140400    \n",
            "_________________________________________________________________\n",
            "time_distributed_11 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_11 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 2,685,630\n",
            "Trainable params: 2,685,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9AHayBOMMEK",
        "outputId": "5ca96473-9a50-4111-91c6-685c649207b1"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='not_pretrained_best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('not_pretrained_best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 98s 114ms/step - loss: 0.4957 - crf_marginal_accuracy: 0.6872 - val_loss: 0.4646 - val_crf_marginal_accuracy: 0.9956\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.4535 - crf_marginal_accuracy: 0.4771 - val_loss: 0.4569 - val_crf_marginal_accuracy: 0.0709\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.4468 - crf_marginal_accuracy: 0.8567 - val_loss: 0.4542 - val_crf_marginal_accuracy: 0.9965\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.4386 - crf_marginal_accuracy: 0.9969 - val_loss: 0.4468 - val_crf_marginal_accuracy: 0.9960\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.4189 - crf_marginal_accuracy: 0.9970 - val_loss: 0.4338 - val_crf_marginal_accuracy: 0.9970\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.3850 - crf_marginal_accuracy: 0.9977 - val_loss: 0.4165 - val_crf_marginal_accuracy: 0.9975\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.3317 - crf_marginal_accuracy: 0.9983 - val_loss: 0.4171 - val_crf_marginal_accuracy: 0.9977\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.2653 - crf_marginal_accuracy: 0.9988 - val_loss: 0.4012 - val_crf_marginal_accuracy: 0.9982\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.2121 - crf_marginal_accuracy: 0.9992 - val_loss: 0.3723 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.1718 - crf_marginal_accuracy: 0.9995 - val_loss: 0.3861 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.1476 - crf_marginal_accuracy: 0.9995 - val_loss: 0.4065 - val_crf_marginal_accuracy: 0.9989\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.1200 - crf_marginal_accuracy: 0.9996 - val_loss: 0.3672 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.0898 - crf_marginal_accuracy: 0.9997 - val_loss: 0.3499 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0734 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3959 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0604 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3799 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0551 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3644 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0511 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3988 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0427 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4072 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0372 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4425 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 92s 107ms/step - loss: 0.0344 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4732 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0320 - crf_marginal_accuracy: 0.9998 - val_loss: 0.4689 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 91s 107ms/step - loss: 0.0289 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5235 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0281 - crf_marginal_accuracy: 0.9998 - val_loss: 0.5479 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0261 - crf_marginal_accuracy: 0.9999 - val_loss: 0.5762 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0240 - crf_marginal_accuracy: 0.9999 - val_loss: 0.6077 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 26/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0217 - crf_marginal_accuracy: 0.9999 - val_loss: 0.6101 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 27/30\n",
            "857/857 [==============================] - 91s 106ms/step - loss: 0.0225 - crf_marginal_accuracy: 0.9999 - val_loss: 0.6157 - val_crf_marginal_accuracy: 0.9992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cofffkTqMMEK",
        "outputId": "ab28ce8a-e2d4-4ab7-e8c4-f256d7990c29"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9026    0.8602    0.8809      1109\n",
            "I-GoodsString     0.8842    0.8487    0.8661      1718\n",
            "\n",
            "    micro avg     0.8914    0.8532    0.8719      2827\n",
            "    macro avg     0.8934    0.8544    0.8735      2827\n",
            " weighted avg     0.8914    0.8532    0.8719      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9pIp5Zpjqo"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=2) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKFIa_0IMMEL",
        "outputId": "99c15854-255e-414f-c473-9aaccc6e495d"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.01), loss=focal_loss(alpha=4), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 3004, 50)          424150    \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_7 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 464,880\n",
            "Trainable params: 40,730\n",
            "Non-trainable params: 424,150\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJSFEq-vMMEL",
        "outputId": "b60b9365-de14-4362-a8ab-90a3693356f0"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='not_pretrained_best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=1024,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('not_pretrained_best_model_fixed_embeds.h5')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 14s 17ms/step - loss: 3.7022 - crf_marginal_accuracy: 0.0013 - val_loss: 4.7602 - val_crf_marginal_accuracy: 0.0021\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 4.6038 - crf_marginal_accuracy: 0.0018 - val_loss: 3.2985 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 3.2380 - crf_marginal_accuracy: 0.0013 - val_loss: 3.1270 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 3.0572 - crf_marginal_accuracy: 0.0013 - val_loss: 2.7264 - val_crf_marginal_accuracy: 0.0014\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 2.6721 - crf_marginal_accuracy: 0.0013 - val_loss: 2.3031 - val_crf_marginal_accuracy: 0.0015\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 2.2782 - crf_marginal_accuracy: 0.0014 - val_loss: 2.1672 - val_crf_marginal_accuracy: 0.0023\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 2.1538 - crf_marginal_accuracy: 0.0021 - val_loss: 2.1199 - val_crf_marginal_accuracy: 0.0024\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 2.1011 - crf_marginal_accuracy: 0.0021 - val_loss: 2.0476 - val_crf_marginal_accuracy: 0.0027\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 2.0199 - crf_marginal_accuracy: 0.0024 - val_loss: 1.9758 - val_crf_marginal_accuracy: 0.0038\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.9417 - crf_marginal_accuracy: 0.0034 - val_loss: 1.9278 - val_crf_marginal_accuracy: 0.0348\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8893 - crf_marginal_accuracy: 0.0311 - val_loss: 1.9081 - val_crf_marginal_accuracy: 0.0679\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8668 - crf_marginal_accuracy: 0.0544 - val_loss: 1.9061 - val_crf_marginal_accuracy: 0.0682\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8634 - crf_marginal_accuracy: 0.0550 - val_loss: 1.9092 - val_crf_marginal_accuracy: 0.9597\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8662 - crf_marginal_accuracy: 0.9633 - val_loss: 1.9157 - val_crf_marginal_accuracy: 0.9942\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8723 - crf_marginal_accuracy: 0.9952 - val_loss: 1.9227 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8793 - crf_marginal_accuracy: 0.9966 - val_loss: 1.9235 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8809 - crf_marginal_accuracy: 0.9966 - val_loss: 1.9179 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8760 - crf_marginal_accuracy: 0.9966 - val_loss: 1.9075 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8673 - crf_marginal_accuracy: 0.9966 - val_loss: 1.8954 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 1.8572 - crf_marginal_accuracy: 0.9966 - val_loss: 1.8817 - val_crf_marginal_accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-v-3tFMMEL",
        "outputId": "628c28d1-7a91-4b75-aedc-69ead284309b"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.4673    0.1289    0.2021      1109\n",
            "I-GoodsString     0.0000    0.0000    0.0000      1718\n",
            "\n",
            "    micro avg     0.4673    0.0506    0.0913      2827\n",
            "    macro avg     0.2337    0.0645    0.1011      2827\n",
            " weighted avg     0.1833    0.0506    0.0793      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKJI4oy3hzMT"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=5, min_count=2) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id2BNTd0n0-0",
        "outputId": "e9876a27-8be2-4a37-f8ab-c0a4056ce5fb"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZbGJKwZwPNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9a8f4c-1b59-407c-842e-2ba3406b8a1e"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFFhboVQs9BR"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.3], iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OamBx6BudKo",
        "outputId": "5ce6ad4e-fa85-4c8a-b93e-d69ed07b3711"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.8753    0.8990    0.8870      1109\n",
            "I-GoodsString     0.8444    0.8749    0.8593      1718\n",
            "\n",
            "    micro avg     0.8565    0.8843    0.8702      2827\n",
            "    macro avg     0.8599    0.8869    0.8732      2827\n",
            " weighted avg     0.8565    0.8843    0.8702      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Rxo5d1o93d"
      },
      "source": [
        "## W2V(not fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGPObsQWal6"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=5, min_count=1)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqDnQ8VNWal-",
        "outputId": "bdec6c0a-cb24-48e2-c807-405fed560a3b"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 3004, 50)          618050    \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_10 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_10 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 658,780\n",
            "Trainable params: 658,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WqCw-lOWamB",
        "outputId": "8364e9d4-d2dd-405a-fb07-ba33457bec4e"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='window=5,min_count=1,best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=1024,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('window=5,min_count=1,best_model.h5')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 15s 18ms/step - loss: 0.9747 - crf_marginal_accuracy: 0.9966 - val_loss: 0.9106 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.8899 - crf_marginal_accuracy: 0.9966 - val_loss: 0.8760 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.8530 - crf_marginal_accuracy: 0.9966 - val_loss: 0.8516 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.8271 - crf_marginal_accuracy: 0.9966 - val_loss: 0.8217 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.7966 - crf_marginal_accuracy: 0.9966 - val_loss: 0.7970 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.7708 - crf_marginal_accuracy: 0.9966 - val_loss: 0.7727 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.7476 - crf_marginal_accuracy: 0.9966 - val_loss: 0.7494 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.7260 - crf_marginal_accuracy: 0.9965 - val_loss: 0.7281 - val_crf_marginal_accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhCujGbXWamC",
        "outputId": "276d75e8-d08a-4235-aec7-31f7fa44fb76"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.5954    0.6276    0.6111      1109\n",
            "I-GoodsString     0.7830    0.1932    0.3100      1718\n",
            "\n",
            "    micro avg     0.6453    0.3636    0.4652      2827\n",
            "    macro avg     0.6892    0.4104    0.4605      2827\n",
            " weighted avg     0.7094    0.3636    0.4281      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1mf60mpD9t"
      },
      "source": [
        "## W2V(fixed, window=5, min_count=1) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jRCZwwNWamC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac31d58-22f2-4a5b-a5f4-a745afea8c6c"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.01), loss=focal_loss(gamma=5), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 3004, 50)          618050    \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_13 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 658,780\n",
            "Trainable params: 40,730\n",
            "Non-trainable params: 618,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy3tg6aWamD",
        "outputId": "49edc5e8-757d-4e2d-bb4f-f681c577725f"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=10),\n",
        "         ModelCheckpoint(filepath='window=5,min_count=1,best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=1024,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('window=5,min_count=1,best_model_fixed_embeds.h5')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2429 - crf_marginal_accuracy: 0.9960 - val_loss: 0.1958 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1882 - crf_marginal_accuracy: 0.9968 - val_loss: 0.1617 - val_crf_marginal_accuracy: 0.9968\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1545 - crf_marginal_accuracy: 0.9971 - val_loss: 0.1464 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1389 - crf_marginal_accuracy: 0.9971 - val_loss: 0.1444 - val_crf_marginal_accuracy: 0.9958\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1364 - crf_marginal_accuracy: 0.9963 - val_loss: 0.1468 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1385 - crf_marginal_accuracy: 0.9955 - val_loss: 0.1477 - val_crf_marginal_accuracy: 0.9949\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1396 - crf_marginal_accuracy: 0.9952 - val_loss: 0.1465 - val_crf_marginal_accuracy: 0.9951\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1388 - crf_marginal_accuracy: 0.9954 - val_loss: 0.1440 - val_crf_marginal_accuracy: 0.9958\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1368 - crf_marginal_accuracy: 0.9960 - val_loss: 0.1421 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1352 - crf_marginal_accuracy: 0.9968 - val_loss: 0.1410 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1345 - crf_marginal_accuracy: 0.9969 - val_loss: 0.1400 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.1337 - crf_marginal_accuracy: 0.9969 - val_loss: 0.1385 - val_crf_marginal_accuracy: 0.9964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuStVCRzWamD",
        "outputId": "352afce3-4926-4a28-8997-54b19b8a4a53"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.7254    0.1262    0.2151      1109\n",
            "I-GoodsString     0.5678    0.3731    0.4503      1718\n",
            "\n",
            "    micro avg     0.5908    0.2763    0.3765      2827\n",
            "    macro avg     0.6466    0.2497    0.3327      2827\n",
            " weighted avg     0.6296    0.2763    0.3580      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL_5lS1paJ1a"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=5, min_count=1) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFV0gNT-aJ1a",
        "outputId": "8cfdd8a6-8111-44f3-bac0-c58644701f4a"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7-nO8i6aJ1a",
        "outputId": "d79d74f6-5d94-4840-f599-fe753de9c664"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swuyMDFUaJ1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a422d97e-7e24-4504-961f-2ac22d01cda4"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.3], iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: less than 75% gpu memory available for training. Free: 549.75 Total: 15109.75\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKofLJ1uaJ1b",
        "outputId": "c3844ba9-6721-42de-c038-93bfd58b0af3"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.8885    0.9053    0.8968      1109\n",
            "I-GoodsString     0.8551    0.8795    0.8671      1718\n",
            "\n",
            "    micro avg     0.8681    0.8896    0.8788      2827\n",
            "    macro avg     0.8718    0.8924    0.8820      2827\n",
            " weighted avg     0.8682    0.8896    0.8788      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4WKYxHZuT9p"
      },
      "source": [
        "## W2V(not fixed, window=25) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgm2UrFtuT9p"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=50, window=25, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si5Zc-UjuEN3",
        "outputId": "4b4b9e01-6f55-44b4-8533-db6630047507"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 3004, 50)          424150    \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_15 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 464,880\n",
            "Trainable params: 464,880\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EN4RSuMuEN9",
        "outputId": "771257d5-543a-4cd6-99ca-22c0079da910"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='window=25,best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=1024,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('window=25,best_model.h5')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 16s 19ms/step - loss: 0.9337 - crf_marginal_accuracy: 0.0384 - val_loss: 0.7648 - val_crf_marginal_accuracy: 0.9733\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.7331 - crf_marginal_accuracy: 0.9801 - val_loss: 0.6647 - val_crf_marginal_accuracy: 0.9791\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.6376 - crf_marginal_accuracy: 0.9845 - val_loss: 0.5911 - val_crf_marginal_accuracy: 0.9865\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.5667 - crf_marginal_accuracy: 0.9896 - val_loss: 0.5539 - val_crf_marginal_accuracy: 0.0815\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.5283 - crf_marginal_accuracy: 0.0670 - val_loss: 0.5132 - val_crf_marginal_accuracy: 0.9917\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.4903 - crf_marginal_accuracy: 0.9932 - val_loss: 0.4919 - val_crf_marginal_accuracy: 0.9918\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.4703 - crf_marginal_accuracy: 0.9931 - val_loss: 0.4765 - val_crf_marginal_accuracy: 0.9916\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.4553 - crf_marginal_accuracy: 0.9930 - val_loss: 0.4651 - val_crf_marginal_accuracy: 0.9915\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.4438 - crf_marginal_accuracy: 0.9931 - val_loss: 0.4576 - val_crf_marginal_accuracy: 0.9918\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.4355 - crf_marginal_accuracy: 0.9933 - val_loss: 0.4520 - val_crf_marginal_accuracy: 0.9918\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.4288 - crf_marginal_accuracy: 0.9932 - val_loss: 0.4476 - val_crf_marginal_accuracy: 0.9914\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.4236 - crf_marginal_accuracy: 0.9929 - val_loss: 0.4431 - val_crf_marginal_accuracy: 0.9910\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.4185 - crf_marginal_accuracy: 0.9924 - val_loss: 0.4376 - val_crf_marginal_accuracy: 0.9911\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.4134 - crf_marginal_accuracy: 0.9925 - val_loss: 0.4328 - val_crf_marginal_accuracy: 0.9916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGjQQcIDuEN9",
        "outputId": "f914a62e-b561-48ab-a248-a2b828e3255b"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.1645    0.4941    0.2468      1109\n",
            "I-GoodsString     0.3562    0.3260    0.3404      1718\n",
            "\n",
            "    micro avg     0.2260    0.3919    0.2867      2827\n",
            "    macro avg     0.2604    0.4100    0.2936      2827\n",
            " weighted avg     0.2810    0.3919    0.3037      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4nOcQoQ7r6Y"
      },
      "source": [
        "## W2V(fixed, window=25) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peH3Gg3p7gYa",
        "outputId": "c89406db-d834-4852-8bcc-d2934726bbbc"
      },
      "source": [
        "MAX_WORDS = len(w2v.wv.vocab)\n",
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[w2v.wv.vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.005), loss=focal_loss(gamma=4), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_18 (Embedding)     (None, 3004, 50)          424150    \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_18 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_18 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 464,880\n",
            "Trainable params: 40,730\n",
            "Non-trainable params: 424,150\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik-ulolE7gYb",
        "outputId": "489a5cbf-0d91-4cbc-918a-cd7581e08ace"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='window=25,best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=1024,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('window=25,best_model_fixed_embeds.h5')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 16s 19ms/step - loss: 0.4207 - crf_marginal_accuracy: 0.9963 - val_loss: 0.2760 - val_crf_marginal_accuracy: 0.9959\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.2712 - crf_marginal_accuracy: 0.9964 - val_loss: 0.2555 - val_crf_marginal_accuracy: 0.9958\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2507 - crf_marginal_accuracy: 0.9962 - val_loss: 0.2426 - val_crf_marginal_accuracy: 0.9952\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.2371 - crf_marginal_accuracy: 0.9958 - val_loss: 0.2359 - val_crf_marginal_accuracy: 0.9944\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2296 - crf_marginal_accuracy: 0.9951 - val_loss: 0.2295 - val_crf_marginal_accuracy: 0.9944\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 13s 16ms/step - loss: 0.2232 - crf_marginal_accuracy: 0.9951 - val_loss: 0.2233 - val_crf_marginal_accuracy: 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmQt6txl7gYb",
        "outputId": "24df7269-6d56-4e1d-c3df-11844138c46f"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.2520    0.1452    0.1842      1109\n",
            "I-GoodsString     0.3482    0.2858    0.3139      1718\n",
            "\n",
            "    micro avg     0.3182    0.2306    0.2674      2827\n",
            "    macro avg     0.3001    0.2155    0.2491      2827\n",
            " weighted avg     0.3105    0.2306    0.2630      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpLPjaElaOZH"
      },
      "source": [
        "\n",
        "## W2V(fixed, window=25) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wywjpjwaeB_Z"
      },
      "source": [
        "w2v = Word2Vec(sentences=df['tokens'], size=30, window=25, min_count=2)\n",
        "w2v.train(sentences=df['tokens'], total_examples=w2v.corpus_count, epochs=30)\n",
        "for d in all_dfs:\n",
        "    d['int_tokens'] = d.apply(find_token, axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iksvgnyyaOZH",
        "outputId": "4ec292b9-b662-428c-eb84-d92483addc1b"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgY_iTw6aOZI",
        "outputId": "5fbcefb9-aa7e-44fd-874a-28f3633ea274"
      },
      "source": [
        "EMBEDDING_LENGTH = w2v.vector_size\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(w2v.wv.vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jsvElhRaOZI"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.3], iterations=10000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsP5GT8daOZI",
        "outputId": "30c236c4-cba3-41e7-f41a-17f780fb8402"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9378    0.9116    0.9246      1109\n",
            "I-GoodsString     0.9098    0.8865    0.8980      1718\n",
            "\n",
            "    micro avg     0.9208    0.8964    0.9084      2827\n",
            "    macro avg     0.9238    0.8991    0.9113      2827\n",
            " weighted avg     0.9208    0.8964    0.9084      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAsUlkf-ap4n"
      },
      "source": [
        "## GLOVE (not fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNrzxYz3ar3x",
        "outputId": "54304f35-15fc-449b-98f8-3e95281cf9f8"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=5)\n",
        "\n",
        "glove = Glove(no_components=50, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtUIADA6a6h-",
        "outputId": "59073a71-68fd-4c4b-9041-c2017ede4d4a"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=True))\n",
        "model.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model.add(crf)\n",
        "\n",
        "model.compile(Adam(lr=0.01), loss=focal_loss(), metrics=[crf_marginal_accuracy])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 3004, 50)          618050    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 658,780\n",
            "Trainable params: 658,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTxAndSBa6iK",
        "outputId": "3ba5b880-ec78-4cf9-a90e-c718f320e8b0"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=5),\n",
        "         ModelCheckpoint(filepath='not_pretrained_glove_best_model.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model.load_weights('not_pretrained_glove_best_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 89s 104ms/step - loss: 0.6272 - crf_marginal_accuracy: 0.9930 - val_loss: 0.4888 - val_crf_marginal_accuracy: 0.9963\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4588 - crf_marginal_accuracy: 0.9936 - val_loss: 0.4634 - val_crf_marginal_accuracy: 0.9964\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.4333 - crf_marginal_accuracy: 0.9970 - val_loss: 0.4511 - val_crf_marginal_accuracy: 0.9967\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.3979 - crf_marginal_accuracy: 0.9973 - val_loss: 0.4313 - val_crf_marginal_accuracy: 0.9969\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.3423 - crf_marginal_accuracy: 0.9977 - val_loss: 0.4080 - val_crf_marginal_accuracy: 0.9973\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 88s 102ms/step - loss: 0.2862 - crf_marginal_accuracy: 0.9982 - val_loss: 0.3913 - val_crf_marginal_accuracy: 0.9978\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 86s 101ms/step - loss: 0.2469 - crf_marginal_accuracy: 0.9985 - val_loss: 0.3634 - val_crf_marginal_accuracy: 0.9983\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1953 - crf_marginal_accuracy: 0.9990 - val_loss: 0.3370 - val_crf_marginal_accuracy: 0.9987\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 88s 103ms/step - loss: 0.1507 - crf_marginal_accuracy: 0.9994 - val_loss: 0.3280 - val_crf_marginal_accuracy: 0.9988\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 87s 102ms/step - loss: 0.1160 - crf_marginal_accuracy: 0.9997 - val_loss: 0.3239 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0869 - crf_marginal_accuracy: 0.9998 - val_loss: 0.3280 - val_crf_marginal_accuracy: 0.9990\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0618 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3355 - val_crf_marginal_accuracy: 0.9991\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 87s 101ms/step - loss: 0.0449 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3476 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0317 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3802 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0257 - crf_marginal_accuracy: 0.9999 - val_loss: 0.3844 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0222 - crf_marginal_accuracy: 1.0000 - val_loss: 0.3878 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0184 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4099 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 18/30\n",
            "857/857 [==============================] - 86s 100ms/step - loss: 0.0150 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4020 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 19/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0129 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4173 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 20/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0092 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4032 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 21/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0081 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4399 - val_crf_marginal_accuracy: 0.9993\n",
            "Epoch 22/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0075 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4624 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 23/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0070 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4771 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 24/30\n",
            "857/857 [==============================] - 84s 98ms/step - loss: 0.0068 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4615 - val_crf_marginal_accuracy: 0.9992\n",
            "Epoch 25/30\n",
            "857/857 [==============================] - 85s 99ms/step - loss: 0.0068 - crf_marginal_accuracy: 1.0000 - val_loss: 0.4605 - val_crf_marginal_accuracy: 0.9993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fQo3JKAa6iL",
        "outputId": "694b0e81-a541-4e8d-ca86-ab3df77b2344"
      },
      "source": [
        "preds = model.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9172    0.8693    0.8926      1109\n",
            "I-GoodsString     0.8951    0.8737    0.8842      1718\n",
            "\n",
            "    micro avg     0.9036    0.8719    0.8875      2827\n",
            "    macro avg     0.9061    0.8715    0.8884      2827\n",
            " weighted avg     0.9037    0.8719    0.8875      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0LPCsrMoJYm"
      },
      "source": [
        "## GLOVE (fixed) + BILSTM + CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7KzsnJxvbDN",
        "outputId": "5451f165-f262-481f-dc9d-a7d8b89750b4"
      },
      "source": [
        "MAX_WORDS = len(glove.dictionary)\n",
        "EMBEDDING_LENGTH = glove.no_components\n",
        "MAX_SEQUENCE_LENGTH = np.max(df['int_tokens'].apply(len))\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "model_fixed_embeds = Sequential()\n",
        "model_fixed_embeds.add(Embedding(MAX_WORDS, EMBEDDING_LENGTH, input_length=MAX_SEQUENCE_LENGTH, mask_zero=False, weights=[glove.word_vectors], trainable=False))\n",
        "model_fixed_embeds.add(Bidirectional(LSTM(HIDDEN_SIZE, return_sequences=True)))\n",
        "model_fixed_embeds.add(TimeDistributed(Dense(len(label_list), activation=\"relu\")))\n",
        "crf = CRF(len(label_list), learn_mode='marginal')\n",
        "model_fixed_embeds.add(crf)\n",
        "\n",
        "model_fixed_embeds.compile(Adam(lr=0.01), loss=focal_loss(gamma=4), metrics=[crf_marginal_accuracy])\n",
        "model_fixed_embeds.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_17 (Embedding)     (None, 3004, 50)          618050    \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 3004, 100)         40400     \n",
            "_________________________________________________________________\n",
            "time_distributed_17 (TimeDis (None, 3004, 3)           303       \n",
            "_________________________________________________________________\n",
            "crf_17 (CRF)                 (None, 3004, 3)           27        \n",
            "=================================================================\n",
            "Total params: 658,780\n",
            "Trainable params: 40,730\n",
            "Non-trainable params: 618,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE_R3XoqvbDP",
        "outputId": "17f72467-80a4-4e70-adf7-c473f2ca8e40"
      },
      "source": [
        "callbacks = [EarlyStopping(monitor='val_crf_marginal_accuracy', patience=10),\n",
        "         ModelCheckpoint(filepath='not_pretrained_glove_best_model_fixed_embeds.h5', monitor='val_crf_marginal_accuracy', save_best_only=True)]\n",
        "\n",
        "x_train = pad_sequences(train['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH)\n",
        "y_train = pad_sequences(train['encoded_ner_tags'], padding='post', maxlen=MAX_SEQUENCE_LENGTH, value=tag_to_idx['O'])\n",
        "y_train = to_categorical(y_train, num_classes=len(label_list))\n",
        "history = model_fixed_embeds.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    epochs=30,\n",
        "    batch_size=1024,\n",
        "    callbacks=callbacks,\n",
        "    validation_split=0.1,\n",
        ")\n",
        "\n",
        "model_fixed_embeds.load_weights('not_pretrained_glove_best_model_fixed_embeds.h5')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 857 samples, validate on 96 samples\n",
            "Epoch 1/30\n",
            "857/857 [==============================] - 16s 18ms/step - loss: 0.4335 - crf_marginal_accuracy: 0.9966 - val_loss: 0.3496 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 2/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.3380 - crf_marginal_accuracy: 0.9966 - val_loss: 0.4887 - val_crf_marginal_accuracy: 0.9593\n",
            "Epoch 3/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.4741 - crf_marginal_accuracy: 0.9637 - val_loss: 0.2706 - val_crf_marginal_accuracy: 0.9870\n",
            "Epoch 4/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2655 - crf_marginal_accuracy: 0.9887 - val_loss: 0.2767 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 5/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2712 - crf_marginal_accuracy: 0.9966 - val_loss: 0.2876 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 6/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2818 - crf_marginal_accuracy: 0.9964 - val_loss: 0.2663 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 7/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2606 - crf_marginal_accuracy: 0.9962 - val_loss: 0.2410 - val_crf_marginal_accuracy: 0.9966\n",
            "Epoch 8/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2361 - crf_marginal_accuracy: 0.9963 - val_loss: 0.2348 - val_crf_marginal_accuracy: 0.9934\n",
            "Epoch 9/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2299 - crf_marginal_accuracy: 0.9934 - val_loss: 0.2394 - val_crf_marginal_accuracy: 0.9845\n",
            "Epoch 10/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2341 - crf_marginal_accuracy: 0.9866 - val_loss: 0.2392 - val_crf_marginal_accuracy: 0.9816\n",
            "Epoch 11/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2339 - crf_marginal_accuracy: 0.9840 - val_loss: 0.2326 - val_crf_marginal_accuracy: 0.9850\n",
            "Epoch 12/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2269 - crf_marginal_accuracy: 0.9863 - val_loss: 0.2249 - val_crf_marginal_accuracy: 0.9905\n",
            "Epoch 13/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2187 - crf_marginal_accuracy: 0.9905 - val_loss: 0.2197 - val_crf_marginal_accuracy: 0.9942\n",
            "Epoch 14/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2131 - crf_marginal_accuracy: 0.9940 - val_loss: 0.2176 - val_crf_marginal_accuracy: 0.9954\n",
            "Epoch 15/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2106 - crf_marginal_accuracy: 0.9955 - val_loss: 0.2174 - val_crf_marginal_accuracy: 0.9961\n",
            "Epoch 16/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2103 - crf_marginal_accuracy: 0.9963 - val_loss: 0.2173 - val_crf_marginal_accuracy: 0.9962\n",
            "Epoch 17/30\n",
            "857/857 [==============================] - 13s 15ms/step - loss: 0.2101 - crf_marginal_accuracy: 0.9966 - val_loss: 0.2165 - val_crf_marginal_accuracy: 0.9962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRQU0DDgvbDQ",
        "outputId": "01eb1183-e55e-456f-aad3-af9f15075534"
      },
      "source": [
        "preds = model_fixed_embeds.predict(pad_sequences(test['int_tokens'], padding='post', maxlen=MAX_SEQUENCE_LENGTH))\n",
        "tag_preds = [np.argmax(pred, axis=1) for pred in preds]\n",
        "truncated_preds = []\n",
        "for i in range(len(tag_preds)):\n",
        "    truncated_preds.append(tag_preds[i][:len(test['encoded_ner_tags'].iloc[i])])\n",
        "named_preds = []\n",
        "for i in truncated_preds:\n",
        "    named_preds.append([])\n",
        "    for j in i:\n",
        "        named_preds[-1].append(label_list[j])\n",
        "\n",
        "print(metrics.flat_classification_report(test['ner_tags'], named_preds, digits=4, labels=labels))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.0251    0.0153    0.0190      1109\n",
            "I-GoodsString     0.6494    0.3277    0.4356      1718\n",
            "\n",
            "    micro avg     0.3756    0.2052    0.2654      2827\n",
            "    macro avg     0.3372    0.1715    0.2273      2827\n",
            " weighted avg     0.4045    0.2052    0.2722      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvYtfwsNzuZd"
      },
      "source": [
        "## GLOVE (fixed, window=5) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pCZ2NJ_zfvQ",
        "outputId": "eb520088-a242-4f0a-b854-ae591795b924"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJlUl4tnzfvb",
        "outputId": "ae121cec-4151-4333-e07c-3123452665d1"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 5\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_-CTKgczfvb"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.3], iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBN8OPD0zfvb",
        "outputId": "341a378c-33d8-48bc-f227-e453d047cb42"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.8959    0.8999    0.8979      1109\n",
            "I-GoodsString     0.8666    0.8731    0.8698      1718\n",
            "\n",
            "    micro avg     0.8780    0.8836    0.8808      2827\n",
            "    macro avg     0.8812    0.8865    0.8839      2827\n",
            " weighted avg     0.8781    0.8836    0.8808      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mj6XiDy65yt"
      },
      "source": [
        "## GLOVE (fixed, window=10) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r-ARNPS61Ib",
        "outputId": "b597a311-22d6-47c4-df8d-11033bfb9faa"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=10)\n",
        "\n",
        "glove = Glove(no_components=50, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=100, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 100 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjcyEbXN7GM0",
        "outputId": "37fa6dd3-887d-4d09-9ac1-7a42c80c9f82"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 10\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPYrbq2m7GM1",
        "outputId": "a08ba987-bc7a-47b7-f46a-531b7ba1af3b"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 10\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_V0-ls47GM1"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.3], iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqI-aOY37GM1",
        "outputId": "15813585-8f9c-4141-e6c7-53310645b9a4"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.8955    0.8963    0.8959      1109\n",
            "I-GoodsString     0.8554    0.8882    0.8715      1718\n",
            "\n",
            "    micro avg     0.8708    0.8914    0.8810      2827\n",
            "    macro avg     0.8754    0.8923    0.8837      2827\n",
            " weighted avg     0.8711    0.8914    0.8811      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYzIBS7IjLwK"
      },
      "source": [
        "## GLOVE (fixed, window=25) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VICcoqOVjLwL",
        "outputId": "4369beb6-ef8f-4e82-e679-0506dca4448e"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=25)\n",
        "\n",
        "glove = Glove(no_components=20, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=100, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 100 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQncFeCOjLwL",
        "outputId": "c18c014c-2e7f-4dc1-aa0b-3777886708bd"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMFCFVQWjLwL",
        "outputId": "82d4b608-b772-4c31-b8e3-dadf374d0b2f"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0uYfrCUjLwL"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.3], iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k600p1NVjLwM",
        "outputId": "991b5959-3005-4b94-a68b-77bc03458de4"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9180    0.8990    0.9084      1109\n",
            "I-GoodsString     0.8825    0.8871    0.8848      1718\n",
            "\n",
            "    micro avg     0.8962    0.8918    0.8940      2827\n",
            "    macro avg     0.9003    0.8930    0.8966      2827\n",
            " weighted avg     0.8964    0.8918    0.8940      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBIZP9Wqn4Xe"
      },
      "source": [
        "## GLOVE (fixed, window=20) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtnxKj_ln4Xe",
        "outputId": "9930ff65-978d-48a0-eff0-6ffc7355a90b"
      },
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=20)\n",
        "\n",
        "glove = Glove(no_components=30, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=100, no_threads=8, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 100 training epochs with 8 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n",
            "Epoch 30\n",
            "Epoch 31\n",
            "Epoch 32\n",
            "Epoch 33\n",
            "Epoch 34\n",
            "Epoch 35\n",
            "Epoch 36\n",
            "Epoch 37\n",
            "Epoch 38\n",
            "Epoch 39\n",
            "Epoch 40\n",
            "Epoch 41\n",
            "Epoch 42\n",
            "Epoch 43\n",
            "Epoch 44\n",
            "Epoch 45\n",
            "Epoch 46\n",
            "Epoch 47\n",
            "Epoch 48\n",
            "Epoch 49\n",
            "Epoch 50\n",
            "Epoch 51\n",
            "Epoch 52\n",
            "Epoch 53\n",
            "Epoch 54\n",
            "Epoch 55\n",
            "Epoch 56\n",
            "Epoch 57\n",
            "Epoch 58\n",
            "Epoch 59\n",
            "Epoch 60\n",
            "Epoch 61\n",
            "Epoch 62\n",
            "Epoch 63\n",
            "Epoch 64\n",
            "Epoch 65\n",
            "Epoch 66\n",
            "Epoch 67\n",
            "Epoch 68\n",
            "Epoch 69\n",
            "Epoch 70\n",
            "Epoch 71\n",
            "Epoch 72\n",
            "Epoch 73\n",
            "Epoch 74\n",
            "Epoch 75\n",
            "Epoch 76\n",
            "Epoch 77\n",
            "Epoch 78\n",
            "Epoch 79\n",
            "Epoch 80\n",
            "Epoch 81\n",
            "Epoch 82\n",
            "Epoch 83\n",
            "Epoch 84\n",
            "Epoch 85\n",
            "Epoch 86\n",
            "Epoch 87\n",
            "Epoch 88\n",
            "Epoch 89\n",
            "Epoch 90\n",
            "Epoch 91\n",
            "Epoch 92\n",
            "Epoch 93\n",
            "Epoch 94\n",
            "Epoch 95\n",
            "Epoch 96\n",
            "Epoch 97\n",
            "Epoch 98\n",
            "Epoch 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9QiUfNKn4Xe",
        "outputId": "9d74a344-568b-42e7-97f0-7ba11e6e2b96"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6OkahAUn4Xf",
        "outputId": "9281e5fc-fff0-42af-8882-1ede82d42f7b"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 20\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Picoj7eUn4Xf"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.3], iterations=1000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7utYKHkHn4Xf",
        "outputId": "6967c0e7-6281-45fb-c9ba-fb0bdf0660e7"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9132    0.9008    0.9069      1109\n",
            "I-GoodsString     0.8823    0.8987    0.8904      1718\n",
            "\n",
            "    micro avg     0.8942    0.8995    0.8968      2827\n",
            "    macro avg     0.8977    0.8998    0.8987      2827\n",
            " weighted avg     0.8944    0.8995    0.8969      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl-kdToFKHn0"
      },
      "source": [
        "## Подбор гиперпараметров для CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxr9cm5gKNIx",
        "outputId": "15619441-e1a9-47fe-aa4d-06b9f83a6f3f"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "window_sizes = range(2, 25)\n",
        "EMBEDDING_LENGTH = 30\n",
        "\n",
        "for window_size in tqdm(window_sizes):\n",
        "    corpus = Corpus() \n",
        "\n",
        "    corpus.fit(df['tokens'], window=window_size)\n",
        "\n",
        "    glove = Glove(no_components=EMBEDDING_LENGTH, learning_rate=0.05) \n",
        "    glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=False)\n",
        "    glove.add_dictionary(corpus.dictionary)\n",
        "    for d in all_dfs:\n",
        "        d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "        d['int_tokens'] = d.apply(find_glove_token, axis=1)\n",
        "    \n",
        "    catboost_x_train = []\n",
        "    catboost_y_train = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_train.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    train.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    catboost_x_test = []\n",
        "    catboost_y_test = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_test.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    test.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", iterations=1000)\n",
        "    cb.fit(catboost_x_train, catboost_y_train)\n",
        "    pred = cb.predict(catboost_x_test)\n",
        "    f1_scores.append(f1_score(catboost_y_test, pred, average='weighted', labels=[0, 1]))\n",
        "    precision_scores.append(precision_score(catboost_y_test, pred, average='weighted', labels=[0, 1]))\n",
        "    recall_scores.append(recall_score(catboost_y_test, pred, average='weighted', labels=[0, 1]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [45:03<00:00, 117.53s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "EWSpAUjhXbVN",
        "outputId": "2e9eea7f-4454-4509-b19c-032b4f562520"
      },
      "source": [
        "plt.plot(window_sizes, f1_scores, label='f1')\n",
        "plt.plot(window_sizes, precision_scores, label='precision')\n",
        "plt.plot(window_sizes, recall_scores, label='recall')\n",
        "plt.title('Metrics dependency on window size')\n",
        "plt.xlabel('Window size')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbgOyEPrAXL0",
        "outputId": "73ffb4bb-d232-467d-add0-1d1d00eaacaa"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "\n",
        "f1_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "window_size = 25\n",
        "EMBEDDING_LENGTH = 10\n",
        "\n",
        "for o_weight in tqdm(np.arange(0.05, 1.0000001, 0.05)):\n",
        "    corpus = Corpus() \n",
        "\n",
        "    corpus.fit(df['tokens'], window=window_size)\n",
        "\n",
        "    glove = Glove(no_components=EMBEDDING_LENGTH, learning_rate=0.05) \n",
        "    glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=False)\n",
        "    glove.add_dictionary(corpus.dictionary)\n",
        "    for d in all_dfs:\n",
        "        d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "        d['int_tokens'] = d.apply(find_glove_token, axis=1)\n",
        "    \n",
        "    catboost_x_train = []\n",
        "    catboost_y_train = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_train.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    train.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    catboost_x_test = []\n",
        "    catboost_y_test = []\n",
        "\n",
        "    def prepare_data_for_catboost(x):\n",
        "        tokenized_text = x['int_tokens']\n",
        "        for i, token in enumerate(tokenized_text):\n",
        "            catboost_x_test.append([])\n",
        "            for shift in range(window_size):\n",
        "                if i - window_size // 2 + shift < 0 or i - window_size // 2 + shift >= len(tokenized_text) :\n",
        "                    catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "                else:\n",
        "                    catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - window_size // 2 + shift]])\n",
        "            catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "    test.apply(prepare_data_for_catboost, axis=1)\n",
        "\n",
        "    cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1] * 2 + [o_weight], iterations=1000)\n",
        "    cb.fit(catboost_x_train, catboost_y_train)\n",
        "    pred = cb.predict(catboost_x_test)\n",
        "    f1_scores.append(f1_score(catboost_y_test, pred, average='weighted', labels=[0, 1]))\n",
        "    precision_scores.append(precision_score(catboost_y_test, pred, average='weighted', labels=[0, 1]))\n",
        "    recall_scores.append(recall_score(catboost_y_test, pred, average='weighted', labels=[0, 1]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [28:45<00:00, 86.27s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "X7aD5-aKAXL-",
        "outputId": "22decca4-7c0b-4325-b514-ef817311860f"
      },
      "source": [
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), f1_scores, label='f1')\n",
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), precision_scores, label='precision')\n",
        "plt.plot(np.arange(0.05, 1.0000001, 0.05), recall_scores, label='recall')\n",
        "plt.title('Metrics dependency on O weight')\n",
        "plt.xlabel('O weight')\n",
        "plt.ylabel('Score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcd-r_M4BPAC"
      },
      "source": [
        "## GLOVE (fixed, window=25, O_weight=0.7) + CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKfpXYtkBPAC"
      },
      "source": [
        "def find_glove_token(x):\n",
        "    res = []\n",
        "    for w in x['tokens']:\n",
        "        if w in glove.dictionary.keys():\n",
        "            res.append(glove.dictionary[w])\n",
        "        else:\n",
        "            res.append(0)\n",
        "    return res\n",
        "\n",
        "#Creating a corpus object\n",
        "corpus = Corpus() \n",
        "\n",
        "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(df['tokens'], window=25)\n",
        "\n",
        "glove = Glove(no_components=30, learning_rate=0.05) \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=False)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "\n",
        "for d in all_dfs:\n",
        "    d['encoded_ner_tags'] = d.apply(lambda x: [tag_to_idx[t] for t in x['ner_tags']], axis=1)\n",
        "    d['int_tokens'] = d.apply(find_glove_token, axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS3pI_5aBPAC",
        "outputId": "c65071cc-5901-4a4e-aa23-9a0f8c935bde"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_train = []\n",
        "catboost_y_train = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_train.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_train[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_train[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_train.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "train.apply(prepare_data_for_catboost, axis=1)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "948    None\n",
              "949    None\n",
              "950    None\n",
              "951    None\n",
              "952    None\n",
              "Length: 953, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02V-qh_8BPAD",
        "outputId": "553cfaaf-5794-4e27-d213-3657d1b26ea9"
      },
      "source": [
        "EMBEDDING_LENGTH = glove.no_components\n",
        "WINDOW_SIZE = 25\n",
        "catboost_x_test = []\n",
        "catboost_y_test = []\n",
        "\n",
        "def prepare_data_for_catboost(x):\n",
        "    tokenized_text = x['int_tokens']\n",
        "    for i, token in enumerate(tokenized_text):\n",
        "        catboost_x_test.append([])\n",
        "        for shift in range(WINDOW_SIZE):\n",
        "            if i - WINDOW_SIZE // 2 + shift < 0 or i - WINDOW_SIZE // 2 + shift >= len(tokenized_text) :\n",
        "                catboost_x_test[-1] += [0] * EMBEDDING_LENGTH\n",
        "            else:\n",
        "                catboost_x_test[-1] += list(glove.word_vectors[tokenized_text[i - WINDOW_SIZE // 2 + shift]])\n",
        "        catboost_y_test.append(tag_to_idx[x['ner_tags'][i]])\n",
        "\n",
        "\n",
        "test.apply(prepare_data_for_catboost, axis=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "234    None\n",
              "235    None\n",
              "236    None\n",
              "237    None\n",
              "238    None\n",
              "Length: 239, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOx71rEwBPAD"
      },
      "source": [
        "cb = CatBoostClassifier(verbose=False, task_type=\"GPU\", class_weights=[1, 1, 0.25], iterations=25000)\n",
        "cb.fit(catboost_x_train, catboost_y_train)\n",
        "pred = cb.predict(catboost_x_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80QcGyiBBPAD",
        "outputId": "39fb3c14-e828-4686-bb6c-98e72f5a9d7c"
      },
      "source": [
        "print(metrics.flat_classification_report(\n",
        "    np.array([label_list[i] for i in catboost_y_test])[..., np.newaxis, np.newaxis], \n",
        "    np.array([label_list[i] for i in pred[:, 0]])[..., np.newaxis, np.newaxis], \n",
        "    digits=4, \n",
        "    labels=labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "B-GoodsString     0.9288    0.9179    0.9234      1109\n",
            "I-GoodsString     0.9115    0.8935    0.9024      1718\n",
            "\n",
            "    micro avg     0.9183    0.9031    0.9106      2827\n",
            "    macro avg     0.9202    0.9057    0.9129      2827\n",
            " weighted avg     0.9183    0.9031    0.9106      2827\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN0Au-eHPKd8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}